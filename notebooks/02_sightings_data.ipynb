{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79806fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import glob\n",
    "import h3\n",
    "from typing import Literal\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "## Compute Sunday from Statistical Week\n",
    "def compute_sunday(row):\n",
    "    jan1 = datetime(int(row[\"catch_year\"]), 1, 1)\n",
    "    first_monday = jan1 + timedelta(days=(7 - jan1.weekday()) % 7)\n",
    "    return first_monday + timedelta(weeks=int(row[\"stat_week\"]) - 1, days=6)\n",
    "\n",
    "\n",
    "## Catch Data Preprocessing\n",
    "def preprocess_rmpc_catch_data(catch_data):\n",
    "    cs = catch_data.copy()\n",
    "\n",
    "    cs.columns = cs.columns.str.strip().str.lower()\n",
    "\n",
    "    # Adjust Catch Code\n",
    "    cs[\"catch_location_code\"] = cs[\"catch_location_code\"].str.replace(\"  \", \" \")\n",
    "\n",
    "    # Add State Code\n",
    "    cs[\"state_code\"] = cs[\"catch_location_code\"].str[0]\n",
    "\n",
    "    # Add Water Type\n",
    "    cs[\"water_type_code\"] = cs[\"catch_location_code\"].str[1]\n",
    "\n",
    "    # Add Sector\n",
    "    cs[\"sector_code\"] = cs[\"catch_location_code\"].str[2]\n",
    "\n",
    "    # Add Region\n",
    "    cs[\"region_code\"] = cs[\"catch_location_code\"].str[3:5]\n",
    "\n",
    "    # Add Statistical Area\n",
    "    cs[\"statistical_area\"] = cs[\"catch_location_code\"].str[5:7]\n",
    "\n",
    "    # Filter to Statistical Week Period\n",
    "    cs = cs[cs.period_type == \"6\"]\n",
    "    cs[\"stat_week\"] = cs[\"period\"]\n",
    "\n",
    "    # Build Date\n",
    "    cs[\"stat_week_sunday\"] = cs.apply(compute_sunday, axis=1)\n",
    "\n",
    "    # Add Number Caught\n",
    "    cs[\"number_caught\"] = cs[\"number_caught\"].astype(float)\n",
    "\n",
    "    return cs\n",
    "\n",
    "\n",
    "## Recovery Data Preprocessing\n",
    "def preprocess_rmpc_recovery_data(recovery_data):\n",
    "    rs = recovery_data.copy()\n",
    "\n",
    "    rs.columns = rs.columns.str.strip().str.lower()\n",
    "\n",
    "    # Adjust Catch Code\n",
    "    rs[\"recovery_location_code\"] = rs[\"recovery_location_code\"].str.replace(\"  \", \" \")\n",
    "\n",
    "    # Add State Code\n",
    "    rs[\"state_code\"] = rs[\"recovery_location_code\"].str[0]\n",
    "\n",
    "    # Add Water Type\n",
    "    rs[\"water_type_code\"] = rs[\"recovery_location_code\"].str[1]\n",
    "\n",
    "    # Add Sector\n",
    "    rs[\"sector_code\"] = rs[\"recovery_location_code\"].str[2]\n",
    "\n",
    "    # Add Region\n",
    "    rs[\"region_code\"] = rs[\"recovery_location_code\"].str[3:5]\n",
    "\n",
    "    # Add Statistical Area\n",
    "    rs[\"statistical_area\"] = rs[\"recovery_location_code\"].str[5:7]\n",
    "\n",
    "    # Filter to Statistical Week Period\n",
    "    rs = rs[rs.period_type == \"6\"]\n",
    "    rs[\"stat_week\"] = rs[\"period\"]\n",
    "\n",
    "    # Build Date\n",
    "    rs = rs.rename(columns={\"run_year\": \"catch_year\"})\n",
    "    rs[\"stat_week_sunday\"] = rs.apply(compute_sunday, axis=1)\n",
    "\n",
    "    # Add Number Caught\n",
    "    rs[\"number_caught\"] = 1  # rs[\"number_caught\"].astype(float)\n",
    "\n",
    "    return rs\n",
    "\n",
    "\n",
    "# Loan and Process Sightings\n",
    "def load_and_process_sighting_data(\n",
    "    directory: str,\n",
    "    date_col: str,\n",
    "    lat_col: str,\n",
    "    lon_col: str,\n",
    "    id_col: str,\n",
    "    h3_resolution: int,\n",
    "    start_date: str = None,\n",
    "    source: Literal[\"TMW\", \"ACARTIA\"] = \"TMW\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and process sighting data for TMW or Acartia.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Path to CSV files.\n",
    "        date_col (str): Column name containing datetime string.\n",
    "        lat_col (str): Latitude column name.\n",
    "        lon_col (str): Longitude column name.\n",
    "        id_col (str): Unique identifier or countable column.\n",
    "        h3_resolution (int): H3 resolution to use.\n",
    "        start_date (str, optional): Filter records to start at this date.\n",
    "        source (str): \"TMW\" or \"ACARTIA\", for minor formatting differences.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Aggregated sightings data with full date-grid coverage.\n",
    "    \"\"\"\n",
    "    print(directory)\n",
    "    # Read & concat all CSVs\n",
    "    if \".csv\" in directory:\n",
    "        data = pd.read_csv(directory)\n",
    "    else:\n",
    "        data = pd.concat(\n",
    "            [pd.read_csv(path) for path in glob.glob(f\"{directory}/*.csv\")]\n",
    "        )\n",
    "    data.columns = data.columns.str.upper()\n",
    "\n",
    "    # Parse date and geo\n",
    "    data[\"DATE\"] = data[date_col].str[:10]\n",
    "    data[\"LATITUDE\"] = pd.to_numeric(data[lat_col], errors=\"coerce\")\n",
    "    data[\"LONGITUDE\"] = pd.to_numeric(data[lon_col], errors=\"coerce\")\n",
    "    data = data.dropna(subset=[\"LATITUDE\", \"LONGITUDE\"])\n",
    "\n",
    "    # Calculate H3 grid\n",
    "    h3_col = f\"H3_GRID_{h3_resolution}\"\n",
    "    data[h3_col] = data.apply(\n",
    "        lambda x: h3.latlng_to_cell(x[\"LATITUDE\"], x[\"LONGITUDE\"], h3_resolution),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    data[\"DATE\"] = pd.to_datetime(data[\"DATE\"])\n",
    "    if start_date:\n",
    "        data = data[data[\"DATE\"] >= pd.to_datetime(start_date)]\n",
    "\n",
    "    # Aggregate sightings\n",
    "    data_agg = data.groupby(\n",
    "        [\"DATE\", \"LATITUDE\", \"LONGITUDE\", h3_col], as_index=False\n",
    "    ).agg(SIGHTING_COUNT=(id_col, \"count\"))\n",
    "\n",
    "    return data_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f525a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tylerstevenson/Documents/CODE/orcasalmon/data/twm\n",
      "/Users/tylerstevenson/Documents/CODE/FindMyWhale/data/raw/sightings/acartia-export.csv\n"
     ]
    }
   ],
   "source": [
    "## Set H3 Resolution\n",
    "h3_resolution = 3\n",
    "\n",
    "## TMW Data Path\n",
    "tmw_directory = \"/Users/tylerstevenson/Documents/CODE/orcasalmon/data/twm\"\n",
    "\n",
    "## Acartia Data Path\n",
    "acartia_directory = \"/Users/tylerstevenson/Documents/CODE/FindMyWhale/data/raw/sightings/acartia-export.csv\"\n",
    "\n",
    "## Open TMW\n",
    "tmw_data_cleaned = load_and_process_sighting_data(\n",
    "    directory=tmw_directory,\n",
    "    date_col=\"SIGHTDATE\",\n",
    "    lat_col=\"LATITUDE\",\n",
    "    lon_col=\"LONGITUDE\",\n",
    "    id_col=\"DATE\",  # or other proxy for sightings count\n",
    "    h3_resolution=h3_resolution,\n",
    "    source=\"TMW\",\n",
    ")\n",
    "\n",
    "## Open Acartia\n",
    "acartia_data_cleaned = load_and_process_sighting_data(\n",
    "    directory=acartia_directory,\n",
    "    date_col=\"CREATED\",\n",
    "    lat_col=\"LATITUDE\",\n",
    "    lon_col=\"LONGITUDE\",\n",
    "    id_col=\"ENTRY_ID\",\n",
    "    h3_resolution=h3_resolution,\n",
    "    start_date=\"2022-01-01\",\n",
    "    source=\"ACARTIA\",\n",
    ")\n",
    "\n",
    "# Conbine Sightings Data\n",
    "sightings_data_raw = pd.concat([acartia_data_cleaned, tmw_data_cleaned])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ae624c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rough bounding box around the Columbia River mouth + offshore zone\n",
    "lat_min, lat_max = 45.9, 46.4\n",
    "lon_min, lon_max = -124.4, -123.7  # includes some ocean west of the entrance\n",
    "\n",
    "df_filtered = sightings_data_raw[\n",
    "    (sightings_data_raw[\"LATITUDE\"] >= lat_min)\n",
    "    & (sightings_data_raw[\"LATITUDE\"] <= lat_max)\n",
    "    & (sightings_data_raw[\"LONGITUDE\"] >= lon_min)\n",
    "    & (sightings_data_raw[\"LONGITUDE\"] <= lon_max)\n",
    "]\n",
    "df_filtered[\"MONTH\"] = df_filtered.DATE.dt.month\n",
    "df_filtered[\"MONTH\"] = df_filtered[\"MONTH\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaf9d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c47173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure DATE is in datetime format\n",
    "df_filtered[\"DATE\"] = pd.to_datetime(df_filtered[\"DATE\"])\n",
    "df_filtered[\"MONTH\"] = df_filtered[\"DATE\"].dt.month\n",
    "\n",
    "# This works even if pandas is old\n",
    "df_filtered[\"stat_week_sunday\"] = df_filtered[\"DATE\"] - pd.to_timedelta(\n",
    "    df_filtered[\"DATE\"].dt.weekday + 1, unit=\"D\"\n",
    ")\n",
    "df_filtered = df_filtered.groupby(\"stat_week_sunday\", as_index=False)[\"MONTH\"].count()\n",
    "df_filtered.columns = [\"DATE\", \"COUNT\"]\n",
    "df_filtered[\"MONTH\"] = df_filtered[\"DATE\"].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f58b81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.groupby(\"MONTH\")[\"COUNT\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f044d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728c24cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a scatter mapbox\n",
    "# fig = px.scatter_mapbox(\n",
    "#     df_filtered,\n",
    "#     lat=\"LATITUDE\",\n",
    "#     lon=\"LONGITUDE\",\n",
    "#     color=\"MONTH\",\n",
    "#     # size=[1]*len(df_filtered),\n",
    "#     hover_name=\"MONTH\",\n",
    "#     zoom=8,\n",
    "#     center={\"lat\": 46.2, \"lon\": -124.0},\n",
    "#     color_discrete_sequence=px.colors.qualitative.Set3,\n",
    "#     mapbox_style=\"carto-positron\",  # or \"open-street-map\"\n",
    "\n",
    "# )\n",
    "\n",
    "# fig.update_layout(\n",
    "#     margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0},\n",
    "#     title=\"Orca Sightings near Columbia River Mouth\"\n",
    "# )\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834f7ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df_filtered.groupby(\"MONTH\", as_index=False)[\"COUNT\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfbb061",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(tmp, x=\"MONTH\", y=\"COUNT\", title=\"Sighting Counts by Month\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3b249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_filtered.copy()\n",
    "df = df[df.DATE >= \"2020-01-01\"]\n",
    "# Make sure your date column is datetime\n",
    "df[\"DATE\"] = pd.to_datetime(df[\"DATE\"])\n",
    "\n",
    "# Set weekly range based on Sunday (statistical week)\n",
    "min_week = df[\"DATE\"].min()\n",
    "max_week = df[\"DATE\"].max()\n",
    "\n",
    "# Create full weekly date range (Sundays)\n",
    "full_weeks = pd.date_range(start=min_week, end=max_week, freq=\"W-SUN\")\n",
    "\n",
    "# Make a DataFrame from the full weekly index\n",
    "weeks_df = pd.DataFrame({\"WEEK_START\": full_weeks})\n",
    "\n",
    "# Merge with your data (assuming you want to preserve original rows)\n",
    "df[\"WEEK_START\"] = df[\"DATE\"]\n",
    "\n",
    "# Aggregate (if needed) or deduplicate (if multiple rows per week)\n",
    "weekly_agg = df.groupby(\"WEEK_START\").sum(numeric_only=True).reset_index()\n",
    "\n",
    "# Left join with full set of weeks\n",
    "filled_df = weeks_df.merge(weekly_agg, on=\"WEEK_START\", how=\"left\")\n",
    "\n",
    "# Fill missing values\n",
    "filled_df = filled_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9a677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(filled_df, x=\"WEEK_START\", y=\"COUNT\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb6f99d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcc874c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06579129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06cf4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\n",
    "    \"/Users/tylerstevenson/Documents/CODE/SalmonSignal/data/raw/Fish count 09222024.xlsx\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3810f96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe426b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e98b441",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salmonsignal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
