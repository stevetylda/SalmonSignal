{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e8abf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------- #\n",
    "#                  MODULES                  #\n",
    "\n",
    "# Standard Modules\n",
    "import os\n",
    "import warnings\n",
    "from itertools import product\n",
    "from joblib import Parallel, delayed\n",
    "from datetime import date, timedelta\n",
    "\n",
    "# Third-Party Modules\n",
    "import geopandas as gpd\n",
    "import h3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from shapely.geometry import box, Point, Polygon\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# System Configuration\n",
    "parallel = Parallel(n_jobs=8)\n",
    "\n",
    "#                                           #\n",
    "# ----------------------------------------- #\n",
    "\n",
    "# ----------------------------------------- #\n",
    "#                 FUNCTIONS                 #\n",
    "\n",
    "\n",
    "# Data Opener for Sightings Data\n",
    "def open_sightings(path):\n",
    "    if os.path.exists(path):\n",
    "        if \".csv\" in path:\n",
    "            sightings = pd.read_csv(path)\n",
    "            return sightings\n",
    "        elif \".parquet\" in path:\n",
    "            sightings = pd.read_parquet(path)\n",
    "            return sightings\n",
    "    #     else:\n",
    "    #         raise \"WARNING: Unsupported file type - supported types include parquet and csv\"\n",
    "    else:\n",
    "        print(\"WARNING: Path does not exist.\")\n",
    "\n",
    "\n",
    "# Geometry Point to H3 Grid\n",
    "def point_to_h3(point, res):\n",
    "    # point: shapely Point geometry\n",
    "    return h3.latlng_to_cell(point.y, point.x, res)\n",
    "\n",
    "\n",
    "# H3 Grid to Polygon\n",
    "def h3_to_polygon(h3_index):\n",
    "    boundary = h3.cell_to_boundary(h3_index)\n",
    "    boundary_lonlat = [(lon, lat) for lat, lon in boundary]\n",
    "    return Polygon(boundary_lonlat)\n",
    "\n",
    "\n",
    "# Open Water Region Polygon\n",
    "def open_water_polygon_aoi(path, data_crs=\"EPSG:4326\"):\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"WARNING: Path does not exist - {path}\")\n",
    "        return None\n",
    "    else:\n",
    "        # Open Polygon\n",
    "        polygon_area = gpd.read_parquet(path)\n",
    "\n",
    "        # Dissolve Geometry\n",
    "        polygon_area = polygon_area.dissolve()\n",
    "\n",
    "        # Enforce Projection\n",
    "        polygon_area = polygon_area.to_crs(data_crs)\n",
    "\n",
    "        return polygon_area\n",
    "\n",
    "\n",
    "# Get H3 Grids Over Polygon Extent\n",
    "def get_h3_grids_over_polygon(poly_area, target_resolution=6):\n",
    "    poly_area_detach = poly_area.copy()\n",
    "    poly_area_detach[\"geometry\"] = poly_area_detach.sample_points(10000)\n",
    "    poly_area_detach = poly_area_detach[[\"geometry\"]]\n",
    "    poly_area_detach = poly_area_detach.explode()\n",
    "\n",
    "    # Apply to all points\n",
    "    poly_area_detach[\"h3_index\"] = poly_area_detach.geometry.apply(\n",
    "        lambda p: point_to_h3(p, 3)\n",
    "    )\n",
    "\n",
    "    # Get unique H3 cells\n",
    "    parent_h3_cells = poly_area_detach[\"h3_index\"].unique().tolist()\n",
    "\n",
    "    # Get children for each parent at target resolution\n",
    "    all_children = []\n",
    "    for parent in parent_h3_cells:\n",
    "        children = h3.cell_to_children(parent, target_resolution)  # Get children\n",
    "\n",
    "        all_children.extend(children)\n",
    "\n",
    "    # Remove duplicates (set automatically removes duplicates)\n",
    "    unique_children = list(set(all_children))\n",
    "\n",
    "    # Get H3 Index Points for Point in Geometry\n",
    "    h3_index_gdf = pd.DataFrame(\n",
    "        {\n",
    "            \"h3_index\": unique_children,\n",
    "            \"latlong\": [h3.cell_to_latlng(cell) for cell in unique_children],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Build GeoDataFrame\n",
    "    geometry = [\n",
    "        Point(xy)\n",
    "        for xy in zip(\n",
    "            h3_index_gdf[\"latlong\"].str[1],\n",
    "            h3_index_gdf[\"latlong\"].str[0],\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    h3_index_gdf = gpd.GeoDataFrame(h3_index_gdf, geometry=geometry, crs=\"EPSG:4326\")\n",
    "    h3_index_gdf = h3_index_gdf.clip(poly_area.buffer(0.01))\n",
    "\n",
    "    return h3_index_gdf\n",
    "\n",
    "\n",
    "# Build Polygons for H3 List\n",
    "def build_polygons_for_h3_list(h3_index):\n",
    "    # Build H3 Grid\n",
    "    h3_gdf = gpd.GeoDataFrame(\n",
    "        {\n",
    "            \"h3_index\": h3_index,\n",
    "            \"geometry\": [h3_to_polygon(h) for h in h3_index],\n",
    "        },\n",
    "        crs=\"EPSG:4326\",\n",
    "    )\n",
    "\n",
    "    # Ensure they Overlap with Polygon Area\n",
    "    print(\"Total Cells:\", len(h3_gdf))\n",
    "\n",
    "    return h3_gdf\n",
    "\n",
    "\n",
    "def get_date_range(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Returns a list of date objects between start_date and end_date (inclusive).\n",
    "    start_date and end_date can be datetime.date objects or 'YYYY-MM-DD' strings.\n",
    "    \"\"\"\n",
    "    # Convert strings to date objects if needed\n",
    "    if isinstance(start_date, str):\n",
    "        start_date = date.fromisoformat(start_date)\n",
    "    if isinstance(end_date, str):\n",
    "        end_date = date.fromisoformat(end_date)\n",
    "\n",
    "    if start_date > end_date:\n",
    "        raise ValueError(\"start_date must be before or equal to end_date\")\n",
    "\n",
    "    delta = (end_date - start_date).days\n",
    "    return [start_date + timedelta(days=i) for i in range(delta + 1)]\n",
    "\n",
    "\n",
    "#                                           #\n",
    "# ----------------------------------------- #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212cbdcf",
   "metadata": {},
   "source": [
    "# Orca Presence Model - Baseline Models\n",
    "\n",
    "<b>POC:</b>Tyler Stevenson <br>\n",
    "<b>LAST MODIFIED:</b>2025-08-12 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bf77d8",
   "metadata": {},
   "source": [
    "## Data + Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0e8658",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Paths\n",
    "sightings_path = \"../data/processed/ORCA_SIGHTINGS/ORCA_SIGHTINGS.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ea5f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Resolution\n",
    "h3_resolution = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5e4003",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CLIP TO JUST OREGON + PUGET SOUND\n",
    "\n",
    "# Bounding box coordinates covering Puget Sound + Salish Sea\n",
    "min_lon, min_lat = -126.3, 44.0  # southwest corner (offshore west of Port Angeles)\n",
    "max_lon, max_lat = -121.5, 51.3  # northeast corner (north of Vancouver)\n",
    "\n",
    "# Create bounding box polygon\n",
    "bbox = box(min_lon, min_lat, max_lon, max_lat)\n",
    "\n",
    "# Make GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame({\"geometry\": [bbox]}, crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462047ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Sightings Data\n",
    "sightings = open_sightings(path=sightings_path)\n",
    "\n",
    "# Preprocess Sightings - Remove Spurious Data\n",
    "sightings[\"LONGITUDE\"] = np.where(\n",
    "    sightings[\"LONGITUDE\"] > 0, sightings[\"LONGITUDE\"] * -1, sightings[\"LONGITUDE\"]\n",
    ")\n",
    "sightings = sightings[(sightings[\"LONGITUDE\"] < -115) & (sightings[\"LONGITUDE\"] > -160)]\n",
    "\n",
    "geometry = [\n",
    "    Point(xy)\n",
    "    for xy in zip(\n",
    "        sightings[\"LONGITUDE\"],\n",
    "        sightings[\"LATITUDE\"],\n",
    "    )\n",
    "]\n",
    "# Build GeoDataFrame\n",
    "sightings = gpd.GeoDataFrame(sightings, geometry=geometry, crs=\"EPSG:4326\")\n",
    "\n",
    "# Clip to AOI\n",
    "sightings = sightings.clip(gdf)\n",
    "\n",
    "# Add H3 Index\n",
    "sightings[\"h3_index\"] = sightings.apply(\n",
    "    lambda x: h3.latlng_to_cell(x[\"LATITUDE\"], x[\"LONGITUDE\"], h3_resolution), axis=1\n",
    ")\n",
    "\n",
    "# Drop Unecessary Features\n",
    "sightings = sightings.drop(\n",
    "    columns=[\n",
    "        \"DATE\",\n",
    "        \"DATETIME\",\n",
    "        \"YEAR_MONTH\",\n",
    "        \"STAT_WEEK_SUNDAY\",\n",
    "        \"geometry\",\n",
    "        \"YEAR_WEEK\",\n",
    "        \"LATITUDE\",\n",
    "        \"LONGITUDE\",\n",
    "        \"SOURCE\",\n",
    "        \"COUNT\",\n",
    "    ],\n",
    "    errors=\"ignore\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1d9012",
   "metadata": {},
   "outputs": [],
   "source": [
    "sightings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aed50f5",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b614e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for SRKW\n",
    "sightings = sightings[sightings[\"POD_TYPE\"] == \"SRKW\"].copy()\n",
    "sightings = sightings[[\"DOY\", \"WOY\", \"MONTH\", \"YEAR\", \"h3_index\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ac55e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure All Dates Exist\n",
    "all_years = sightings[\"YEAR\"].unique().tolist()\n",
    "all_doy = list(range(1, 366))\n",
    "\n",
    "all_sightings_merge = sightings[[\"h3_index\"]].drop_duplicates()\n",
    "all_sightings_merge[\"YEAR\"] = all_sightings_merge.apply(lambda x: all_years, axis=1)\n",
    "all_sightings_merge = all_sightings_merge.explode(\"YEAR\")\n",
    "\n",
    "all_sightings_merge[\"DOY\"] = all_sightings_merge.apply(lambda x: all_doy, axis=1)\n",
    "all_sightings_merge = all_sightings_merge.explode(\"DOY\")\n",
    "\n",
    "wm = sightings[[\"DOY\", \"WOY\", \"MONTH\"]].drop_duplicates()\n",
    "all_sightings_merge = pd.merge(all_sightings_merge, wm, how=\"left\")\n",
    "\n",
    "sightings[\"COUNT\"] = 1\n",
    "sightings = pd.merge(all_sightings_merge, sightings, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09671df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sightings[\"COUNT\"] = sightings[\"COUNT\"].fillna(0)\n",
    "sightings[\"DOY\"] = sightings[\"DOY\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0738ebe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd8ff83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Features\n",
    "\n",
    "# Temporal Features:\n",
    "## DOY (sin/cos transformed for cyclicality):\n",
    "sightings[\"DOY_sin\"] = np.sin(2 * np.pi * sightings[\"DOY\"] / 365.25)\n",
    "sightings[\"DOY_cos\"] = np.cos(2 * np.pi * sightings[\"DOY\"] / 365.25)\n",
    "\n",
    "sightings[\"sighting\"] = np.where(sightings[\"COUNT\"] == 0, 0, 1)\n",
    "srkw_df = sightings.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3fc120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale and Encode Fatures\n",
    "# Define preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), [\"DOY_sin\", \"DOY_cos\", \"YEAR\"]),\n",
    "        (\n",
    "            \"cat\",\n",
    "            OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True),\n",
    "            [\"h3_index\"],\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545bab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61169f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target\n",
    "X = srkw_df[\n",
    "    [\n",
    "        \"DOY_sin\",\n",
    "        \"DOY_cos\",\n",
    "        \"YEAR\",\n",
    "        \"h3_index\",\n",
    "    ]\n",
    "]\n",
    "y = srkw_df[\"sighting\"]\n",
    "\n",
    "# Train-test split (chronological, e.g., test on 2024â€“2025)\n",
    "train_idx = srkw_df[\"YEAR\"] < 2023\n",
    "test_idx = srkw_df[\"YEAR\"] >= 2023\n",
    "X_train, X_test = X[train_idx], X[test_idx]\n",
    "y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "# Pipeline\n",
    "model = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            LogisticRegression(max_iter=1000, random_state=42, class_weight=\"balanced\"),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "print(\"SRKW AUC-ROC:\", roc_auc_score(y_test, y_pred_proba))\n",
    "print(\"SRKW F1-Score:\", f1_score(y_test, y_pred_proba > 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ac6ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c474e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(srkw_df['sighting'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8de05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prediction DataFrame\n",
    "future_days1 = pd.DataFrame({\"DOY\": range(1, 366), \"YEAR\": 2023})\n",
    "future_days1[\"DOY_sin\"] = np.sin(2 * np.pi * future_days1[\"DOY\"] / 365.25)\n",
    "future_days1[\"DOY_cos\"] = np.cos(2 * np.pi * future_days1[\"DOY\"] / 365.25)\n",
    "\n",
    "future_days2 = pd.DataFrame({\"DOY\": range(1, 366), \"YEAR\": 2024})\n",
    "future_days2[\"DOY_sin\"] = np.sin(2 * np.pi * future_days2[\"DOY\"] / 365.25)\n",
    "future_days2[\"DOY_cos\"] = np.cos(2 * np.pi * future_days2[\"DOY\"] / 365.25)\n",
    "\n",
    "future_days3 = pd.DataFrame({\"DOY\": range(1, 366), \"YEAR\": 2025})\n",
    "future_days3[\"DOY_sin\"] = np.sin(2 * np.pi * future_days3[\"DOY\"] / 365.25)\n",
    "future_days3[\"DOY_cos\"] = np.cos(2 * np.pi * future_days3[\"DOY\"] / 365.25)\n",
    "\n",
    "future_days = pd.concat([future_days1, future_days2, future_days3])\n",
    "\n",
    "h3_cells = sightings.h3_index.unique().tolist()\n",
    "future_days[\"h3_index\"] = future_days.apply(lambda x: h3_cells, axis=1)\n",
    "future_days = future_days.explode(\"h3_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e17f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross with all H3 cells\n",
    "pred_df = future_days\n",
    "\n",
    "# Predict probabilities\n",
    "pred_df[\"prob_SRKW\"] = model.predict_proba(pred_df)[:, 1]\n",
    "\n",
    "# Aggregate by H3 cell (average probability over 7 days)\n",
    "# pred_df = pred_df.groupby(\"h3_index\")[\"prob_SRKW\"].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c8c94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.merge(pred_df, sightings[test_idx], how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422d438f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36b9216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "\n",
    "# fig = px.scatter(tmp, x=\"sighting\", y=\"prob_SRKW\")\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2df5fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb0d285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2100fbcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salmonsignal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
