{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "99aa7a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------- #\n",
    "#                  MODULES                  #\n",
    "\n",
    "# Standard Modules\n",
    "import os\n",
    "import warnings\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Third-Party Modules\n",
    "import geopandas as gpd\n",
    "import h3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import rasterio.features\n",
    "import rioxarray\n",
    "from shapely.geometry import box, Point, Polygon\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import rasterio.features\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon\n",
    "from joblib import Parallel, delayed\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import h3\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# System Configuration\n",
    "parallel = Parallel(n_jobs=8)\n",
    "\n",
    "#                                           #\n",
    "# ----------------------------------------- #\n",
    "\n",
    "# ----------------------------------------- #\n",
    "#                 FUNCTIONS                 #\n",
    "\n",
    "\n",
    "# Open Data\n",
    "def open_geotiff(\n",
    "    path,\n",
    "    data_crs=\"EPSG:4326\",\n",
    "    desired_crs=\"EPSG:4326\",\n",
    "    mask_upper_data=False,\n",
    "    mask_lower_data=False,\n",
    "    mask_upper_val=None,\n",
    "    mask_lower_val=None,\n",
    "):\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"WARNING: Path does not exist - {path}\")\n",
    "        return None\n",
    "    else:\n",
    "        # Open Data\n",
    "        da = rioxarray.open_rasterio(path)\n",
    "\n",
    "        # Filter Data to Sea Level\n",
    "        if mask_upper_data:\n",
    "            da = xr.where(da > mask_upper_val, mask_upper_val, da)\n",
    "        if mask_lower_data:\n",
    "            da = xr.where(da < mask_upper_val, mask_lower_val, da)\n",
    "\n",
    "        # Set CRS (example: WGS84 EPSG:4326)\n",
    "        if da.rio.crs == None:\n",
    "            da = da.rio.write_crs(data_crs)\n",
    "\n",
    "        else:\n",
    "            # reproject CRS\n",
    "            print(\"need to add a crs reprojection\", da.rio.crs, \"->\", desired_crs)\n",
    "            # TODO: reproject to provided crs\n",
    "\n",
    "        return da\n",
    "\n",
    "\n",
    "# Open Water Region Polygon\n",
    "def open_water_polygon_aoi(path, data_crs=\"EPSG:4326\"):\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"WARNING: Path does not exist - {path}\")\n",
    "        return None\n",
    "    else:\n",
    "        # Open Polygon\n",
    "        polygon_area = gpd.read_parquet(path)\n",
    "\n",
    "        # Dissolve Geometry\n",
    "        polygon_area = polygon_area.dissolve()\n",
    "\n",
    "        # Enforce Projection\n",
    "        polygon_area = polygon_area.to_crs(data_crs)\n",
    "\n",
    "        return polygon_area\n",
    "\n",
    "\n",
    "# Clip Raster Data to AOI\n",
    "def clip_raster_to_aoi(da, poly_data):\n",
    "    da_clipped = da.rio.clip(\n",
    "        poly_data.geometry,  # geometry column\n",
    "        poly_data.crs,  # CRS of the geometry\n",
    "        all_touched=True,  # include partial pixels\n",
    "        drop=True,  # drop pixels outside\n",
    "    )\n",
    "    return da_clipped\n",
    "\n",
    "\n",
    "# Clip Polygon to Bounds\n",
    "def clip_poly_to_data_bounds(da, poly_data):\n",
    "    # Your bounds (min_lon, min_lat, max_lon, max_lat)\n",
    "    da_bounds = da.rio.bounds()\n",
    "\n",
    "    # Create shapely box (polygon)\n",
    "    polygon = box(*da_bounds)\n",
    "\n",
    "    # Make GeoDataFrame\n",
    "    bounds_gdf = gpd.GeoDataFrame({\"geometry\": [polygon]}, crs=\"EPSG:4326\")\n",
    "\n",
    "    # Clip Polygon Data\n",
    "    poly_data = poly_data.clip(bounds_gdf)\n",
    "\n",
    "    # Subset to Geometry\n",
    "    poly_data = poly_data[[\"geometry\"]]\n",
    "\n",
    "    return poly_data\n",
    "\n",
    "\n",
    "# Geometry Point to H3 Grid\n",
    "def point_to_h3(point, res):\n",
    "    # point: shapely Point geometry\n",
    "    return h3.latlng_to_cell(point.y, point.x, res)\n",
    "\n",
    "\n",
    "# H3 Grid to Polygon\n",
    "def h3_to_polygon(h3_index):\n",
    "    boundary = h3.cell_to_boundary(h3_index)\n",
    "    boundary_lonlat = [(lon, lat) for lat, lon in boundary]\n",
    "    return Polygon(boundary_lonlat)\n",
    "\n",
    "\n",
    "# Identify All H3 Grids in Polygon\n",
    "def get_all_h3_cells(poly_area, target_resolution=5):\n",
    "    # Original Polygon Area\n",
    "    poly_area_orig = poly_area.copy()\n",
    "\n",
    "    # Explode Geometries\n",
    "    poly_area = poly_area.explode()\n",
    "    poly_area[\"geometry\"] = poly_area.buffer(0.2)\n",
    "\n",
    "    h3_grids = []\n",
    "    for geometry_val in poly_area[\"geometry\"]:\n",
    "        # For each polygon geometry (Multi/Poly)\n",
    "        hex_ids = h3.geo_to_cells(geometry_val, res=target_resolution)\n",
    "\n",
    "        h3_grids.extend(hex_ids)\n",
    "\n",
    "    # Get Unique Grids\n",
    "    h3_grids = np.unique(h3_grids)\n",
    "\n",
    "    # Build H3 Grid\n",
    "    h3_gdf = gpd.GeoDataFrame(\n",
    "        {\n",
    "            \"h3_index\": h3_grids,\n",
    "            \"geometry\": [h3_to_polygon(h) for h in h3_grids],\n",
    "        },\n",
    "        crs=\"EPSG:4326\",\n",
    "    )\n",
    "\n",
    "    # Ensure they Overlap with Polygon Area\n",
    "    h3_gdf_clipped = h3_gdf.clip(poly_area_orig)\n",
    "    h3_gdf = h3_gdf[h3_gdf.h3_index.isin(h3_gdf_clipped.h3_index)]\n",
    "    print(\"Total Cells:\", len(h3_gdf))\n",
    "\n",
    "    return h3_gdf, h3_gdf_clipped\n",
    "\n",
    "\n",
    "# Vectorized Polygon Extract\n",
    "def polygon_stats_vectorized(\n",
    "    da: xr.DataArray, gdf: gpd.GeoDataFrame\n",
    ") -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Compute descriptive statistics (min, max, mean, median, std) for raster data within polygons.\n",
    "\n",
    "    Parameters:\n",
    "    - da: xarray.DataArray with raster data (must have rio.crs and rio.transform)\n",
    "    - gdf: geopandas.GeoDataFrame with polygon geometries\n",
    "\n",
    "    Returns:\n",
    "    - gpd.GeoDataFrame: Input GeoDataFrame with added columns for min, max, mean, median, and std\n",
    "    \"\"\"\n",
    "\n",
    "    # Validate inputs\n",
    "    if not hasattr(da, \"rio\") or da.rio.crs is None:\n",
    "        raise ValueError(\"Input DataArray must have a valid CRS\")\n",
    "    if gdf.crs is None:\n",
    "        raise ValueError(\"Input GeoDataFrame must have a valid CRS\")\n",
    "    if not all(gdf.geometry.is_valid):\n",
    "        raise ValueError(\"GeoDataFrame contains invalid geometries\")\n",
    "\n",
    "    # Ensure CRS match\n",
    "    if da.rio.crs != gdf.crs:\n",
    "        gdf = gdf.to_crs(da.rio.crs)\n",
    "\n",
    "    # Rasterize polygons with unique IDs\n",
    "    shapes = ((geom, idx) for idx, geom in enumerate(gdf.geometry))\n",
    "    mask = rasterio.features.rasterize(\n",
    "        shapes,\n",
    "        out_shape=(da.rio.height, da.rio.width),\n",
    "        transform=da.rio.transform(),\n",
    "        fill=-1,  # Mark areas outside polygons\n",
    "        all_touched=True,\n",
    "        dtype=np.int32,\n",
    "    )\n",
    "\n",
    "    # Flatten raster and mask\n",
    "    data_flat = da.values.ravel()\n",
    "    mask_flat = mask.ravel()\n",
    "\n",
    "    # Filter valid pixels (exclude nodata and non-polygon areas)\n",
    "    valid = (mask_flat >= 0) & np.isfinite(data_flat)\n",
    "    if not np.any(valid):\n",
    "        raise ValueError(\"No valid pixels found in the raster for any polygon\")\n",
    "\n",
    "    data_flat = data_flat[valid]\n",
    "    mask_flat = mask_flat[valid]\n",
    "\n",
    "    # Sort by polygon ID for efficient grouping\n",
    "    order = np.argsort(mask_flat)\n",
    "    data_flat = data_flat[order]\n",
    "    mask_flat = mask_flat[order]\n",
    "\n",
    "    # Find group boundaries\n",
    "    unique_ids, idx_start = np.unique(mask_flat, return_index=True)\n",
    "    idx_end = np.r_[idx_start[1:], len(mask_flat)]\n",
    "\n",
    "    # Initialize stats arrays\n",
    "    n_polygons = len(gdf)\n",
    "    mins = np.full(n_polygons, np.nan)\n",
    "    maxs = np.full(n_polygons, np.nan)\n",
    "    means = np.full(n_polygons, np.nan)\n",
    "    medians = np.full(n_polygons, np.nan)\n",
    "    stds = np.full(n_polygons, np.nan)\n",
    "\n",
    "    # Compute stats for polygons with valid pixels\n",
    "    valid_indices = np.arange(len(unique_ids))\n",
    "    mins[unique_ids] = np.minimum.reduceat(data_flat, idx_start)\n",
    "    maxs[unique_ids] = np.maximum.reduceat(data_flat, idx_start)\n",
    "    means[unique_ids] = np.add.reduceat(data_flat, idx_start) / (idx_end - idx_start)\n",
    "    medians[unique_ids] = [\n",
    "        np.median(data_flat[s:e]) for s, e in zip(idx_start, idx_end)\n",
    "    ]\n",
    "    stds[unique_ids] = [\n",
    "        np.std(data_flat[s:e], ddof=0) for s, e in zip(idx_start, idx_end)\n",
    "    ]\n",
    "\n",
    "    # Assemble DataFrame\n",
    "    stats_df = pd.DataFrame(\n",
    "        {\"min\": mins, \"max\": maxs, \"mean\": means, \"median\": medians, \"std\": stds}\n",
    "    )\n",
    "\n",
    "    # Join stats to GeoDataFrame\n",
    "    return gdf.reset_index(drop=True).join(stats_df)\n",
    "\n",
    "\n",
    "#                                           #\n",
    "# ----------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e52ea39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Water Polygon Path\n",
    "water_poly_path = \"../../../data/processed/GIS/ocean/TERRITORIAL_WATERS.parquet\"\n",
    "\n",
    "# Data Sourced from GEBCO_2025 - https://download.gebco.net\n",
    "raster_path = \"../../../data/raw/bathymetry/GEBCO_12_Aug_2025_e9cdc1fe517e/gebco_2025_n54.524_s33.96_w-130.0_e-120.0.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d187629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Water Region Polygon\n",
    "water_poly = open_water_polygon_aoi(water_poly_path, data_crs=\"EPSG:4326\")\n",
    "\n",
    "# Open GeoTiff\n",
    "da = open_geotiff(\n",
    "    raster_path, data_crs=\"EPSG:4326\", mask_upper_data=True, mask_upper_val=0\n",
    ")\n",
    "\n",
    "# Clip AOI to Polygon AOI\n",
    "da_clipped = clip_raster_to_aoi(da=da, poly_data=water_poly)\n",
    "\n",
    "# Clip Polygon to Bounds of Data Array\n",
    "water_poly = clip_poly_to_data_bounds(da=da_clipped, poly_data=water_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ea0b786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desired Resolution\n",
    "desired_resolution = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b8275b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def h3_from_single_polygon(polygon, res=5):\n",
    "    return list(h3.geo_to_cells(polygon, res=res))\n",
    "\n",
    "\n",
    "def get_all_h3_cells(poly_area, target_resolution=5, n_jobs=-1):\n",
    "    # Explode multipolygons to single polygons\n",
    "    poly_area = poly_area.explode(ignore_index=True)\n",
    "    print(\"...Exploded Polygon\")\n",
    "\n",
    "    # Optional: tiny buffer if needed\n",
    "    poly_area[\"geometry\"] = poly_area[\"geometry\"].buffer(0.0)\n",
    "    poly_area[\"geometry\"] = poly_area[\"geometry\"].buffer(0.1)\n",
    "    print(\"...Buffered Geometry\")\n",
    "\n",
    "    # Parallel processing for speed\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(h3_from_single_polygon)(geom, target_resolution)\n",
    "        for geom in poly_area[\"geometry\"]\n",
    "    )\n",
    "    print(\"...Collected H3 Grids\")\n",
    "\n",
    "    # Flatten list and deduplicate\n",
    "    h3_ids = np.unique([h for sublist in results for h in sublist])\n",
    "\n",
    "    # Convert H3 cells to polygons\n",
    "    h3_polys = [Polygon(h3_to_polygon(h)) for h in h3_ids]\n",
    "    print(\"...Built Polygons\")\n",
    "\n",
    "    # Build GeoDataFrame\n",
    "    h3_gdf = gpd.GeoDataFrame(\n",
    "        {\"h3_index\": h3_ids, \"geometry\": h3_polys}, crs=\"EPSG:4326\"\n",
    "    )\n",
    "\n",
    "    # Clip to original area to remove fringe cells\n",
    "    h3_gdf_clipped = h3_gdf.clip(poly_area)\n",
    "    print(\"...Clipped to Bounding Area\")\n",
    "\n",
    "    h3_gdf = h3_gdf[h3_gdf.h3_index.isin(h3_gdf_clipped.h3_index)]\n",
    "    print(\"...Filtered Cells\")\n",
    "    print()\n",
    "    print(\"Total Cells:\", len(h3_gdf))\n",
    "    return h3_gdf, h3_gdf_clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b843df5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Exploded Polygon\n",
      "...Buffered Geometry\n",
      "...Collected H3 Grids\n",
      "...Built Polygons\n",
      "...Clipped to Bounding Area\n",
      "...Filtered Cells\n",
      "\n",
      "Total Cells: 7431\n"
     ]
    }
   ],
   "source": [
    "# Get All H3 Polygons\n",
    "h3_water_poly, h3_water_poly_clipped = get_all_h3_cells(\n",
    "    poly_area=water_poly, target_resolution=desired_resolution, n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dcddec84",
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_water_poly_clipped.explore().save(\"test.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cfe525c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Polygon Statistics for H3 Grid\n",
    "poly_stats_vectorized = polygon_stats_vectorized(\n",
    "    da=da_clipped, gdf=h3_water_poly_clipped\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cd3bb941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign to Full H3 Poly\n",
    "poly_stats_vectorized = poly_stats_vectorized.drop(columns=\"geometry\")\n",
    "\n",
    "poly_stats_vectorized = pd.merge(poly_stats_vectorized, h3_water_poly, how=\"left\")\n",
    "poly_stats_vectorized[\"mean\"] = poly_stats_vectorized[\"mean\"].fillna(-9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b1c04567",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_stats_vectorized = gpd.GeoDataFrame(\n",
    "    poly_stats_vectorized, geometry=\"geometry\", crs=\"EPSG:4326\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "808eee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_stats_vectorized.dropna(subset=[\"mean\", \"geometry\"]).explore(\n",
    "    \"mean\", cmap=\"Blues_r\", vmin=-200, vmax=0  # ocean is a good cmap too\n",
    ").save(f\"gebco_bathymetry_{desired_resolution}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b5e4206a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to File\n",
    "poly_stats_vectorized.to_parquet(\n",
    "    f\"../../../data/processed/GIS/GEBCO_BATHEYMETRY_{desired_resolution}.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9409030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd3c724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f60f5d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff91bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_water_poly_clipped_ea = h3_water_poly_clipped.copy()\n",
    "h3_water_poly_clipped_ea[\"clipped_area\"] = h3_water_poly_clipped_ea.area\n",
    "h3_water_poly_clipped_ea = h3_water_poly_clipped_ea[[\"h3_index\", \"clipped_area\"]]\n",
    "\n",
    "h3_water_poly_unclipped = h3_water_poly.copy()\n",
    "h3_water_poly_unclipped[\"unclipped_area\"] = h3_water_poly_unclipped.area\n",
    "h3_water_poly_unclipped = h3_water_poly_unclipped[[\"h3_index\", \"unclipped_area\"]]\n",
    "\n",
    "tmp = pd.merge(h3_water_poly_clipped_ea, h3_water_poly_unclipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d07ab314",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[\"water_covers\"] = tmp[\"clipped_area\"] / tmp[\"unclipped_area\"]\n",
    "\n",
    "h3_water_poly_covers = pd.merge(h3_water_poly, tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b972090",
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_water_poly_covers.dropna(subset=[\"water_covers\", \"geometry\"]).explore(\n",
    "    \"water_covers\",\n",
    "    cmap=\"turbo\",\n",
    ").save(\"area_coverage.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9384e1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_water_poly_covers = h3_water_poly_covers[[\"h3_index\", \"geometry\", \"water_covers\"]]\n",
    "h3_water_poly_covers[\"water_covers\"] = round(h3_water_poly_covers[\"water_covers\"], 5)\n",
    "h3_water_poly_covers[\"H3_RESOLUTION\"] = desired_resolution\n",
    "h3_water_poly_covers.to_parquet(\n",
    "    f\"../../../data/processed/GIS/H3_{desired_resolution}_Polygons_With_Water_Coverage.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9ee6a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1cc86df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute distance to shelf break by deriving a contour on a depth threshold (e.g., 200 m) and computing H3-cell distance to that contour. shelf break proximity = killer covariate.\n",
    "# compute BPI (bathymetric position index) to detect depressions/ridges (use whitebox or scipy filters).\n",
    "# add seafloor substrate layers if available (gravel/mud/rock) — very useful for some prey.\n",
    "# compute bathymetric complexity at multiple scales (3×3 window, 25×25 window) and include both as covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a3720a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca16774f",
   "metadata": {},
   "source": [
    "1. NOAA National Centers for Environmental Information (NCEI)\n",
    "Bathymetry Data Viewer has REST-like endpoints behind it, but the public docs focus on downloads.\n",
    "Direct API for their netCDF/GeoTIFF products isn’t super public, but you can grab prebuilt rasters via:\n",
    "ERDDAP servers (many NOAA datasets, bathy included)\n",
    "Example: https://coastwatch.pfeg.noaa.gov/erddap/griddap/\n",
    "Lets you query depth by bounding box, depth variable = altitude or z.\n",
    "NCEI also serves Coastal Relief Models (CRM) as OPeNDAP / WCS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8021c196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae4a44e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765e3db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polygon_stats_from_rioxarray(da: xr.DataArray, gdf: gpd.GeoDataFrame):\n",
    "#     \"\"\"\n",
    "#     Compute min, max, mean, median, std for each polygon in gdf from a rioxarray.DataArray.\n",
    "\n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     da : rioxarray.DataArray\n",
    "#         Raster data array with georeferencing\n",
    "#     gdf : geopandas.GeoDataFrame\n",
    "#         Polygons to compute stats for (must have geometry column)\n",
    "\n",
    "#     Returns:\n",
    "#     --------\n",
    "#     pandas.DataFrame : gdf with columns added for stats\n",
    "#     \"\"\"\n",
    "#     # Ensure CRS match\n",
    "#     if da.rio.crs != gdf.crs:\n",
    "#         gdf = gdf.to_crs(da.rio.crs)\n",
    "\n",
    "#     # Rasterize all polygons at once\n",
    "#     shapes = ((geom, i) for i, geom in enumerate(gdf.geometry))\n",
    "#     mask = rasterio.features.rasterize(\n",
    "#         shapes,\n",
    "#         out_shape=(da.rio.height, da.rio.width),\n",
    "#         transform=da.rio.transform(),\n",
    "#         fill=-1,\n",
    "#         all_touched=True,\n",
    "#         dtype=int,\n",
    "#     )\n",
    "\n",
    "#     mask_da = xr.DataArray(mask, coords=[da.y, da.x], dims=[\"y\", \"x\"])\n",
    "\n",
    "#     # Flatten to vectors for fast masking\n",
    "#     da_flat = da.values.flatten()\n",
    "#     mask_flat = mask_da.values.flatten()\n",
    "\n",
    "#     results = []\n",
    "#     for i in range(len(gdf)):\n",
    "#         vals = da_flat[mask_flat == i]\n",
    "#         vals = vals[~np.isnan(vals)]  # ignore nodata\n",
    "#         if len(vals) == 0:\n",
    "#             stats_dict = dict(\n",
    "#                 min=np.nan, max=np.nan, mean=np.nan, median=np.nan, std=np.nan\n",
    "#             )\n",
    "#         else:\n",
    "#             stats_dict = dict(\n",
    "#                 min=float(vals.min()),\n",
    "#                 max=float(vals.max()),\n",
    "#                 mean=float(vals.mean()),\n",
    "#                 median=float(np.median(vals)),\n",
    "#                 std=float(vals.std()),\n",
    "#             )\n",
    "#         results.append(stats_dict)\n",
    "\n",
    "#     stats_df = pd.DataFrame(results)\n",
    "#     return gdf.reset_index(drop=True).join(stats_df)\n",
    "\n",
    "# # Get Polygon Stats for H3 Grids\n",
    "# poly_stats = polygon_stats_from_rioxarray(da=da_clipped, gdf=h3_water_poly)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salmonsignal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
