{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140be542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Modules\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import swifter\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.data_functions import load_sightings_data, add_features_sightings_data\n",
    "\n",
    "\n",
    "def plot_confusion_matrix_plotly(y_true, y_pred, labels=None, normalize=False):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm = np.round(cm, 2)\n",
    "\n",
    "    if labels is None:\n",
    "        labels = sorted(list(set(y_true) | set(y_pred)))\n",
    "\n",
    "    cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "\n",
    "    fig = px.imshow(\n",
    "        cm_df,\n",
    "        text_auto=True,\n",
    "        color_continuous_scale=\"Reds\",\n",
    "        aspect=\"auto\",\n",
    "        labels=dict(x=\"Predicted\", y=\"Actual\", color=\"Count\"),\n",
    "    )\n",
    "\n",
    "    fig.update_xaxes(side=\"top\")\n",
    "    fig.update_layout(title=\"Confusion Matrix\", font=dict(size=14))\n",
    "\n",
    "    return fig, cm\n",
    "\n",
    "\n",
    "def plot_classification_report(classification_metrics):\n",
    "\n",
    "    fig = px.line(title=\"Classification Metrics at Different Thresholds\")\n",
    "    fig.add_scatter(\n",
    "        x=classification_metrics[\"THRESHOLD\"],\n",
    "        y=classification_metrics[\"ACCURACY\"],\n",
    "        name=\"Accuracy\",\n",
    "        marker_color=\"#ff006e\",\n",
    "    )\n",
    "    fig.add_scatter(\n",
    "        x=classification_metrics[\"THRESHOLD\"],\n",
    "        y=classification_metrics[\"PRECISION\"],\n",
    "        name=\"Precision\",\n",
    "        marker_color=\"#8338ec\",\n",
    "    )\n",
    "    fig.add_scatter(\n",
    "        x=classification_metrics[\"THRESHOLD\"],\n",
    "        y=classification_metrics[\"RECALL\"],\n",
    "        name=\"Recall\",\n",
    "        marker_color=\"#3a86ff\",\n",
    "    )\n",
    "    fig.add_scatter(\n",
    "        x=classification_metrics[\"THRESHOLD\"],\n",
    "        y=classification_metrics[\"F1\"],\n",
    "        name=\"F1 Score\",\n",
    "        marker_color=\"#ffbe0b\",\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "def threshold_metrics_plot(y_true, y_proba, steps=100):\n",
    "    thresholds = np.linspace(0, 1, steps)\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    accuracies = []\n",
    "\n",
    "    for t in tqdm(thresholds):\n",
    "        y_pred = (y_proba >= t).astype(int)\n",
    "        precisions.append(precision_score(y_true, y_pred, zero_division=0))\n",
    "        recalls.append(recall_score(y_true, y_pred))\n",
    "        f1s.append(f1_score(y_true, y_pred))\n",
    "        accuracies.append(accuracy_score(y_true, y_pred))\n",
    "\n",
    "    threshold_lookup = pd.DataFrame(\n",
    "        {\n",
    "            \"THRESHOLD\": thresholds,\n",
    "            \"ACCURACY\": accuracies,\n",
    "            \"PRECISION\": precisions,\n",
    "            \"RECALL\": recalls,\n",
    "            \"F1\": f1s,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return threshold_lookup\n",
    "\n",
    "\n",
    "def plot_threshold_metrics(df, min_precision=0.4):\n",
    "    max_possible_precision = df[\"PRECISION\"].max()\n",
    "\n",
    "    # Adjust min_precision if it's too high\n",
    "    if min_precision > max_possible_precision:\n",
    "        print(\n",
    "            f\"⚠️ Requested min_precision={min_precision} \"\n",
    "            f\"is higher than max precision={max_possible_precision:.3f}. Lowering requirement.\"\n",
    "        )\n",
    "        min_precision = max_possible_precision\n",
    "\n",
    "    # Filter rows that meet min precision requirement\n",
    "    valid_df = df[df[\"PRECISION\"] >= min_precision]\n",
    "\n",
    "    if not valid_df.empty:\n",
    "        best_row = valid_df.loc[valid_df[\"RECALL\"].idxmax()]\n",
    "    else:\n",
    "        best_row = df.loc[df[\"RECALL\"].idxmax()]  # fallback: max recall\n",
    "\n",
    "    best_threshold = best_row[\"THRESHOLD\"]\n",
    "\n",
    "    return best_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56d5e37",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Paths + Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63765d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "SIGHTINGS_PATH = (\n",
    "    \"../../data/processed/ORCA_SIGHTINGS/ORCA_SIGHTINGS.parquet\"  # Data Paths\n",
    ")\n",
    "H3_RESOLUTION = 5  # Target Resolution\n",
    "START_DATE = None  # Optional: set start date for generating absence rows\n",
    "END_DATE = None  # Optional: set end date\n",
    "POD_TYPE = \"SRKW\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5964ee8c",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Open Sightings Data and Add Initial Feature Set\n",
    "\n",
    "1. Map lat/lon → configurable low-res H3.\n",
    "2. Aggregate to one row per (H3 cell, date).\n",
    "3. Add report_count, orca_present columns.\n",
    "4. Fill missing dates for all cells.\n",
    "5. Add seasonality encoding (sin/cos of DOY, MONTH, WOY)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14df2499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Sightings Data\n",
    "df_model = load_sightings_data(\n",
    "    SIGHTINGS_PATH, POD_TYPE, H3_RESOLUTION, START_DATE, END_DATE\n",
    ")\n",
    "\n",
    "# Preprocess Data\n",
    "df_model = add_features_sightings_data(df_model)\n",
    "\n",
    "# display(df_model.head())\n",
    "# display(df_model[\"presence\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f2218b",
   "metadata": {},
   "source": [
    "*** \n",
    "\n",
    "## Fit Simple Model - H3 Grid & DOY as Predictions\n",
    "\n",
    "This is to check if there is predictive power in the H3 Grid + Date Combo Alone -> there should be since SRKW whales return to similar locations year-over-year.\n",
    "\n",
    "We will test Logistic Regression and XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7569bf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    ")\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6e407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We Will Split Using Date - Sinc ethis is a Time Series and we may use different kinds of features later\n",
    "split_date = \"2025-01-01\"  # example date for split\n",
    "\n",
    "# 1. Train/Test Split\n",
    "train_idx, test_idx = df_model[\"DATE\"] < split_date, df_model[\"DATE\"] >= split_date\n",
    "\n",
    "# 2. Split Data\n",
    "train, test = df_model[train_idx], df_model[test_idx]\n",
    "\n",
    "# 3. Define Temporal Columns\n",
    "temporal_cols = [\"DOY\", \"DOY_SIN\", \"DOY_COS\"]\n",
    "\n",
    "# 4. Define Categorical Columns for One-Hot Encoding\n",
    "categorical_cols = [\"H3_CELL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d00e5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Fit One-Hot Encoder to Categorical Columns\n",
    "ohe = OneHotEncoder(sparse_output=True, handle_unknown=\"ignore\")\n",
    "h3_sparse = ohe.fit_transform(df_model[categorical_cols])\n",
    "\n",
    "# 2. Standardize Continuous Columns\n",
    "scaler = StandardScaler()\n",
    "X_temporal = scaler.fit_transform(df_model[temporal_cols])\n",
    "\n",
    "# 3. Stack sparse H3 one-hot with dense temporal features\n",
    "X_sparse = sparse.hstack([h3_sparse, X_temporal])\n",
    "\n",
    "# 4. Convert to CSR format (fast row slicing)\n",
    "X_sparse = X_sparse.tocsr()\n",
    "\n",
    "# 5a. Split Train\n",
    "X_train = X_sparse[train_idx.values]\n",
    "y_train = df_model[\"presence\"].loc[train_idx]\n",
    "\n",
    "# 5b. Split Test\n",
    "X_test = X_sparse[test_idx.values]\n",
    "y_test = df_model[\"presence\"].loc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8732119",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "\n",
    "# 1. Fit Models\n",
    "## 1a. Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=1000, class_weight=\"balanced\", n_jobs=-1)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04b717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1b. XGBoost\n",
    "xg_model = XGBClassifier(\n",
    "    n_estimators=500,  # number of trees\n",
    "    learning_rate=0.05,  # step size shrinkage\n",
    "    max_depth=6,  # tree depth\n",
    "    subsample=0.8,  # row sampling\n",
    "    colsample_bytree=0.8,  # feature sampling\n",
    "    scale_pos_weight=(len(y_train) - sum(y_train))\n",
    "    / sum(y_train),  # handle imbalance like class_weight\n",
    "    eval_metric=\"logloss\",  # metric for eval sets\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "xg_model.fit(X_train, y_train)\n",
    "\n",
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eed0ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "\n",
    "# 2a. Evaluate Model - Logistic Regression\n",
    "lr_y_pred = lr_model.predict(X_test)\n",
    "lr_y_proba = lr_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Get Classification Metrics\n",
    "lr_classification_metrics = threshold_metrics_plot(y_test, lr_y_proba, steps=100)\n",
    "\n",
    "# Get Best Threshold Using Recall Balanced by Precision\n",
    "lr_best_threshold = plot_threshold_metrics(lr_classification_metrics, min_precision=0.5)\n",
    "\n",
    "###########################################\n",
    "\n",
    "# 2b. Evaluate Model - XGBoost\n",
    "xg_y_pred = xg_model.predict(X_test)\n",
    "xg_y_proba = xg_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Get Classification Metrics\n",
    "xg_classification_metrics = threshold_metrics_plot(y_test, xg_y_proba, steps=100)\n",
    "\n",
    "# Get Best Threshold Using Recall Balanced by Precision\n",
    "xg_best_threshold = plot_threshold_metrics(xg_classification_metrics, min_precision=0.5)\n",
    "\n",
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84c7fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plot_classification_report(lr_classification_metrics)\n",
    "# fig.add_scatter(x = lr_best_threshold)\n",
    "# fig.show()\n",
    "\n",
    "# lr_y_pred_w_thresh = np.where(lr_y_proba > lr_best_threshold, 1, 0)\n",
    "# fig, cm = plot_confusion_matrix_plotly(\n",
    "#     y_test, lr_y_pred_w_thresh, labels=None, normalize=False\n",
    "# )\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ae6e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xg_y_pred_w_thresh = np.where(xg_y_proba > xg_best_threshold, 1, 0)\n",
    "# fig, cm = plot_confusion_matrix_plotly(\n",
    "#     y_test, xg_y_pred_w_thresh, labels=None, normalize=False\n",
    "# )\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082a8551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00058c8c",
   "metadata": {},
   "source": [
    "*** \n",
    "\n",
    "## What About Isolation Forest? \n",
    "\n",
    "Right now positives are ~0.6% of the dataset.\n",
    "In that regime, even a “balanced” classifier spends most of its energy learning the negative class and basically ignores the positives unless you force it to care.\n",
    "Anomaly detection flips that around — instead of “learn both classes equally,” you learn what “normal” looks like (negatives), then flag things that look different.\n",
    "This is exactly what fraud detection, rare disease screening, and whale detection in sparse conditions do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365b1f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train only on negative class\n",
    "# Ensure boolean mask alignment\n",
    "mask = (y_train == 0).values  # <-- converts to NumPy array\n",
    "X_train_neg = X_train[mask]\n",
    "\n",
    "# Or if X_train is a NumPy array already:\n",
    "X_train_neg = X_train[mask, :]\n",
    "\n",
    "iso = IsolationForest(\n",
    "    n_estimators=200, contamination=0.006, random_state=42  # approximate positive rate\n",
    ")\n",
    "iso.fit(X_train_neg)\n",
    "\n",
    "# Anomaly score (higher = more anomalous)\n",
    "scores = -iso.score_samples(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b5b1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick threshold to match desired recall/precision\n",
    "threshold = np.percentile(scores, 99.4)  # tweak based on desired recall\n",
    "y_pred_anom = (scores >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d075d741",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_anom)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5e7e88",
   "metadata": {},
   "source": [
    "Still not great, our best bet is to do feature engineering...\n",
    "\n",
    "***\n",
    "\n",
    "## Feature Engineering\n",
    "Even simple models benefit from a few extra features. Ideas to start with:\n",
    "- Temporal features: DOY, WOY, MONTH, YEAR (already there), maybe sine/cosine transforms for seasonal cycles.\n",
    "- Lagged presence features: e.g., presence in the same H3 cell 1, 2, 3 days ago. Useful for persistence.\n",
    "- Rolling/aggregated features: 3-day or 7-day rolling sum or mean of sightings per H3 cell.\n",
    "- Neighbor info: later, you can include aggregated presence in neighboring H3 cells to capture spatial autocorrelation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a38e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure data is sorted by H3_CELL and DATE\n",
    "df_model = df_model.sort_values([\"H3_CELL\", \"DATE\"]).reset_index(drop=True)\n",
    "\n",
    "# Lags: presence 1,2,3, 26, 52, 56 days ago\n",
    "lag_days = [1, 2, 3, 7, 13, 26, 52, 56]\n",
    "for lag in lag_days:\n",
    "    df_model[f\"lag_{lag}\"] = df_model.groupby(\"H3_CELL\")[\"presence\"].shift(lag)\n",
    "\n",
    "# Rolling sums: last 3 and 7 days\n",
    "rolling_windows = [3, 7, 14]\n",
    "for window in rolling_windows:\n",
    "    df_model[f\"roll_{window}\"] = (\n",
    "        df_model.groupby(\"H3_CELL\")[\"presence\"]\n",
    "        .shift(1)\n",
    "        .rolling(window=window, min_periods=1)\n",
    "        .sum()\n",
    "    )\n",
    "\n",
    "# Fill NaNs with 0 (first few days have no lag/rolling)\n",
    "lag_roll_cols = [f\"lag_{l}\" for l in lag_days] + [f\"roll_{w}\" for w in rolling_windows]\n",
    "df_model[lag_roll_cols] = df_model[lag_roll_cols].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774e19a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec29ff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Categorical Columns\n",
    "categorical_cols = [\"H3_CELL\", \"MONTH\"]\n",
    "\n",
    "# Identify Temporal Columns\n",
    "temporal_cols = [\n",
    "    \"DOY\",\n",
    "    \"DOW\",\n",
    "    \"WOY\",\n",
    "    \"MONTH\",\n",
    "    \"YEAR\",\n",
    "    \"MONTH_SIN\",\n",
    "    \"MONTH_COS\",\n",
    "    \"DOY_SIN\",\n",
    "    \"DOY_COS\",\n",
    "    \"WOY_SIN\",\n",
    "    \"WOY_COS\",\n",
    "    \"lag_1\",\n",
    "    \"lag_2\",\n",
    "    \"lag_3\",\n",
    "    \"lag_7\",\n",
    "    \"lag_13\",\n",
    "    \"lag_26\",\n",
    "    \"lag_52\",\n",
    "    \"lag_56\",\n",
    "    \"roll_3\",\n",
    "    \"roll_7\",\n",
    "    \"roll_14\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1898df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse one-hot for H3_CELL\n",
    "ohe = OneHotEncoder(sparse_output=True, handle_unknown=\"ignore\")\n",
    "h3_sparse = ohe.fit_transform(df_model[categorical_cols])\n",
    "\n",
    "# Scale temporal features\n",
    "# temporal_cols = [\"DOY\", \"WOY\", \"MONTH\", \"YEAR\"]\n",
    "temporal_cols = [\"DOY\", \"WOY\", \"YEAR\", \"MONTH_SIN\", \"MONTH_COS\", \"DOY_SIN\", \"DOY_COS\"]\n",
    "scaler = StandardScaler()\n",
    "X_temporal = scaler.fit_transform(df_model[temporal_cols])\n",
    "\n",
    "# Combine sparse + temporal + lag/rolling\n",
    "X_dense = df_model[lag_roll_cols].values  # dense numeric\n",
    "X_sparse_full = sparse.hstack([h3_sparse, X_temporal, X_dense])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe5e229",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = df_model[\"DATE\"] < split_date\n",
    "test_idx = df_model[\"DATE\"] >= split_date\n",
    "\n",
    "# Convert to CSR format (fast row slicing)\n",
    "X_sparse_full = X_sparse_full.tocsr()\n",
    "\n",
    "X_train = X_sparse_full[train_idx.values]\n",
    "y_train = df_model[\"presence\"].loc[train_idx]\n",
    "\n",
    "X_test = X_sparse_full[test_idx.values]\n",
    "y_test = df_model[\"presence\"].loc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6961ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1b. XGBoost\n",
    "xg_model = XGBClassifier(\n",
    "    n_estimators=500,  # number of trees\n",
    "    learning_rate=0.05,  # step size shrinkage\n",
    "    max_depth=6,  # tree depth\n",
    "    subsample=0.8,  # row sampling\n",
    "    colsample_bytree=0.8,  # feature sampling\n",
    "    scale_pos_weight=(len(y_train) - sum(y_train))\n",
    "    / sum(y_train),  # handle imbalance like class_weight\n",
    "    eval_metric=\"logloss\",  # metric for eval sets\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "xg_model.fit(X_train, y_train)\n",
    "\n",
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199c8776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_forecast_clean(\n",
    "    model,\n",
    "    df_last,\n",
    "    ohe,\n",
    "    scaler,\n",
    "    lag_roll_cols,\n",
    "    temporal_cols,\n",
    "    h3_col=\"H3_CELL\",\n",
    "    n_days=7,\n",
    "    thresh_=0.5,\n",
    "):\n",
    "\n",
    "    forecasts = []\n",
    "    df_forecast = df_last.copy()\n",
    "\n",
    "    short_lags = [1, 2, 3, 7, 13, 26, 52, 56]\n",
    "    rolling_windows = [3, 7, 14]\n",
    "\n",
    "    for day in range(1, n_days + 1):\n",
    "        # Increment date and update temporal features\n",
    "        df_forecast[\"DATE\"] = df_forecast[\"DATE\"] + pd.Timedelta(days=1)\n",
    "        df_forecast[\"DOY\"] = df_forecast[\"DATE\"].dt.dayofyear\n",
    "        df_forecast[\"WOY\"] = df_forecast[\"DATE\"].dt.isocalendar().week\n",
    "        df_forecast[\"MONTH\"] = df_forecast[\"DATE\"].dt.month\n",
    "        df_forecast[\"YEAR\"] = df_forecast[\"DATE\"].dt.year\n",
    "\n",
    "        df_forecast[\"MONTH_SIN\"] = np.sin(2 * np.pi * df_forecast[\"MONTH\"] / 12)\n",
    "        df_forecast[\"MONTH_COS\"] = np.cos(2 * np.pi * df_forecast[\"MONTH\"] / 12)\n",
    "\n",
    "        df_forecast[\"DOY_SIN\"] = np.sin(2 * np.pi * df_forecast[\"MONTH\"] / 12)\n",
    "        df_forecast[\"DOY_COS\"] = np.cos(2 * np.pi * df_forecast[\"MONTH\"] / 12)\n",
    "\n",
    "        df_forecast[\"WOY_SIN\"] = np.sin(2 * np.pi * df_forecast[\"WOY\"] / 52)\n",
    "        df_forecast[\"WOY_COS\"] = np.cos(2 * np.pi * df_forecast[\"WOY\"] / 52)\n",
    "\n",
    "        # Transform features\n",
    "        X_temporal = scaler.transform(df_forecast[temporal_cols])\n",
    "        h3_sparse = ohe.transform(df_forecast[[h3_col, \"MONTH\"]])\n",
    "        X_dense = df_forecast[lag_roll_cols].values\n",
    "        X_input = sparse.hstack([h3_sparse, X_temporal, X_dense])\n",
    "\n",
    "        # Predict\n",
    "        proba = model.predict_proba(X_input)[:, 1]\n",
    "        presence_pred = (proba >= thresh_).astype(float)\n",
    "\n",
    "        df_forecast[\"presence_pred\"] = presence_pred\n",
    "        df_forecast[\"proba\"] = proba\n",
    "        forecasts.append(df_forecast[[\"DATE\", h3_col, \"presence_pred\", \"proba\"]].copy())\n",
    "\n",
    "        # Update lag/rolling for next day\n",
    "        for lag in short_lags:\n",
    "            df_forecast[f\"lag_{lag}\"] = (\n",
    "                df_forecast.groupby(h3_col)[\"presence_pred\"].shift(lag).fillna(0)\n",
    "            )\n",
    "        for window in rolling_windows:\n",
    "            df_forecast[f\"roll_{window}\"] = (\n",
    "                df_forecast.groupby(h3_col)[\"presence_pred\"]\n",
    "                .shift(1)\n",
    "                .rolling(window=window, min_periods=1)\n",
    "                .sum()\n",
    "                .fillna(0)\n",
    "            )\n",
    "\n",
    "    return pd.concat(forecasts).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0331c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All H3 cells in training data (or full dataset)\n",
    "all_h3_cells = df_model[\"H3_CELL\"].unique()\n",
    "train_max_date = df_model[df_model[\"DATE\"] <= split_date][\"DATE\"].max()\n",
    "\n",
    "# Create df_last with one row per H3 cell\n",
    "df_last = pd.DataFrame({\"H3_CELL\": all_h3_cells})\n",
    "df_last[\"DATE\"] = train_max_date\n",
    "\n",
    "# Add lag/rolling columns initialized to 0\n",
    "for col in lag_roll_cols:\n",
    "    df_last[col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b11130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of days in test set\n",
    "n_days = df_model[df_model[\"DATE\"] > split_date][\"DATE\"].nunique()\n",
    "\n",
    "forecast_df = recursive_forecast_clean(\n",
    "    model=xg_model,\n",
    "    df_last=df_last,\n",
    "    ohe=ohe,\n",
    "    scaler=scaler,\n",
    "    lag_roll_cols=lag_roll_cols,\n",
    "    temporal_cols=temporal_cols,\n",
    "    n_days=n_days,\n",
    "    thresh_=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28f5dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only rows that actually exist in test set\n",
    "df_eval = pd.merge(\n",
    "    forecast_df,\n",
    "    df_model[test_idx][[\"H3_CELL\", \"DATE\", \"presence\"]],\n",
    "    on=[\"H3_CELL\", \"DATE\"],\n",
    "    how=\"inner\",  # keep only observed rows\n",
    ")\n",
    "# df_eval[\"presence_pred\"] = np.where(df_eval[\"proba\"] > 0.15, 1, 0)\n",
    "\n",
    "y_true = df_eval[\"presence\"]\n",
    "y_pred = df_eval[\"presence_pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaee456",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "print(\"\\nROC-AUC Score:\")\n",
    "print(roc_auc_score(y_true, df_eval[\"proba\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e334f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve, f1_score\n",
    "\n",
    "# True labels and predicted probabilities\n",
    "y_true = df_eval[\"presence\"]\n",
    "y_probs = df_eval[\"proba\"]\n",
    "\n",
    "thresholds = np.arange(0.01, 1.0, 0.01)\n",
    "best_thresh = 0.5\n",
    "best_f1 = 0\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred = (y_probs >= t).astype(int)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_thresh = t\n",
    "\n",
    "print(f\"Best threshold for F1: {best_thresh:.2f} (F1={best_f1:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef62468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280c66b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0.05, 0.5, 0.05)  # lower thresholds since data is imbalanced\n",
    "results = []\n",
    "\n",
    "for t in thresholds:\n",
    "    forecast_df = recursive_forecast_clean(\n",
    "        model=xg_model,\n",
    "        df_last=df_last,\n",
    "        ohe=ohe,\n",
    "        scaler=scaler,\n",
    "        lag_roll_cols=lag_roll_cols,\n",
    "        temporal_cols=temporal_cols,\n",
    "        n_days=n_days,\n",
    "        thresh_=t,\n",
    "    )\n",
    "\n",
    "    # Merge with observed test data (only rows with true presence)\n",
    "    df_eval = pd.merge(\n",
    "        forecast_df,\n",
    "        df_model[test_idx][[\"H3_CELL\", \"DATE\", \"presence\"]],\n",
    "        on=[\"H3_CELL\", \"DATE\"],\n",
    "        how=\"inner\",\n",
    "    )\n",
    "\n",
    "    y_true = df_eval[\"presence\"]\n",
    "    y_pred = df_eval[\"presence_pred\"]\n",
    "\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    results.append((t, f1))\n",
    "\n",
    "# Find best threshold\n",
    "best_thresh, best_f1 = max(results, key=lambda x: x[1])\n",
    "print(f\"Best threshold in recursive forecast: {best_thresh:.2f} (F1={best_f1:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b02394",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cc6218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Forecast w/Best Threshold\n",
    "forecast_df = recursive_forecast_clean(\n",
    "    model=xg_model,\n",
    "    df_last=df_last,\n",
    "    ohe=ohe,\n",
    "    scaler=scaler,\n",
    "    lag_roll_cols=lag_roll_cols,\n",
    "    temporal_cols=temporal_cols,\n",
    "    n_days=n_days,\n",
    "    thresh_=0.1,  # best_thresh,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c29f202",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "\n",
    "# Only rows that actually exist in test set\n",
    "df_eval = pd.merge(\n",
    "    forecast_df,\n",
    "    df_model[test_idx][[\"H3_CELL\", \"DATE\", \"presence\"]],\n",
    "    on=[\"H3_CELL\", \"DATE\"],\n",
    "    how=\"inner\",  # keep only observed rows\n",
    ")\n",
    "df_eval[\"presence_pred\"] = np.where(df_eval[\"proba\"] > 0.05, 1, 0)\n",
    "\n",
    "y_true = df_eval[\"presence\"]\n",
    "y_pred = df_eval[\"presence_pred\"]\n",
    "\n",
    "#######################################################\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "print(\"\\nROC-AUC Score:\")\n",
    "print(roc_auc_score(y_true, df_eval[\"proba\"]))\n",
    "\n",
    "#######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc96991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_functions import h3_to_polygon\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93b660a",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_h3 = forecast_df.copy()  # [forecast_df.DATE == \"2025-07-24\"]\n",
    "forecast_h3[\"geometry\"] = forecast_h3[\"H3_CELL\"].apply(h3_to_polygon)\n",
    "forecast_h3 = gpd.GeoDataFrame(forecast_h3, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "\n",
    "forecast_h3[\"proba_scaled\"] = (forecast_h3[\"proba\"] - forecast_h3[\"proba\"].min()) / (\n",
    "    forecast_h3[\"proba\"].max() - forecast_h3[\"proba\"].min()\n",
    ")\n",
    "forecast_h3[\"WOY\"] = forecast_h3[\"DATE\"].dt.isocalendar().week\n",
    "forecast_h3[\"YEAR\"] = forecast_h3[\"DATE\"].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec482d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_h3[forecast_h3.DATE == \"2025-07-24\"].explore(\n",
    "    \"presence_pred\", cmap=\"cool\"\n",
    ").save(\"test.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d0eb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# year_ = 2025\n",
    "\n",
    "# sightings_filt = sightings[(sightings.POD_TYPE == pod_type) & (sightings.YEAR == year_)]\n",
    "\n",
    "# sightings_filt.WOY.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc286db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = forecast_h3_date.explore(\n",
    "#     \"proba_scaled\",\n",
    "#     cmap=\"cool\",\n",
    "#     tiles=\"CartoDB positron\",\n",
    "# )\n",
    "# m = sightings_filt.explore(m=m)\n",
    "# # m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdd54ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb96e660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Smooth Forecasts\n",
    "import h3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# df_forecast has columns: H3_CELL, proba\n",
    "cells = forecast_h3[\"H3_CELL\"].unique()\n",
    "cell_coords = np.array([h3.cell_to_latlng(cell) for cell in cells])  # lat/lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bc2f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Choose bandwidth in km (sigma)\n",
    "sigma_km = 5.0\n",
    "\n",
    "\n",
    "# Compute pairwise distances (Haversine) in km\n",
    "def haversine(latlon1, latlon2):\n",
    "    lat1, lon1 = np.radians(latlon1[:, 0]), np.radians(latlon1[:, 1])\n",
    "    lat2, lon2 = np.radians(latlon2[:, 0]), np.radians(latlon2[:, 1])\n",
    "    dlat = lat2[:, None] - lat1[None, :]\n",
    "    dlon = lon2[:, None] - lon1[None, :]\n",
    "    a = (\n",
    "        np.sin(dlat / 2) ** 2\n",
    "        + np.cos(lat1[None, :]) * np.cos(lat2[:, None]) * np.sin(dlon / 2) ** 2\n",
    "    )\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return 6371 * c  # Earth radius in km\n",
    "\n",
    "\n",
    "dist_matrix = haversine(cell_coords, cell_coords)  # shape: (n_cells, n_cells)\n",
    "\n",
    "# Gaussian weights\n",
    "weights = np.exp(-(dist_matrix**2) / (2 * sigma_km**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22de9c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original probabilities in the same order as `cells`\n",
    "proba_vector = forecast_h3.groupby(\"H3_CELL\")[\"proba\"].mean().reindex(cells).values\n",
    "\n",
    "# Smoothed probability\n",
    "smoothed_proba = weights @ proba_vector / weights.sum(axis=1)\n",
    "\n",
    "# Add back to dataframe\n",
    "forecast_h3[\"proba_smooth\"] = forecast_h3[\"H3_CELL\"].map(\n",
    "    dict(zip(cells, smoothed_proba))\n",
    ")\n",
    "\n",
    "forecast_h3[\"proba_smooth_scale\"] = (\n",
    "    forecast_h3[\"proba_smooth\"] - forecast_h3[\"proba_smooth\"].min()\n",
    ") / (forecast_h3[\"proba_smooth\"].max() - forecast_h3[\"proba_smooth\"].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f5445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only rows that actually exist in test set\n",
    "df_eval = pd.merge(\n",
    "    forecast_h3,\n",
    "    df_model[test_idx][[\"H3_CELL\", \"DATE\", \"presence\"]],\n",
    "    on=[\"H3_CELL\", \"DATE\"],\n",
    "    how=\"inner\",  # keep only observed rows\n",
    ")\n",
    "df_eval[\"presence_smooth\"] = np.where(df_eval[\"proba_smooth\"] > 0.05, 1, 0)\n",
    "\n",
    "y_true = df_eval[\"presence\"]\n",
    "y_pred = df_eval[\"presence_smooth\"]\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "print(\"\\nROC-AUC Score:\")\n",
    "print(roc_auc_score(y_true, df_eval[\"proba\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc60bd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_h3[forecast_h3.DATE == \"2025-07-24\"].explore(\n",
    "    \"proba_smooth_scale\", cmap=\"cool\"\n",
    ").save(\"test.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8322ab8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5190f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648aff5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53238258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1️⃣ Include neighboring cells\n",
    "# Add features like presence in adjacent H3 cells or rolling sums over parent grids.\n",
    "# This helps the model predict a sighting in a nearby cell even if that cell itself hasn’t seen a sighting yet.\n",
    "# 2️⃣ Include environmental / spatial covariates\n",
    "# Latitude/longitude (or encoded features)\n",
    "# Distance to known hotspots\n",
    "# Prey availability, tides, or other relevant covariates\n",
    "# This gives the model some signal for predicting outside the “usual” cells.\n",
    "# 3️⃣ Adjust class imbalance / threshold\n",
    "# You could slightly lower the threshold for all other H3 cells to catch rare presences.\n",
    "# Or use a probability calibration / class-weighting method to avoid underestimating rare events.\n",
    "# 4️⃣ Consider spatial smoothing / Gaussian kernel\n",
    "# Post-process predicted probabilities by smoothing across neighbors, so a hotspot “spills” into adjacent cells.\n",
    "# This is a neat trick if you want to maintain simplicity but improve spatial coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6414d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3331b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salmonsignal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
