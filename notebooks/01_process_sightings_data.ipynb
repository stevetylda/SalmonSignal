{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "430f7bf3",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Open Sightings Data\n",
    "\n",
    "1. Find Pod Designation (Place Sightings Into Pod - J, K, L, Transient, Other)\n",
    "2. Find Pod Type Designation (Place Sightings Into Pod Type - SRKW, Transient, Other)\n",
    "3. Aggregate Sightings by Laitutde + Longitude + Date \n",
    "4. Add Variables (DOY, WOY, MONTH, YEAR, SOURCE)\n",
    "\n",
    "By opening this data, we can investigate whether there is any correlation between sightings at the Columbia River mouth and Salmon abundance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e70a0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------- #\n",
    "#                 MODULES                 #\n",
    "\n",
    "# Standard Modules\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "# Third-Party Modules\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#                                         #\n",
    "# --------------------------------------- #\n",
    "\n",
    "# --------------------------------------- #\n",
    "#                FUNCTIONS                #\n",
    "\n",
    "####################\n",
    "################ TWM\n",
    "\n",
    "\n",
    "# TWM Data Preprocessing\n",
    "def preprocess_twm_data(data):\n",
    "    data[\"pod_tag\"] = data[\"pod_tag\"].fillna(data[\"pod\"])\n",
    "    data[\"pod_tag\"] = data[\"pod_tag\"].fillna(\"orcas\")\n",
    "\n",
    "    # Soft Fix for Unknown but Partially Identified - OverInflate Sightings?\n",
    "    data[\"pod_tag\"] = np.where(\n",
    "        data[\"pod_tag\"].str.startswith(\"nr\"), \"AGR\", data[\"pod_tag\"]\n",
    "    )\n",
    "    data[\"pod_tag\"] = np.where(\n",
    "        data[\"pod_tag\"].str.startswith(\"sr\"), \"JKL\", data[\"pod_tag\"]\n",
    "    )\n",
    "    data[\"pod_tag\"] = np.where(\n",
    "        data[\"pod_tag\"].str.startswith(\"t\"), \"T\", data[\"pod_tag\"]\n",
    "    )\n",
    "    data = data[[\"SightDate\", \"latitude\", \"longitude\", \"pod_tag\"]]\n",
    "    data.columns = [\"DATE\", \"LATITUDE\", \"LONGITUDE\", \"POD_TAG\"]\n",
    "\n",
    "    data[\"POD_TAG\"] = np.where(\n",
    "        data[\"POD_TAG\"] != \"orcas\", data[\"POD_TAG\"].apply(list), list([\"O\"])\n",
    "    )\n",
    "    data = data.explode(\"POD_TAG\")\n",
    "    data[\"COUNT\"] = 1\n",
    "\n",
    "    data[\"POD_TYPE\"] = data[\"POD_TAG\"].map(pod_lookup)\n",
    "\n",
    "    data = data.groupby(\n",
    "        [\"DATE\", \"LATITUDE\", \"LONGITUDE\", \"POD_TYPE\", \"POD_TAG\"], as_index=False\n",
    "    )[\"COUNT\"].sum()\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "####################\n",
    "############ ACARTIA\n",
    "\n",
    "\n",
    "# Function to extract species from notes as a list\n",
    "def extract_species_from_notes(notes):\n",
    "    if pd.isna(notes):\n",
    "        return [\"Unspecified\"]\n",
    "\n",
    "    text = str(notes).lower()\n",
    "    extracted_species = set()\n",
    "\n",
    "    # Comprehensive keyword mapping based on common cetacean species\n",
    "    species_keywords = {\n",
    "        \"Killer Whale\": [\n",
    "            \"orca\",\n",
    "            \"killer whale\",\n",
    "            \"srkw\",\n",
    "            \"southern resident\",\n",
    "            \"transient\",\n",
    "            \"bigg's\",\n",
    "            \"j pod\",\n",
    "            \"k pod\",\n",
    "            \"l pod\",\n",
    "            \"j-pod\",\n",
    "            \"k-pod\",\n",
    "            \"l-pod\",\n",
    "            \"ballena asesina\",\n",
    "            \"orque\",\n",
    "            \"Ã©paulard\",\n",
    "            \"hunting a sea lion\",\n",
    "        ],\n",
    "        \"Humpback Whale\": [\"humpback\", \"ballena jorobada\"],\n",
    "        \"Gray Whale\": [\"gray whale\", \"grey whale\"],\n",
    "        \"Blue Whale\": [\"blue whale\", \"ballena azul\"],\n",
    "        \"Fin Whale\": [\"fin whale\", \"finback whale\"],\n",
    "        \"Minke Whale\": [\"minke\", \"petit rorqual\"],\n",
    "        \"Sperm Whale\": [\"sperm whale\"],\n",
    "        \"Right Whale\": [\"right whale\", \"black right whale\"],\n",
    "        \"Sei Whale\": [\"sei whale\"],\n",
    "        \"Baird's Beaked Whale\": [\"baird's beaked whale\"],\n",
    "        \"Beluga Whale\": [\"beluga\"],\n",
    "        \"Bryde's Whale\": [\"bryde\"],\n",
    "        \"Pilot Whale\": [\"pilot whale\"],\n",
    "        \"False Killer Whale\": [\"false killer whale\"],\n",
    "        \"Beaked Whale\": [\"beaked whale\"],\n",
    "        \"Narwhal\": [\"narwhal\"],\n",
    "        \"Bowhead Whale\": [\"bowhead\"],\n",
    "        \"Harbor Porpoise\": [\"harbor porpoise\", \"marsouin commun\"],\n",
    "        \"Dall's Porpoise\": [\"dall's porpoise\", \"dalls\"],\n",
    "        \"Porpoise\": [\"porpoise\"],  # Generic\n",
    "        \"Bottlenose Dolphin\": [\"bottlenose dolphin\", \"bottlenose whale\"],\n",
    "        \"Risso's Dolphin\": [\"risso's dolphin\"],\n",
    "        \"Pacific White-sided Dolphin\": [\n",
    "            \"pacific white-sided dolphin\",\n",
    "            \"pacific white sided dolphin\",\n",
    "        ],\n",
    "        \"Common Dolphin\": [\"common dolphin\"],\n",
    "        \"Common Dolphin\": [\"long-beaked common dolphin\", \"long beaked common dolphin\"],\n",
    "        \"Common Dolphin\": [\"short-beaked common dolphin\"],\n",
    "        \"Striped Dolphin\": [\"striped dolphin\"],\n",
    "        \"Spinner Dolphin\": [\"spinner dolphin\"],\n",
    "        \"Spotted Dolphin\": [\"spotted dolphin\"],\n",
    "        \"White-beaked Dolphin\": [\"white-beaked dolphin\"],\n",
    "        \"Atlantic White-sided Dolphin\": [\"atlantic white-sided dolphin\"],\n",
    "        \"Right Whale\": [\"northern right whale dolphin\"],\n",
    "        \"Dolphin\": [\"dolphin\"],  # Generic\n",
    "        \"Other\": [\"seal\", \"sea lion\", \"shark\", \"sunfish\", \"mola mola\"],\n",
    "    }\n",
    "\n",
    "    # Check for each species\n",
    "    for sp, keywords in species_keywords.items():\n",
    "        if any(k in text for k in keywords):\n",
    "            extracted_species.add(sp)\n",
    "\n",
    "    # Special regex for orca individual IDs\n",
    "    if re.search(r\"\\b[jklto]\\-?\\d+\\b\", text, re.IGNORECASE):\n",
    "        extracted_species.add(\"Killer Whale\")\n",
    "\n",
    "    # Return list of species; if none but 'whale' mentioned, return ['Unspecified Whale']\n",
    "    if \"False Killer Whale\" in extracted_species:\n",
    "        if \"Killer Whale\" in extracted_species:\n",
    "            extracted_species.discard(\"Killer Whale\")\n",
    "    if extracted_species:\n",
    "        return sorted(extracted_species)\n",
    "    elif \"whale\" in text:\n",
    "        return [\"Unspecified Whale\"]\n",
    "    else:\n",
    "        return [\"Unspecified\"]\n",
    "\n",
    "\n",
    "# Preprocess Acartia Data to Identify Likely Orca Sightings\n",
    "def collect_likely_orca_sightings(data):\n",
    "    ## Lower-Case\n",
    "    data[\"pre_type\"] = data[\"type\"].astype(str)\n",
    "    data[\"pre_type\"] = data[\"pre_type\"].str.lower()\n",
    "\n",
    "    ## Remove Apostrophes\n",
    "    data[\"pre_type\"] = data[\"pre_type\"].str.replace(\"'\", \"\")\n",
    "\n",
    "    ## Remove Slashes\n",
    "    data[\"pre_type\"] = data[\"pre_type\"].str.replace(\"\\\\\", \"\")\n",
    "\n",
    "    ## Remove Colon\n",
    "    data[\"pre_type\"] = data[\"pre_type\"].str.replace(\":\", \"\")\n",
    "\n",
    "    ## Remove \"Sighting\"\n",
    "    data[\"pre_type\"] = data[\"pre_type\"].str.replace(\" sighting\", \"\")\n",
    "\n",
    "    ################################################################################\n",
    "    # Standardize Type Column\n",
    "    data[\"std_type\"] = data[\"pre_type\"].astype(str).str.lower().map(species_mapping)\n",
    "\n",
    "    # Check for Nan Std Type -> this means that the type was not in our lookup\n",
    "    if len(data[data[\"std_type\"].isna()]) > 0:\n",
    "        print(\"Check Keywords Lookup to ensure all are caught\")\n",
    "        print(\"Un caught\")\n",
    "        display(list(data[data[\"std_type\"].isna()][\"type\"].unique()))\n",
    "\n",
    "    ################################################################################\n",
    "    # Check Unspecified Group - Notes Section\n",
    "    data_tagged = data[data[\"std_type\"] != \"Unspecified\"]\n",
    "    data_tagged_likely_orca = data_tagged[data_tagged[\"std_type\"] == \"Killer Whale\"][\n",
    "        [\"created\", \"latitude\", \"longitude\", \"data_source_comments\"]\n",
    "    ]\n",
    "\n",
    "    # Standardize Source Comments Column\n",
    "    data_untag = data[data[\"std_type\"] == \"Unspecified\"].copy()\n",
    "\n",
    "    ## Fill Null with Unspecified\n",
    "    data_untag[\"std_data_source_comments\"] = data_untag[\"data_source_comments\"].fillna(\n",
    "        \"Unspecified\"\n",
    "    )\n",
    "\n",
    "    data_untag[\"std_data_source_comments\"] = data_untag[\n",
    "        \"std_data_source_comments\"\n",
    "    ].str.replace(\"\\n\", \"\")\n",
    "\n",
    "    data_untag[\"std_data_source_comments\"] = (\n",
    "        data_untag[\"std_data_source_comments\"]\n",
    "        .str.replace(\"Orca Network\", \"\")\n",
    "        .str.replace(\"Orcq Network\", \"\")\n",
    "        .str.replace(\"http://www.orca\", \"\")\n",
    "        .str.replace(\"Orcasound\", \"\")\n",
    "    )\n",
    "\n",
    "    data_untag[\"std_data_source_comments\"] = data_untag[\n",
    "        \"std_data_source_comments\"\n",
    "    ].str.replace(\"[\", \"\")\n",
    "\n",
    "    data_untag[\"std_data_source_comments\"] = data_untag[\n",
    "        \"std_data_source_comments\"\n",
    "    ].str.replace(\"]\", \"\")\n",
    "\n",
    "    data_untag[\"std_data_source_comments\"] = (\n",
    "        data_untag[\"std_data_source_comments\"]\n",
    "        .str.replace(\" at\", \"\")\n",
    "        .str.replace(\" the\", \"\")\n",
    "        .str.replace(\" of\", \"\")\n",
    "        .str.replace(\"viewed\", \"\")\n",
    "    )\n",
    "\n",
    "    data_untag[\"std_data_source_comments\"] = data_untag[\n",
    "        \"std_data_source_comments\"\n",
    "    ].str.replace(\"Not orca\", \"\")\n",
    "\n",
    "    # Extract from notes\n",
    "    data_untag[\"extracted_from_notes\"] = data_untag[\"std_data_source_comments\"].apply(\n",
    "        extract_species_from_notes\n",
    "    )\n",
    "\n",
    "    # Explode Multiple Species\n",
    "    data_untag = data_untag.explode(\"extracted_from_notes\")\n",
    "\n",
    "    data_untag_likely_orca = data_untag[\n",
    "        data_untag[\"extracted_from_notes\"] == \"Killer Whale\"\n",
    "    ][[\"created\", \"latitude\", \"longitude\", \"data_source_comments\"]]\n",
    "\n",
    "    data_likely_orca = pd.concat([data_tagged_likely_orca, data_untag_likely_orca])\n",
    "    data_likely_orca[\"DATE\"] = data_likely_orca[\"created\"].str[0:10]\n",
    "    data_likely_orca = data_likely_orca.rename(\n",
    "        columns={\"latitude\": \"LATITUDE\", \"longitude\": \"LONGITUDE\"}\n",
    "    )\n",
    "\n",
    "    return data_likely_orca\n",
    "\n",
    "\n",
    "# build Pod Tagging\n",
    "def build_pod_tag_list(j, k, l, t):\n",
    "    tag = []\n",
    "    if j == 1:\n",
    "        tag.append(\"J\")\n",
    "    if k == 1:\n",
    "        tag.append(\"K\")\n",
    "    if l == 1:\n",
    "        tag.append(\"L\")\n",
    "    if t == 1:\n",
    "        tag.append(\"T\")\n",
    "\n",
    "    if len(tag) == 0:\n",
    "        tag = [None]\n",
    "\n",
    "    return tag\n",
    "\n",
    "\n",
    "# Define Pod Keys\n",
    "def define_keys(data):\n",
    "    long_string = \",\".join(data.data_source_comments.astype(str))\n",
    "\n",
    "    jpod_keys = [\n",
    "        \"J pod\",\n",
    "        \"Jpod\",\n",
    "        \"J ppd\",\n",
    "        \"J Pod\",\n",
    "        \"j Pod\",\n",
    "        \"J-pod\",\n",
    "        \"Js\",\n",
    "        \"j pod\",\n",
    "        \"jpod\",\n",
    "        \"j ppd\",\n",
    "        \"j-pod\",\n",
    "        \"j+k\",\n",
    "        \"k+j\",\n",
    "        \"j & k\",\n",
    "        \"k & j\",\n",
    "        \"j and k\",\n",
    "        \"k and j\",\n",
    "        \"jk pods\",\n",
    "        \"kj pods\",\n",
    "        \"J/K\",\n",
    "        \"j/k\",\n",
    "        \"J+K\",\n",
    "        \"K+J\",\n",
    "        \"J & K\",\n",
    "        \"K & J\",\n",
    "        \"J and K\",\n",
    "        \"K and J\",\n",
    "        \"JK pods\",\n",
    "        \"KJ pods\",\n",
    "        \"j+l\",\n",
    "        \"l+j\",\n",
    "        \"j & l\",\n",
    "        \"l & j\",\n",
    "        \"j and l\",\n",
    "        \"l and j\",\n",
    "        \"jl pods\",\n",
    "        \"lj pods\",\n",
    "        \"J+L\",\n",
    "        \"L+J\",\n",
    "        \"J & L\",\n",
    "        \"L & J\",\n",
    "        \"J and L\",\n",
    "        \"L and J\",\n",
    "        \"JL pods\",\n",
    "        \"LJ pods\",\n",
    "        \"j, k, l pod\",\n",
    "        \"j, k, and l pod\",\n",
    "        \"jkl\",\n",
    "        \"J, K, L pod\",\n",
    "        \"J, K, and L pod\",\n",
    "        \"JKL\",\n",
    "        \"j27\",\n",
    "        \"j38\",\n",
    "        \"j35\",\n",
    "        \"j40\",\n",
    "        \"J27\",\n",
    "        \"J38\",\n",
    "        \"J35\",\n",
    "        \"J40\",\n",
    "        \"J,\",\n",
    "        \"j,\",\n",
    "    ]\n",
    "\n",
    "    # Supplement\n",
    "    jpod_ids = matches = re.findall(\n",
    "        r\"\\bj\\s*\\d+[A-Za-z]?\\b\", long_string, flags=re.IGNORECASE\n",
    "    )\n",
    "    jpod_ids = np.unique(jpod_ids)\n",
    "\n",
    "    jpod_keys = np.unique(jpod_keys + list(jpod_ids))\n",
    "\n",
    "    kpod_keys = [\n",
    "        \"K pod\",\n",
    "        \"K Pod\",\n",
    "        \"k pod\",\n",
    "        \"Kpod\",\n",
    "        \"K,\",\n",
    "        \"k,\",\n",
    "        \"K-pod\",\n",
    "        \"Ks\",\n",
    "        \"k pod\",\n",
    "        \"kpod\",\n",
    "        \"k-pod\",\n",
    "        \"j+k\",\n",
    "        \"k+j\",\n",
    "        \"j & k\",\n",
    "        \"J/K\",\n",
    "        \"j/k\",\n",
    "        \"k & j\",\n",
    "        \"j and k\",\n",
    "        \"k and j\",\n",
    "        \"jk pods\",\n",
    "        \"kj pods\",\n",
    "        \"J+K\",\n",
    "        \"K+J\",\n",
    "        \"J & K\",\n",
    "        \"K & J\",\n",
    "        \"J and K\",\n",
    "        \"K and J\",\n",
    "        \"JK pods\",\n",
    "        \"KJ pods\",\n",
    "        \"k+l\",\n",
    "        \"l+k\",\n",
    "        \"k & l\",\n",
    "        \"l & k\",\n",
    "        \"k and l\",\n",
    "        \"l and k\",\n",
    "        \"lk pods\",\n",
    "        \"kl pods\",\n",
    "        \"K+L\",\n",
    "        \"L+K\",\n",
    "        \"K & L\",\n",
    "        \"L & K\",\n",
    "        \"K and L\",\n",
    "        \"L and K\",\n",
    "        \"LK pods\",\n",
    "        \"KL pods\",\n",
    "        \"j, k, l pod\",\n",
    "        \"j, k, and l pod\",\n",
    "        \"jkl\",\n",
    "        \"J, K, L pod\",\n",
    "        \"J, K, and L pod\",\n",
    "        \"JKL\",\n",
    "        \"k37\",\n",
    "        \"K37\",\n",
    "    ]\n",
    "\n",
    "    kpod_ids = matches = re.findall(\n",
    "        r\"\\bk\\s*\\d+[A-Za-z]?\\b\", long_string, flags=re.IGNORECASE\n",
    "    )\n",
    "    kpod_ids = np.unique(kpod_ids)\n",
    "\n",
    "    kpod_keys = np.unique(kpod_keys + list(kpod_ids))\n",
    "\n",
    "    lpod_keys = [\n",
    "        \"L pod\",\n",
    "        \"Lpod\",\n",
    "        \"L-pod\",\n",
    "        \"L,\",\n",
    "        \"l,\",\n",
    "        \"Ls\",\n",
    "        \"j+l\",\n",
    "        \"l+j\",\n",
    "        \"j & l\",\n",
    "        \"l & j\",\n",
    "        \"j and l\",\n",
    "        \"l and j\",\n",
    "        \"jl pods\",\n",
    "        \"lj pods\",\n",
    "        \"J+L\",\n",
    "        \"L+J\",\n",
    "        \"J & L\",\n",
    "        \"L & J\",\n",
    "        \"J and L\",\n",
    "        \"L and J\",\n",
    "        \"JL pods\",\n",
    "        \"LJ pods\",\n",
    "        \"k+l\",\n",
    "        \"l+k\",\n",
    "        \"k & l\",\n",
    "        \"l & k\",\n",
    "        \"k and l\",\n",
    "        \"l and k\",\n",
    "        \"lk pods\",\n",
    "        \"kl pods\",\n",
    "        \"K+L\",\n",
    "        \"L+K\",\n",
    "        \"K & L\",\n",
    "        \"L & K\",\n",
    "        \"K and L\",\n",
    "        \"L and K\",\n",
    "        \"LK pods\",\n",
    "        \"KL pods\",\n",
    "        \"j, k, l pod\",\n",
    "        \"j, k, and l pod\",\n",
    "        \"jkl\",\n",
    "        \"J, K, L pod\",\n",
    "        \"J, K, and L pod\",\n",
    "        \"JKL\",\n",
    "        \"l12\",\n",
    "        \"l54\",\n",
    "        \"l-12\",\n",
    "        \"l82\",\n",
    "        \"l85\",\n",
    "        \"l87\",\n",
    "        \"L12\",\n",
    "        \"L54\",\n",
    "        \"L-12\",\n",
    "        \"L82\",\n",
    "        \"L85\",\n",
    "        \"L87\",\n",
    "        \"L4\",\n",
    "    ]\n",
    "\n",
    "    lpod_ids = matches = re.findall(\n",
    "        r\"\\bl\\s*\\d+[A-Za-z]?\\b\", long_string, flags=re.IGNORECASE\n",
    "    )\n",
    "    lpod_ids = np.unique(lpod_ids)\n",
    "\n",
    "    lpod_keys = np.unique(lpod_keys + list(lpod_ids))\n",
    "\n",
    "    biggs_keys = [\n",
    "        \"Bigg\",\n",
    "        \"bigg\",\n",
    "        \"T Party\",\n",
    "        \"sea lion\",\n",
    "        \"Sea Lion\",\n",
    "        \"seal\",\n",
    "        \"Transient\",\n",
    "        \"transient\",\n",
    "        \"Ts\",\n",
    "        \"t99\",\n",
    "        \"65\",\n",
    "        \"Hunting a seal close to shore at Alki\",\n",
    "        \"65A\",\n",
    "        \"65a\",\n",
    "        \"T046B\",\n",
    "        \"t046B\" \"t137\",\n",
    "        \"t46\",\n",
    "        \"hunting Harbor porpoises\",\n",
    "        \"t10\",\n",
    "        \"t2c\",\n",
    "        \"t49\",\n",
    "        \"T99\",\n",
    "        \"T137\",\n",
    "        \"T36\",\n",
    "        \"T10\",\n",
    "        \"T2C\",\n",
    "        \"T49\",\n",
    "        \"T65A\",\n",
    "        \"T124\",\n",
    "        \"T35\",\n",
    "        \"T46\",\n",
    "        \"T087\",\n",
    "        \"T87\",\n",
    "        \"T60\",\n",
    "        \"T75\" \"T68\",\n",
    "        \"T65\",\n",
    "        \"T77\",\n",
    "        \"T19\",\n",
    "        \"T18\",\n",
    "        \"T34\",\n",
    "        \"T90\",\n",
    "        \"T123\",\n",
    "        \"T68\",\n",
    "        \"T11\",\n",
    "        \"T37\",\n",
    "    ]\n",
    "\n",
    "    biggs_ids = matches = re.findall(\n",
    "        r\"\\bt\\s*\\d+[A-Za-z]?\\b\", long_string, flags=re.IGNORECASE\n",
    "    )\n",
    "    biggs_ids = np.unique(biggs_ids)\n",
    "\n",
    "    biggs_keys = np.unique(biggs_keys + list(biggs_ids))\n",
    "\n",
    "    srkw_keys = (\n",
    "        [\n",
    "            \"SRKW\",\n",
    "            \"srkw\",\n",
    "            \"srs\",\n",
    "            \"srk\",\n",
    "            \"salmon\",\n",
    "            \"Southern Residents\",\n",
    "            \"southern resident\",\n",
    "            \"Southern Resident Killer Whales\",\n",
    "            \"Southern Resident\",\n",
    "            \" resident\",\n",
    "            \" Resident\",\n",
    "        ]\n",
    "        + list(jpod_keys)\n",
    "        + list(kpod_keys)\n",
    "        + list(lpod_keys)\n",
    "    )\n",
    "\n",
    "    return jpod_keys, kpod_keys, lpod_keys, biggs_keys, srkw_keys\n",
    "\n",
    "\n",
    "# Assign Pod-Type\n",
    "def assign_pod_type_bool(data, jpod_keys, kpod_keys, lpod_keys, biggs_keys, srkw_keys):\n",
    "\n",
    "    # J pod\n",
    "    data[\"J\"] = data[\"data_source_comments\"].apply(\n",
    "        lambda x: 1 if any([k for k in jpod_keys if k in str(x)]) else 0\n",
    "    )\n",
    "    # K pod\n",
    "    data[\"K\"] = data[\"data_source_comments\"].apply(\n",
    "        lambda x: 1 if any([k for k in kpod_keys if k in str(x)]) else 0\n",
    "    )\n",
    "    # L pod\n",
    "    data[\"L\"] = data[\"data_source_comments\"].apply(\n",
    "        lambda x: 1 if any([k for k in lpod_keys if k in str(x)]) else 0\n",
    "    )\n",
    "\n",
    "    data[\"T\"] = data[\"data_source_comments\"].apply(\n",
    "        lambda x: 1 if any([k for k in biggs_keys if k in str(x)]) else 0\n",
    "    )\n",
    "\n",
    "    data[\"SRKW\"] = data[\"data_source_comments\"].apply(\n",
    "        lambda x: 1 if any([k for k in srkw_keys if k in str(x)]) else 0\n",
    "    )\n",
    "\n",
    "    data[\"POD_TAG\"] = data.apply(\n",
    "        lambda x: build_pod_tag_list(j=x[\"J\"], k=x[\"K\"], l=x[\"L\"], t=x[\"T\"]), axis=1\n",
    "    )\n",
    "\n",
    "    data = data.explode(\"POD_TAG\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# Preprocess Acartia Data\n",
    "def preprocess_acartia_data(data):\n",
    "    data.columns = data.columns.str.strip()\n",
    "    data = data[[\"created\", \"latitude\", \"longitude\", \"type\", \"data_source_comments\"]]\n",
    "\n",
    "    # Identify Likely Orcas\n",
    "    data = collect_likely_orca_sightings(data)\n",
    "\n",
    "    # Build Pod-Keys\n",
    "    jpod_keys, kpod_keys, lpod_keys, biggs_keys, srkw_keys = define_keys(data)\n",
    "\n",
    "    data_passed = assign_pod_type_bool(\n",
    "        data, jpod_keys, kpod_keys, lpod_keys, biggs_keys, srkw_keys\n",
    "    )\n",
    "    data_passed[\"POD_TAG\"] = data_passed[\"POD_TAG\"].fillna(\"O\")\n",
    "    data_passed[\"POD_TYPE\"] = data_passed[\"POD_TAG\"].map(pod_lookup)\n",
    "    data_passed[\"POD_TYPE\"] = np.where(\n",
    "        data_passed[\"SRKW\"] == 1, \"SRKW\", data_passed[\"POD_TYPE\"]\n",
    "    )\n",
    "\n",
    "    data_passed[\"COUNT\"] = 1\n",
    "\n",
    "    data = data_passed.groupby(\n",
    "        [\"DATE\", \"LATITUDE\", \"LONGITUDE\", \"POD_TYPE\", \"POD_TAG\"], as_index=False\n",
    "    )[\"COUNT\"].sum()\n",
    "    data = data[data.DATE >= \"2020-01-01\"]\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# Preprocess Sightings Data - Killer Whales (TODO: need to accoutn for northern resident in Acartia sightings.)\n",
    "def preprocess_kw_sightings_data(directory, source):\n",
    "    if os.path.exists(directory):\n",
    "\n",
    "        # Read & concat all CSVs\n",
    "        if \".csv\" in directory:\n",
    "            data = pd.read_csv(directory)\n",
    "        else:\n",
    "            data = []\n",
    "            for path in glob.glob(f\"{directory}/*.csv\"):\n",
    "                df = pd.read_csv(path)\n",
    "                data.append(df)\n",
    "            if len(data) > 0:\n",
    "                data = pd.concat(data)\n",
    "            else:\n",
    "                data = pd.DataFrame()\n",
    "\n",
    "        if source == \"TWM\":\n",
    "            # Preprocess TWM Data\n",
    "            data = preprocess_twm_data(data)\n",
    "            data[\"SOURCE\"] = \"TWM\"\n",
    "\n",
    "        elif source == \"ACARTIA\":\n",
    "            # Preprocess Acartia Data\n",
    "            data = preprocess_acartia_data(data)\n",
    "            data[\"SOURCE\"] = \"ACARTIA\"\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "#                                         #\n",
    "# --------------------------------------- #\n",
    "\n",
    "# --------------------------------------- #\n",
    "#              DATA LOOKUPS               #\n",
    "\n",
    "# Pod-Community Lookup\n",
    "pod_lookup = {\n",
    "    \"A\": \"NRKW\",\n",
    "    \"G\": \"NRKW\",\n",
    "    \"R\": \"NRKW\",\n",
    "    \"J\": \"SRKW\",\n",
    "    \"K\": \"SRKW\",\n",
    "    \"L\": \"SRKW\",\n",
    "    \"T\": \"TRANSIENT\",\n",
    "    \"O\": \"OTHER\",\n",
    "}\n",
    "\n",
    "\n",
    "# Define mapping for standardizing species names\n",
    "species_mapping = {\n",
    "    \"humpback\": \"Humpback Whale\",\n",
    "    \"ballena jorobada\": \"Humpback Whale\",\n",
    "    \"humpback whale\": \"Humpback Whale\",\n",
    "    \"humpback sighting:\": \"Humpback Whale\",\n",
    "    \"orca\": \"Killer Whale\",\n",
    "    \"killer whale\": \"Killer Whale\",\n",
    "    \"southern resident orca\": \"Killer Whale\",\n",
    "    \"southern resident killer whale\": \"Killer Whale\",\n",
    "    \"killer whale (orca)\": \"Killer Whale\",\n",
    "    \"orca (ballena asesina)\": \"Killer Whale\",\n",
    "    \"killer whale sighting:\": \"Killer Whale\",\n",
    "    \"orca sighting:\": \"Killer Whale\",\n",
    "    \"southern resident killer whale sighting:\": \"Killer Whale\",\n",
    "    \"killer whale (orca) sighting:\": \"Killer Whale\",\n",
    "    \"gray\": \"Gray Whale\",\n",
    "    \"grey\": \"Gray Whale\",\n",
    "    \"gray whale\": \"Gray Whale\",\n",
    "    \"grey whale\": \"Gray Whale\",\n",
    "    \"gray whale sighting:\": \"Gray Whale\",\n",
    "    \"blue whale\": \"Blue Whale\",\n",
    "    \"ballena azul\": \"Blue Whale\",\n",
    "    \"blue whale sighting:\": \"Blue Whale\",\n",
    "    \"fin whale\": \"Fin Whale\",\n",
    "    \"finback whale\": \"Fin Whale\",\n",
    "    \"fin whale sighting:\": \"Fin Whale\",\n",
    "    \"minke whale\": \"Minke Whale\",\n",
    "    \"petit rorqual\": \"Minke Whale\",\n",
    "    \"minke whale sighting:\": \"Minke Whale\",\n",
    "    \"harbor porpoise\": \"Harbor Porpoise\",\n",
    "    \"marsouin commun\": \"Harbor Porpoise\",\n",
    "    \"dalls porpoise\": \"Dall's Porpoise\",\n",
    "    \"pacific white-sided dolphin\": \"Pacific White-sided Dolphin\",\n",
    "    \"pacific white-sided dolphin sighting:\": \"Pacific White-sided Dolphin\",\n",
    "    \"common dolphin\": \"Common Dolphin\",\n",
    "    \"common dolphin - unidentified\": \"Common Dolphin\",\n",
    "    \"common dolphin sighting:\": \"Common Dolphin\",\n",
    "    \"common long-beaked dolphin\": \"Common Dolphin\",\n",
    "    \"long-beaked common dolphin\": \"Common Dolphin\",\n",
    "    \"common short-beaked dolphin\": \"Common Dolphin\",\n",
    "    \"right whale\": \"Right Whale\",\n",
    "    \"right whale sighting:\": \"Right Whale\",\n",
    "    \"black right whale\": \"Right Whale\",\n",
    "    \"northern right whale dolphin\": \"Right Whale\",\n",
    "    \"northern right whale dolphin sighting:\": \"Right Whale\",\n",
    "    \"sperm whale\": \"Sperm Whale\",\n",
    "    \"sperm whale sighting:\": \"Sperm Whale\",\n",
    "    \"white-beaked dolphin\": \"White-beaked Dolphin\",\n",
    "    \"striped dolphin\": \"Striped Dolphin\",\n",
    "    \"rissos dolphin\": \"Risso's Dolphin\",\n",
    "    \"rissos dolphin sighting:\": \"Risso's Dolphin\",\n",
    "    \"sei whale\": \"Sei Whale\",\n",
    "    \"steller sealion\": \"Steller Sea Lion\",\n",
    "    \"short finned pilot whale\": \"Short-finned Pilot Whale\",\n",
    "    \"short finned pilot whale sighting:\": \"Short-finned Pilot Whale\",\n",
    "    \"bottlenose dolphin\": \"Bottlenose Dolphin\",\n",
    "    \"bottlenose whale\": \"Bottlenose Dolphin\",\n",
    "    \"beluga\": \"Beluga Whale\",\n",
    "    \"beluga whale\": \"Beluga Whale\",\n",
    "    \"beluga whale sighting:\": \"Beluga Whale\",\n",
    "    \"sowerbys beaked whale\": \"Sowerby's Beaked Whale\",\n",
    "    \"atlantic white-sided dolphin\": \"Atlantic White-sided Dolphin\",\n",
    "    \"atlantic white-sided dolphin sighting:\": \"Atlantic White-sided Dolphin\",\n",
    "    \"bairds beaked whale\": \"Baird's Beaked Whale\",\n",
    "    \"mola mola / sunfish\": \"Mola Mola\",\n",
    "    \"blue shark\": \"Blue Shark\",\n",
    "    \"whale - unidentified\": \"Unspecified\",\n",
    "    \"unspecified\": \"Unspecified\",\n",
    "    \"unspecified sighting:\": \"Unspecified\",\n",
    "    \"other\": \"Unspecified\",\n",
    "    \"other (specify in comments)\": \"Unspecified\",\n",
    "    \"other sighting:\": \"Unspecified\",\n",
    "    \"other (specify in comments) sighting:\": \"Unspecified\",\n",
    "    \"other species\": \"Unspecified\",\n",
    "    \"non spÃ©cifiÃ©\": \"Unspecified\",\n",
    "    \"non spÃ£Â©cifiÃ£Â©\": \"Unspecified\",\n",
    "    \"autre\": \"Unspecified\",\n",
    "    \"\": \"Unspecified\",\n",
    "    \"nan\": \"Unspecified\",\n",
    "    np.nan: \"Unspecified\",\n",
    "}\n",
    "\n",
    "#                                         #\n",
    "# --------------------------------------- #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ab48ec",
   "metadata": {},
   "source": [
    "## Preprocess Whale Sightings Dataset from TWM and Acartia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641443b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess TWM Data\n",
    "tmw_directory = \"/Users/tylerstevenson/Documents/CODE/orcasalmon/data/twm\"\n",
    "twm_data = preprocess_kw_sightings_data(directory=tmw_directory, source=\"TWM\")\n",
    "\n",
    "# Preprocess TWM Data\n",
    "acartia_directory = \"/Users/tylerstevenson/Documents/CODE/FindMyWhale/data/raw/sightings/acartia-export.csv\"\n",
    "acartia_data = preprocess_kw_sightings_data(\n",
    "    directory=acartia_directory, source=\"ACARTIA\"\n",
    ")\n",
    "\n",
    "# Sightings Data\n",
    "sightings_data = pd.concat([twm_data, acartia_data])\n",
    "\n",
    "# Post-Process Sightings Data to Make Ready for Analysis\n",
    "# Remove Non-Located Sightings\n",
    "sightings_data = sightings_data[\n",
    "    (sightings_data.LATITUDE != \"<Null>\") & (sightings_data.LONGITUDE != \"<Null>\")\n",
    "]\n",
    "\n",
    "# D-Type Handling\n",
    "sightings_data[\"LATITUDE\"] = sightings_data[\"LATITUDE\"].astype(float)\n",
    "sightings_data[\"LONGITUDE\"] = sightings_data[\"LONGITUDE\"].astype(float)\n",
    "sightings_data[\"DATETIME\"] = pd.to_datetime(sightings_data[\"DATE\"])\n",
    "\n",
    "# Make Date Type\n",
    "sightings_data[\"DATE\"] = sightings_data[\"DATETIME\"].dt.date\n",
    "sightings_data[\"DOY\"] = sightings_data[\"DATETIME\"].dt.day_of_year\n",
    "sightings_data[\"WOY\"] = sightings_data[\"DATETIME\"].dt.isocalendar().week\n",
    "sightings_data[\"MONTH\"] = sightings_data[\"DATETIME\"].dt.month\n",
    "sightings_data[\"YEAR\"] = sightings_data[\"DATETIME\"].dt.year\n",
    "sightings_data[\"YEAR_WEEK\"] = sightings_data[\"DATETIME\"].dt.strftime(\"%Y-%U\")\n",
    "sightings_data[\"YEAR_MONTH\"] = sightings_data[\"DATETIME\"].dt.strftime(\"%Y-%m-01\")\n",
    "\n",
    "# Calculate the weekday number (Monday=0, Sunday=6)\n",
    "weekday_num = sightings_data[\"DATETIME\"].dt.weekday\n",
    "\n",
    "# Calculate the date of the previous Sunday by subtracting (weekday_num + 1) % 7 days\n",
    "sightings_data[\"STAT_WEEK_SUNDAY\"] = sightings_data[\"DATETIME\"] - pd.to_timedelta(\n",
    "    (weekday_num + 1) % 7, unit=\"D\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf30895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to File\n",
    "sightings_preprocessed_data_dir = \"../data/processed/ORCA_SIGHTINGS\"\n",
    "if not os.path.exists(sightings_preprocessed_data_dir):\n",
    "    os.makedirs(sightings_preprocessed_data_dir)\n",
    "\n",
    "# Outpath Path\n",
    "output_path = f\"{sightings_preprocessed_data_dir}/ORCA_SIGHTINGS.parquet\"\n",
    "\n",
    "# Export to Path\n",
    "sightings_data.to_parquet(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c3a9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sightings_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c987ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b29093",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_counts = sightings_data.groupby([\"DATE\", \"POD_TYPE\"], as_index=False)[\n",
    "    \"COUNT\"\n",
    "].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b091d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.line(daily_counts, x=\"DATE\", y=\"COUNT\", color=\"POD_TYPE\")\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca74599b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25eba209",
   "metadata": {},
   "source": [
    "## Analysis of Sightings Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a78eabc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2560e78a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfed1b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_latitude = 46.2167\n",
    "selected_longitude = -123.9333\n",
    "selected_buffer_distance = 100\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "# Step 1: Make GeoDataFrame in EPSG:4326\n",
    "area_filter = gpd.GeoDataFrame(\n",
    "    geometry=gpd.points_from_xy([selected_longitude], [selected_latitude]),\n",
    "    crs=\"EPSG:4326\",\n",
    ")\n",
    "area_filter = area_filter.to_crs(epsg=32610)\n",
    "\n",
    "# Step 3: Buffer in meters (buffer_km * 1000)\n",
    "area_filter[\"geometry\"] = area_filter.geometry.buffer(selected_buffer_distance * 1000)\n",
    "\n",
    "# Step 4: Back to EPSG:4326 (lat/lon degrees)\n",
    "area_filter = area_filter.to_crs(epsg=4326)\n",
    "\n",
    "selected_area = area_filter.copy()\n",
    "# plot_data = plot_data.sjoin(area_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d42cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_filter.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b83af9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Geospatial DataSet\n",
    "orca_sightings_df = gpd.GeoDataFrame(\n",
    "    sightings_data,\n",
    "    geometry=gpd.points_from_xy(sightings_data.LONGITUDE, sightings_data.LATITUDE),\n",
    "    crs=\"EPSG:4326\",  # WGS84 lat/lon\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34113840",
   "metadata": {},
   "outputs": [],
   "source": [
    "orca_sightings_df_filtered = orca_sightings_df.sjoin(area_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073fcb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_columbia_sightings = orca_sightings_df_filtered.groupby(\n",
    "    [\"WOY\", \"POD_TYPE\"], as_index=False\n",
    ")[\"COUNT\"].sum()\n",
    "\n",
    "# tot_columbia_sightings = tot_columbia_sightings[\n",
    "#     tot_columbia_sightings.POD_TYPE == \"SRKW\"\n",
    "# ]\n",
    "\n",
    "df_srkw = pd.DataFrame({\"WOY\": list(range(1, 53))})\n",
    "df_srkw[\"POD_TYPE\"] = \"SRKW\"\n",
    "\n",
    "df_tran = pd.DataFrame({\"WOY\": list(range(1, 53))})\n",
    "df_tran[\"POD_TYPE\"] = \"TRANSIENT\"\n",
    "\n",
    "df_othe = pd.DataFrame({\"WOY\": list(range(1, 53))})\n",
    "df_othe[\"POD_TYPE\"] = \"OTHER\"\n",
    "\n",
    "df = pd.concat([df_srkw, df_tran, df_othe])\n",
    "\n",
    "tot_columbia_sightings = pd.merge(tot_columbia_sightings, df, how=\"outer\")\n",
    "tot_columbia_sightings[\"COUNT\"] = tot_columbia_sightings[\"COUNT\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c5922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(tot_columbia_sightings, x=\"WOY\", y=\"COUNT\", color=\"POD_TYPE\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d441f54e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d39f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a680fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in bonneville data\n",
    "bon_raw = pd.read_parquet(\n",
    "    \"../data/processed/FPC_DAM_COUNTS/Bonneville_FPC_DAM_COUNTS.parquet\"\n",
    ")\n",
    "bon_raw[\"Count\"] = np.where(bon_raw[\"Count\"] < 0, 0, bon_raw[\"Count\"])\n",
    "bon = bon_raw.groupby([\"WoY\", \"Species\"], as_index=False)[\"Count\"].mean()\n",
    "bon = bon.rename(columns={\"WoY\": \"WOY\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0efbf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_area_plot_stacked(\n",
    "    bon_raw, metric, metric_lower, metric_upper, dam, species=\"ChinookAdult\"\n",
    "):\n",
    "    bon_woy = bon_raw[\n",
    "        (bon_raw[metric] >= metric_lower) & (bon_raw[metric] <= metric_upper)\n",
    "    ]\n",
    "    bon_woy_chinook = bon_woy[bon_woy.Species == species]\n",
    "    bon_woy_chinook[\"Year\"] = bon_woy_chinook[\"Year\"].astype(int)\n",
    "    bon_woy_chinook = bon_woy_chinook.sort_values(metric).reset_index(drop=True)\n",
    "\n",
    "    bon_woy_chinook = bon_woy_chinook.groupby([metric, \"Year\"], as_index=False)[\n",
    "        \"Count\"\n",
    "    ].sum()\n",
    "\n",
    "    # Define blue-to-red color gradient\n",
    "    years = sorted(bon_woy_chinook[\"Year\"].unique())\n",
    "    n_years = len(years)\n",
    "    # Interpolate colors from blue (#0000FF) to red (#FF0000)\n",
    "    colors = [\n",
    "        f\"rgb({int(255 * (1 - i/(n_years-1)))}, 0, {int(255 * i/(n_years-1))})\"\n",
    "        for i in range(n_years)\n",
    "    ]\n",
    "    year_color_map = dict(zip(years, colors))\n",
    "\n",
    "    # Calculate total count per year and sort years by total count descending (largest first)\n",
    "    total_counts = (\n",
    "        bon_woy_chinook.groupby(\"Year\")[\"Count\"].sum().sort_values(ascending=False)\n",
    "    )\n",
    "    sorted_years = total_counts.index.tolist()\n",
    "\n",
    "    # Create the filled area plot with largest areas in the back\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for year in sorted_years:\n",
    "        # Filter data for the current year\n",
    "        df_year = bon_woy_chinook[bon_woy_chinook[\"Year\"] == year].sort_values(metric)\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_year[metric],\n",
    "                y=df_year[\"Count\"],\n",
    "                mode=\"lines\",\n",
    "                name=str(year),\n",
    "                fill=\"tozeroy\",  # Fill area to y=0 (non-stacked)\n",
    "                line=dict(color=year_color_map[year], width=2),\n",
    "                fillcolor=year_color_map[year],  # Fill with same color as line\n",
    "                # hovertemplate=f\"{metric}: %{x}<br>Count: %{y}<br>Year: %{text}\",\n",
    "                text=[str(year)] * len(df_year),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # # Update layout\n",
    "    fig.update_layout(\n",
    "        title=f\"{species} Counts by {metric}, Colored by Year - {dam}\",\n",
    "        xaxis_title=metric,\n",
    "        yaxis_title=\"Count\",\n",
    "        legend_title=\"Year\",\n",
    "        plot_bgcolor=\"black\",  # Black background\n",
    "        paper_bgcolor=\"black\",  # Black surrounding area\n",
    "        font=dict(color=\"white\"),  # White text for labels\n",
    "    )\n",
    "\n",
    "    return fig, bon_woy_chinook\n",
    "\n",
    "\n",
    "# Get Area Plot\n",
    "fig, bon_ = plot_area_plot_stacked(\n",
    "    bon_raw, metric=\"WoY\", metric_lower=0, metric_upper=53, dam=\"Bonneville\", species = 'ChinookAdult'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f879bced",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_way_pivot = pd.pivot_table(bon_, index=\"WoY\", columns=\"Year\", values=\"Count\")\n",
    "\n",
    "fig = px.imshow(box_way_pivot, color_continuous_scale=\"turbo\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1577ee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tot_columbia_sightings.copy()\n",
    "tmp[\"COUNT\"] = np.where(\n",
    "    (tmp[\"COUNT\"] > 0) & (tmp[\"POD_TYPE\"] == \"OTHER\"), 250000, tmp[\"COUNT\"]\n",
    ")\n",
    "tmp[\"COUNT\"] = np.where(\n",
    "    (tmp[\"COUNT\"] > 0) & (tmp[\"POD_TYPE\"] == \"SRKW\"), 150000, tmp[\"COUNT\"]\n",
    ")\n",
    "tmp[\"COUNT\"] = np.where(\n",
    "    (tmp[\"COUNT\"] > 0) & (tmp[\"POD_TYPE\"] == \"TRANSIENT\"), 50000, tmp[\"COUNT\"]\n",
    ")\n",
    "tmp = pd.pivot_table(tmp.fillna(\"nn\"), columns=\"WOY\", values=\"COUNT\", index=\"POD_TYPE\")\n",
    "tmp = tmp[tmp.index != \"nn\"].fillna(0)\n",
    "\n",
    "\n",
    "tmp = pd.merge(\n",
    "    box_way_pivot.reset_index(),\n",
    "    tmp.T.reset_index().rename(columns={\"WOY\": \"WoY\", \"OTHER\": 2026, \"SRKW\": 2027}),\n",
    ")\n",
    "\n",
    "px.imshow(tmp, color_continuous_scale=\"turbo\")\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1155bbf",
   "metadata": {},
   "source": [
    "## Tagging Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf394ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\n",
    "# https://www.fisheries.noaa.gov/inport/item/18090\n",
    "def fetch_srkw_coastal_page(offset=0, rows=100):\n",
    "    \"\"\"Fetch a single page of SRKW coastal occurrence data.\"\"\"\n",
    "    url = \"https://www.webapps.nwfsc.noaa.gov/apex/parr/srkw_occurrence_coastal/data/page/\"\n",
    "    params = {\"offset\": offset, \"rows\": rows}\n",
    "    headers = {\"User-Agent\": \"orca-fetcher-9000\"}\n",
    "\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    return response.json().get(\"items\", [])\n",
    "\n",
    "\n",
    "def fetch_all_srkw_coastal(max_pages=500, rows_per_page=100, sleep_sec=0.5):\n",
    "    \"\"\"Fetch all available pages of SRKW data, auto-stop when empty.\"\"\"\n",
    "    all_records = []\n",
    "    for i in range(max_pages):\n",
    "        offset = i * rows_per_page\n",
    "        # print(f\"Fetching page {i} (offset={offset})...\")\n",
    "        try:\n",
    "            page = fetch_srkw_coastal_page(offset=offset, rows=rows_per_page)\n",
    "            if not page:\n",
    "                print(\"No more records â halting.\")\n",
    "                break\n",
    "            all_records.extend(page)\n",
    "            time.sleep(sleep_sec)  # be kind to their server\n",
    "        except Exception as e:\n",
    "            print(f\"Page {i} errored: {e}\")\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(all_records)\n",
    "\n",
    "\n",
    "def to_geodataframe(df, lon_field=\"lon_p\", lat_field=\"lat_p\"):\n",
    "    \"\"\"Convert a DataFrame with lon/lat to a GeoDataFrame.\"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"geometry\"] = df.apply(lambda row: Point(row[lon_field], row[lat_field]), axis=1)\n",
    "    return gpd.GeoDataFrame(df, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "\n",
    "\n",
    "# ð Run the full download\n",
    "tagging_df = fetch_all_srkw_coastal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e430aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_gdf = to_geodataframe(tagging_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191d5268",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_gdf_in_aoi = tagging_gdf.sjoin(area_filter)\n",
    "tagging_gdf_in_aoi[\"NEAR_MOUTH\"] = \"NEAR - MOUTH\"\n",
    "\n",
    "tagging_gdf = pd.merge(tagging_gdf, tagging_gdf_in_aoi, how=\"outer\")\n",
    "tagging_gdf[\"NEAR_MOUTH\"] = tagging_gdf[\"NEAR_MOUTH\"].fillna(\"AWAY\")\n",
    "\n",
    "tagging_gdf[\"DATE\"] = tagging_gdf[\"gmt_date\"]\n",
    "tagging_gdf[\"DATETIME\"] = pd.to_datetime(tagging_gdf[\"DATE\"])\n",
    "tagging_gdf[\"YEAR\"] = tagging_gdf[\"DATETIME\"].dt.year\n",
    "tagging_gdf[\"DOY\"] = tagging_gdf[\"DATETIME\"].dt.day_of_year\n",
    "tagging_gdf[\"WOY\"] = tagging_gdf[\"DATETIME\"].dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf250382",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = tagging_gdf[[\"WOY\", \"DOY\", \"YEAR\", \"NEAR_MOUTH\"]].drop_duplicates(\n",
    "    subset=[\"WOY\", \"NEAR_MOUTH\"]\n",
    ")\n",
    "tags = tags[(tags.DOY > 50) & (tags.DOY < 200) & (tags.NEAR_MOUTH == \"NEAR - MOUTH\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2de528f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2e9c43f",
   "metadata": {},
   "source": [
    "## Dam Analysis vs. Sightings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7368f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_species_table(\n",
    "    dam_data_raw, dam_name, date_metric, min_date_metric, max_date_metric\n",
    "):\n",
    "    species_table = []\n",
    "    for species_name in dam_data_raw.Species.unique():\n",
    "        woy_analysis_table = build_dam_peak_analysis(\n",
    "            dam_data_raw,\n",
    "            dam_name,\n",
    "            species_name,\n",
    "            date_metric,\n",
    "            min_date_metric,\n",
    "            max_date_metric,\n",
    "        )\n",
    "        species_table.append(woy_analysis_table)\n",
    "\n",
    "    species_table = pd.concat(species_table)\n",
    "\n",
    "    return species_table\n",
    "\n",
    "\n",
    "def run_analysis_on_dams(dam_data, date_metric=\"WoY\"):\n",
    "\n",
    "    # Preprocess Data\n",
    "    dam_data = dam_data.groupby([date_metric, \"Year\", \"Decade\"], as_index=False)[\n",
    "        \"Count\"\n",
    "    ].sum()\n",
    "\n",
    "    # Expand the data\n",
    "    expanded_values = np.repeat(dam_data[date_metric], dam_data[\"Count\"])\n",
    "\n",
    "    # Calculate the median\n",
    "    long_term_median = np.median(expanded_values)\n",
    "\n",
    "    # Collect for All Years\n",
    "    # Get Year Mdeians\n",
    "    year_val, median_vals, mean_vals, std_vals = [], [], [], []\n",
    "    for year_ in dam_data[\"Year\"].unique():\n",
    "        df_ = dam_data[dam_data[\"Year\"] == year_].copy()\n",
    "        # Expand the data\n",
    "        expanded_values = np.repeat(\n",
    "            df_[date_metric],\n",
    "            df_[\"Count\"],\n",
    "        )\n",
    "\n",
    "        # Calculate the median\n",
    "        mean_val = np.mean(expanded_values)\n",
    "        mean_vals.append(mean_val)\n",
    "\n",
    "        std_val = np.std(expanded_values)\n",
    "        std_vals.append(std_val)\n",
    "\n",
    "        median_val = np.median(expanded_values)\n",
    "        median_vals.append(median_val)\n",
    "\n",
    "        year_val.append(year_)\n",
    "\n",
    "    test_ = pd.DataFrame(\n",
    "        {\n",
    "            \"YEAR\": year_val,\n",
    "            f\"MEDIAN_{date_metric}\": median_vals,\n",
    "            f\"MEAN_{date_metric}\": mean_vals,\n",
    "            f\"STD_{date_metric}\": std_vals,\n",
    "        }\n",
    "    )\n",
    "    test_ = test_.sort_values(\"YEAR\").reset_index(drop=True)\n",
    "\n",
    "    return test_, long_term_median\n",
    "\n",
    "\n",
    "def plot_species_area_plot_at_dam(\n",
    "    df,\n",
    "    dam_name,\n",
    "    orca_sightings_df_filtered,\n",
    "    selected_buffer_distance,\n",
    "    tags,\n",
    "    date_metric,\n",
    "    adjust_to_estimate_density_at_mouth,\n",
    "    how_much_to_adjust,\n",
    "):\n",
    "\n",
    "    # Get unique species dynamically\n",
    "    species_list = sorted(df[\"Species\"].unique())\n",
    "    print(species_list)\n",
    "    num_species = len(species_list)\n",
    "\n",
    "    # Generate hues spaced evenly across the color wheel\n",
    "    hues = np.linspace(0, 360, num_species, endpoint=False)\n",
    "\n",
    "    # Create figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add traces for each species\n",
    "    for i, species in enumerate(species_list):\n",
    "        # Filter data for the species\n",
    "        df_species = df[df[\"Species\"] == species].sort_values(\"YEAR\")\n",
    "\n",
    "        # Define colors based on hue\n",
    "        hue = hues[i]\n",
    "        mean_color = f\"hsl({hue}, 100%, 40%)\"  # Darker for MEAN line\n",
    "        std_color = f\"hsl({hue}, 100%, 70%)\"  # Lighter for STD lines\n",
    "        fill_color = (\n",
    "            f\"hsla({hue}, 100%, 70%, 0.3)\"  # Even lighter with transparency for fill\n",
    "        )\n",
    "\n",
    "        if adjust_to_estimate_density_at_mouth == True:\n",
    "            lower_b = (\n",
    "                df_species[f\"MEAN_{date_metric}\"] - df_species[f\"STD_{date_metric}\"]\n",
    "            ) - how_much_to_adjust\n",
    "            upper_b = (\n",
    "                df_species[f\"MEAN_{date_metric}\"]\n",
    "                + df_species[f\"STD_{date_metric}\"]\n",
    "                - how_much_to_adjust\n",
    "            )\n",
    "            val_p = df_species[f\"MEAN_{date_metric}\"] - how_much_to_adjust\n",
    "            adjusted = f\"-Adjusted ({how_much_to_adjust} days)\"\n",
    "        else:\n",
    "            lower_b = (\n",
    "                df_species[f\"MEAN_{date_metric}\"] - df_species[f\"STD_{date_metric}\"]\n",
    "            )\n",
    "            upper_b = (\n",
    "                df_species[f\"MEAN_{date_metric}\"] + df_species[f\"STD_{date_metric}\"]\n",
    "            )\n",
    "            val_p = df_species[f\"MEAN_{date_metric}\"]\n",
    "            adjusted = \"\"\n",
    "\n",
    "        # Lower bound trace (MEAN - STD)\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_species[\"YEAR\"],\n",
    "                y=lower_b,\n",
    "                mode=\"lines\",\n",
    "                line=dict(color=std_color, width=1),\n",
    "                name=f\"{species} - STD\",\n",
    "                legendgroup=species,\n",
    "                showlegend=False,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Upper bound trace with fill to lower bound\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_species[\"YEAR\"],\n",
    "                y=upper_b,\n",
    "                mode=\"lines\",\n",
    "                line=dict(color=std_color, width=1),\n",
    "                fill=\"tonexty\",\n",
    "                fillcolor=fill_color,\n",
    "                name=f\"{species} + STD\",\n",
    "                legendgroup=species,\n",
    "                showlegend=False,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # MEAN line trace\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_species[\"YEAR\"],\n",
    "                y=val_p,\n",
    "                mode=\"lines\",\n",
    "                line=dict(color=mean_color, width=2),\n",
    "                name=species,\n",
    "                legendgroup=species,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Compute decade marks for grid lines\n",
    "    min_year = df[\"YEAR\"].min() // 10 * 10\n",
    "    max_year = (df[\"YEAR\"].max() // 10 + 1) * 10\n",
    "    decades = list(range(int(min_year), int(max_year) + 1, 10))\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=f\"Early Spring Run - Average Contributing Days at {dam_name} Dam by Species (Day 75 - 175) {adjusted}\",\n",
    "        xaxis_title=\"Year\",\n",
    "        yaxis_title=date_metric,\n",
    "        showlegend=True,\n",
    "        paper_bgcolor=\"white\",\n",
    "        plot_bgcolor=\"white\",\n",
    "        font=dict(color=\"black\"),\n",
    "        xaxis=dict(\n",
    "            gridcolor=\"lightgrey\",\n",
    "            showgrid=True,\n",
    "            tickmode=\"array\",\n",
    "            tickvals=decades,\n",
    "            title_font=dict(color=\"black\"),\n",
    "            tickfont=dict(color=\"black\"),\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            gridcolor=\"lightgrey\",\n",
    "            showgrid=True,\n",
    "            title_font=dict(color=\"black\"),\n",
    "            tickfont=dict(color=\"black\"),\n",
    "        ),\n",
    "    )\n",
    "    sights = orca_sightings_df_filtered.copy()\n",
    "    if date_metric == \"DoY\":\n",
    "        sights = sights.rename(columns={\"DOY\": \"DoY\"})\n",
    "    if date_metric == \"WoY\":\n",
    "        sights = sights.rename(columns={\"WOY\": \"WoY\"})\n",
    "    sights = sights[[\"YEAR\", \"POD_TYPE\", date_metric]].drop_duplicates()\n",
    "    sights = sights[sights[date_metric] < 180]\n",
    "    fig.add_scatter(\n",
    "        x=sights[sights.POD_TYPE == \"SRKW\"][\"YEAR\"],\n",
    "        y=sights[sights.POD_TYPE == \"SRKW\"][date_metric],\n",
    "        name=f\"Sightings (<{selected_buffer_distance}KM) - SRKW\",\n",
    "        mode=\"markers\",\n",
    "        marker_color=\"blue\",\n",
    "    )\n",
    "    fig.add_scatter(\n",
    "        x=sights[sights.POD_TYPE == \"OTHER\"][\"YEAR\"],\n",
    "        y=sights[sights.POD_TYPE == \"OTHER\"][date_metric],\n",
    "        name=f\"Sightings (<{selected_buffer_distance}KM) - OTHER\",\n",
    "        mode=\"markers\",\n",
    "        marker_color=\"green\",\n",
    "    )\n",
    "    fig.add_scatter(\n",
    "        x=sights[sights.POD_TYPE == \"TRANSIENT\"][\"YEAR\"],\n",
    "        y=sights[sights.POD_TYPE == \"TRANSIENT\"][date_metric],\n",
    "        name=f\"Sightings (<{selected_buffer_distance}KM) - TRANSIENT\",\n",
    "        mode=\"markers\",\n",
    "        marker_color=\"orange\",\n",
    "    )\n",
    "\n",
    "    # Assign colors and shapes for NEAR_MOUTH\n",
    "    near_mouth_values = tags[\"NEAR_MOUTH\"].unique()\n",
    "\n",
    "    colors = [\"#1f77b4\", \"#ff7f0e\"]\n",
    "    shapes = [\"cross\", \"star\"]\n",
    "    near_mouth_map = {\n",
    "        val: {\"color\": colors[i], \"shape\": shapes[i]}\n",
    "        for i, val in enumerate(near_mouth_values)\n",
    "    }\n",
    "\n",
    "    # Add scatter for tags\n",
    "    for near_mouth in near_mouth_values:\n",
    "        tags_subset = tags[tags[\"NEAR_MOUTH\"] == near_mouth]\n",
    "        if date_metric == \"DoY\":\n",
    "            tags_subset = tags_subset.rename(columns={\"DOY\": \"DoY\"})\n",
    "        if date_metric == \"WoY\":\n",
    "            tags_subset = tags_subset.rename(columns={\"WOY\": \"WoY\"})\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=tags_subset[\"YEAR\"],\n",
    "                y=tags_subset[date_metric],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(\n",
    "                    color=\"black\",\n",
    "                    symbol=\"x\",\n",
    "                    size=4,\n",
    "                    # line=dict(width=1, color=\"black\"),\n",
    "                ),\n",
    "                name=f\"Tagged (<{selected_buffer_distance}KM) - SRKW\",\n",
    "                legendgroup=f\"Tagged (<{selected_buffer_distance}KM) - SRKW\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_analysis(\n",
    "    test_,\n",
    "    dam_name,\n",
    "    species_name,\n",
    "    date_metric,\n",
    "    long_term_median,\n",
    "    orca_sightings_df_filtered,\n",
    "    date_upper_limit,\n",
    "):\n",
    "    fig = px.line(title=f\"Analysis of WoY Count at {dam_name} - {species_name}\")\n",
    "    fig.add_scatter(\n",
    "        y=test_[f\"MEAN_{date_metric}\"],\n",
    "        x=test_[\"YEAR\"],\n",
    "        name=f\"Mean Revist ({date_metric}) \",\n",
    "        marker_color=\"#F4442E\",\n",
    "    )\n",
    "    fig.add_scatter(\n",
    "        y=test_[f\"MEAN_{date_metric}\"] + test_[f\"STD_{date_metric}\"],\n",
    "        x=test_[\"YEAR\"],\n",
    "        name=\"Upper Bounds\",\n",
    "        marker_color=\"#FFB7AE\",\n",
    "    )\n",
    "    fig.add_scatter(\n",
    "        y=test_[f\"MEAN_{date_metric}\"] - test_[f\"STD_{date_metric}\"],\n",
    "        x=test_[\"YEAR\"],\n",
    "        name=\"Lower Bounds\",\n",
    "        marker_color=\"#FFB7AE\",\n",
    "    )\n",
    "\n",
    "    sights = orca_sightings_df_filtered.copy()\n",
    "    if date_metric == \"DoY\":\n",
    "        sights = sights.rename(columns={\"DOY\": \"DoY\"})\n",
    "    sights = sights[[\"YEAR\", \"POD_TYPE\", date_metric]].drop_duplicates()\n",
    "    sights = sights[sights[date_metric] < date_upper_limit]\n",
    "    fig.add_scatter(\n",
    "        x=sights[sights.POD_TYPE == \"SRKW\"][\"YEAR\"],\n",
    "        y=sights[sights.POD_TYPE == \"SRKW\"][date_metric],\n",
    "        name=\"Sightings (<115KM) - SRKW\",\n",
    "        mode=\"markers\",\n",
    "        marker_color=\"blue\",\n",
    "    )\n",
    "    fig.add_scatter(\n",
    "        x=sights[sights.POD_TYPE == \"OTHER\"][\"YEAR\"],\n",
    "        y=sights[sights.POD_TYPE == \"OTHER\"][date_metric],\n",
    "        name=\"Sightings (<115KM) - OTHER\",\n",
    "        mode=\"markers\",\n",
    "        marker_color=\"green\",\n",
    "    )\n",
    "    fig.add_scatter(\n",
    "        x=sights[sights.POD_TYPE == \"TRANSIENT\"][\"YEAR\"],\n",
    "        y=sights[sights.POD_TYPE == \"TRANSIENT\"][date_metric],\n",
    "        name=\"Sightings (<115KM) - TRANSIENT\",\n",
    "        mode=\"markers\",\n",
    "        marker_color=\"orange\",\n",
    "    )\n",
    "\n",
    "    fig.add_hline(y=long_term_median)\n",
    "\n",
    "    # # Update layout\n",
    "    fig.update_layout(\n",
    "        title=f\"{dam_name} Dam - {species_name} Counts by {date_metric} vs. Columbia River Mouth Killer Whale Sightings\",\n",
    "        xaxis_title=\"Year\",\n",
    "        yaxis_title=date_metric,\n",
    "        legend_title=\"Year\",\n",
    "        plot_bgcolor=\"white\",  # Black background\n",
    "        paper_bgcolor=\"white\",  # Black surrounding area\n",
    "        font=dict(color=\"black\"),  # White text for labels\n",
    "        # showlegend=True,\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "def build_dam_peak_analysis(\n",
    "    dam_data_raw, dam_name, species_name, date_metric, min_date_metric, max_date_metric\n",
    "):\n",
    "    dam_data_preproc = dam_data_raw[\n",
    "        (dam_data_raw[date_metric] >= min_date_metric)\n",
    "        & (dam_data_raw[date_metric] <= max_date_metric)\n",
    "    ]\n",
    "\n",
    "    dam_data_preproc = dam_data_preproc[dam_data_preproc.Species == species_name]\n",
    "    dam_data_preproc[\"Year\"] = dam_data_preproc[\"Year\"].astype(int)\n",
    "    dam_data_preproc = dam_data_preproc.sort_values(date_metric).reset_index(drop=True)\n",
    "    dam_data_preproc[\"Decade\"] = dam_data_preproc[\"Year\"].astype(str).str[0:3]\n",
    "    dam_data_preproc[\"Decade\"] = (\n",
    "        dam_data_preproc[\"Decade\"].apply(lambda x: f\"{x}0\").astype(int)\n",
    "    )\n",
    "    dam_data_preproc = dam_data_preproc[dam_data_preproc.Count >= 0]\n",
    "\n",
    "    # Get Analysis Table\n",
    "    woy_analysis_table, long_term_median = run_analysis_on_dams(\n",
    "        dam_data_preproc, date_metric=date_metric\n",
    "    )\n",
    "    woy_analysis_table[\"Species\"] = species_name\n",
    "    woy_analysis_table[\"Dam\"] = dam_name\n",
    "    woy_analysis_table[\"LongTermMedian\"] = long_term_median\n",
    "\n",
    "    add_decade = dam_data_preproc[[\"Year\", \"Decade\"]].drop_duplicates()\n",
    "    add_decade.columns = [\"YEAR\", \"DECADE\"]\n",
    "\n",
    "    woy_analysis_table = pd.merge(woy_analysis_table, add_decade)\n",
    "\n",
    "    woy_analysis_table = pd.merge(\n",
    "        woy_analysis_table,\n",
    "        woy_analysis_table.groupby(\"DECADE\", as_index=False).agg(\n",
    "            DECADE_AVG=(f\"MEAN_{date_metric}\", \"mean\")\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    woy_analysis_table = pd.merge(\n",
    "        woy_analysis_table,\n",
    "        woy_analysis_table.groupby(\"DECADE\", as_index=False).agg(\n",
    "            DECADE_STD=(f\"STD_{date_metric}\", \"mean\")\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    return woy_analysis_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e8b3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in bonneville data\n",
    "bon_raw = pd.read_parquet(\n",
    "    \"../data/processed/FPC_DAM_COUNTS/Bonneville_FPC_DAM_COUNTS.parquet\"\n",
    ")\n",
    "\n",
    "wlm_raw = pd.read_parquet(\n",
    "    \"../data/processed/FPC_DAM_COUNTS/Willamette_FPC_DAM_COUNTS.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a017020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Area Plot\n",
    "fig, bon_ = plot_area_plot_stacked(\n",
    "    pd.concat([wlm_raw, bon_raw]),\n",
    "    metric=\"WoY\",\n",
    "    metric_lower=10,\n",
    "    metric_upper=25,\n",
    "    dam=\"Willamette + Bonneville\",\n",
    "    species = 'ChinookAdult'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faac1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_metric = \"WoY\"\n",
    "min_date_metric = 0\n",
    "max_date_metric = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb6abcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Bonneville Raw Species Analysis Data\n",
    "bon_species_table = get_species_table(\n",
    "    dam_data_raw=bon_raw,\n",
    "    dam_name=\"Bonneville\",\n",
    "    date_metric=date_metric,\n",
    "    min_date_metric=min_date_metric,\n",
    "    max_date_metric=max_date_metric,\n",
    ")\n",
    "\n",
    "# Get Willamette Raw Species Analysis Data\n",
    "wlm_raw_species_table = get_species_table(\n",
    "    dam_data_raw=wlm_raw,\n",
    "    dam_name=\"Willamette\",\n",
    "    date_metric=date_metric,\n",
    "    min_date_metric=min_date_metric,\n",
    "    max_date_metric=max_date_metric,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bea5a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to Common Meals for SRKW\n",
    "species_list = [\"ChinookAdult\", \"ChinookJack\", \"Steelhead\"]\n",
    "\n",
    "df_wlm = wlm_raw_species_table[wlm_raw_species_table.Species.isin(species_list)].copy()\n",
    "df_wlm[\"Species\"] = df_wlm[\"Species\"].apply(lambda x: f\"{x} - Willamette\")\n",
    "\n",
    "df_bon = bon_species_table[bon_species_table.Species.isin(species_list)].copy()\n",
    "df_bon[\"Species\"] = df_bon[\"Species\"].apply(lambda x: f\"{x} - Bonneville\")\n",
    "\n",
    "df = pd.concat([df_wlm, df_bon])\n",
    "\n",
    "fig = plot_species_area_plot_at_dam(\n",
    "    df,\n",
    "    dam_name=\"Bonenville / Willamette\",\n",
    "    orca_sightings_df_filtered=orca_sightings_df_filtered,\n",
    "    selected_buffer_distance=selected_buffer_distance,\n",
    "    tags=tags,\n",
    "    date_metric=date_metric,\n",
    "    adjust_to_estimate_density_at_mouth=False,\n",
    "    how_much_to_adjust=1,\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83fbfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get Area Plot\n",
    "# fig, bon_ = plot_area_plot_stacked(\n",
    "#     wlm_raw,\n",
    "#     metric=\"WoY\",\n",
    "#     metric_lower=0,\n",
    "#     metric_upper=30,\n",
    "#     dam=\"Willamette\",\n",
    "#     species=\"ChinookAdult\",\n",
    "# )\n",
    "# fig.add_scatter(\n",
    "#     x=orca_sightings_df_filtered[orca_sightings_df_filtered.POD_TYPE == \"SRKW\"][\"WOY\"],\n",
    "#     y=[np.max(wlm_raw[\"Count\"])]\n",
    "#     * len(orca_sightings_df_filtered[orca_sightings_df_filtered.POD_TYPE == \"SRKW\"]),\n",
    "#     mode=\"markers\",\n",
    "#     marker_color=\"yellow\",\n",
    "#     name=\"SRKW - Sightings\",\n",
    "# )\n",
    "\n",
    "# fig.add_scatter(\n",
    "#     x=orca_sightings_df_filtered[orca_sightings_df_filtered.POD_TYPE != \"SRKW\"][\"WOY\"],\n",
    "#     y=[1.1 * np.max(wlm_raw[\"Count\"])]\n",
    "#     * len(orca_sightings_df_filtered[orca_sightings_df_filtered.POD_TYPE != \"SRKW\"]),\n",
    "#     mode=\"markers\",\n",
    "#     marker_color=\"turquoise\",\n",
    "#     name=\"OTHER - Sightings\",\n",
    "# )\n",
    "# fig.show()\n",
    "\n",
    "# # Get Area Plot\n",
    "# fig, bon_ = plot_area_plot_stacked(\n",
    "#     wlm_raw,\n",
    "#     metric=\"WoY\",\n",
    "#     metric_lower=0,\n",
    "#     metric_upper=30,\n",
    "#     dam=\"Willamette\",\n",
    "#     species=\"ChinookJack\",\n",
    "# )\n",
    "# fig.add_scatter(\n",
    "#     x=orca_sightings_df_filtered[orca_sightings_df_filtered.POD_TYPE == \"SRKW\"][\"WOY\"],\n",
    "#     y=[np.max(wlm_raw[\"Count\"])]\n",
    "#     * len(orca_sightings_df_filtered[orca_sightings_df_filtered.POD_TYPE == \"SRKW\"]),\n",
    "#     mode=\"markers\",\n",
    "#     marker_color=\"yellow\",\n",
    "#     name=\"SRKW - Sightings\",\n",
    "# )\n",
    "\n",
    "# fig.add_scatter(\n",
    "#     x=orca_sightings_df_filtered[orca_sightings_df_filtered.POD_TYPE != \"SRKW\"][\"WOY\"],\n",
    "#     y=[1.1 * np.max(bon_[\"Count\"])]\n",
    "#     * len(orca_sightings_df_filtered[orca_sightings_df_filtered.POD_TYPE != \"SRKW\"]),\n",
    "#     mode=\"markers\",\n",
    "#     marker_color=\"turquoise\",\n",
    "#     name=\"OTHER - Sightings\",\n",
    "# )\n",
    "# fig.show()\n",
    "\n",
    "# # Get Area Plot\n",
    "# fig, bon_ = plot_area_plot_stacked(\n",
    "#     wlm_raw,\n",
    "#     metric=\"WoY\",\n",
    "#     metric_lower=0,\n",
    "#     metric_upper=30,\n",
    "#     dam=\"Willamette\",\n",
    "#     species=\"Steelhead\",\n",
    "# )\n",
    "# fig.add_scatter(\n",
    "#     x=orca_sightings_df_filtered[orca_sightings_df_filtered.POD_TYPE == \"SRKW\"][\"WOY\"],\n",
    "#     y=[np.max(bon_[\"Count\"])]\n",
    "#     * len(orca_sightings_df_filtered[orca_sightings_df_filtered.POD_TYPE == \"SRKW\"]),\n",
    "#     mode=\"markers\",\n",
    "#     marker_color=\"yellow\",\n",
    "#     name=\"SRKW - Sightings\",\n",
    "# )\n",
    "\n",
    "# fig.add_scatter(\n",
    "#     x=orca_sightings_df_filtered[orca_sightings_df_filtered.POD_TYPE != \"SRKW\"][\"WOY\"],\n",
    "#     y=[1.1 * np.max(bon_[\"Count\"])]\n",
    "#     * len(orca_sightings_df_filtered[orca_sightings_df_filtered.POD_TYPE != \"SRKW\"]),\n",
    "#     mode=\"markers\",\n",
    "#     marker_color=\"turquoise\",\n",
    "#     name=\"OTHER - Sightings\",\n",
    "# )\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3de5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# orca_sightings_df_filtered.explore(\n",
    "#     \"WOY\", marker_kwds=dict(radius=10, fill=True), cmap=\"RdBu\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000bcc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "orca_sightings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574d1035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "# Define the bounding box coordinates\n",
    "min_lon = -135.4  # Western boundary (100 km west of ~124.5Â°W coast)\n",
    "max_lon = -123.5  # Eastern boundary (inland)\n",
    "min_lat = 40.5  # Southern boundary (near CA-Mexico border)\n",
    "max_lat = 48.0  # Northern boundary (near WA-Canada border)\n",
    "\n",
    "# Create a polygon for the bounding box\n",
    "bbox = Polygon(\n",
    "    [\n",
    "        (min_lon, min_lat),  # SW corner\n",
    "        (min_lon, max_lat),  # NW corner\n",
    "        (max_lon, max_lat),  # NE corner\n",
    "        (max_lon, min_lat),  # SE corner\n",
    "        (min_lon, min_lat),  # Close the polygon\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a GeoDataFrame\n",
    "gdf1 = gpd.GeoDataFrame(geometry=[bbox], crs=\"EPSG:4326\")\n",
    "\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "# Define the bounding box coordinates\n",
    "min_lon = -135.4  # Western boundary (100 km west of ~124.5Â°W coast)\n",
    "max_lon = -112.1  # Eastern boundary (inland)\n",
    "min_lat = 30.5  # Southern boundary (near CA-Mexico border)\n",
    "max_lat = 44  # Northern boundary (near WA-Canada border)\n",
    "\n",
    "# Create a polygon for the bounding box\n",
    "bbox = Polygon(\n",
    "    [\n",
    "        (min_lon, min_lat),  # SW corner\n",
    "        (min_lon, max_lat),  # NW corner\n",
    "        (max_lon, max_lat),  # NE corner\n",
    "        (max_lon, min_lat),  # SE corner\n",
    "        (min_lon, min_lat),  # Close the polygon\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a GeoDataFrame\n",
    "gdf2 = gpd.GeoDataFrame(geometry=[bbox], crs=\"EPSG:4326\")\n",
    "\n",
    "# Define the bounding box coordinates\n",
    "min_lon = -135.4  # Western boundary (100 km west of ~124.5Â°W coast)\n",
    "max_lon = -124.5  # Eastern boundary (inland)\n",
    "min_lat = 47.5  # Southern boundary (near CA-Mexico border)\n",
    "max_lat = 49.0  # Northern boundary (near WA-Canada border)\n",
    "\n",
    "# Create a polygon for the bounding box\n",
    "bbox = Polygon(\n",
    "    [\n",
    "        (min_lon, min_lat),  # SW corner\n",
    "        (min_lon, max_lat),  # NW corner\n",
    "        (max_lon, max_lat),  # NE corner\n",
    "        (max_lon, min_lat),  # SE corner\n",
    "        (min_lon, min_lat),  # Close the polygon\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a GeoDataFrame\n",
    "gdf3 = gpd.GeoDataFrame(geometry=[bbox], crs=\"EPSG:4326\")\n",
    "\n",
    "\n",
    "# gdf = pd.concat([gdf2, gdf1, gdf3]).dissolve()\n",
    "gdf = pd.concat([gdf2, gdf1]).dissolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c513e6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "coast_sightings = orca_sightings_df.sjoin(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf9efa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186fd7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(coast_sightings, x=\"WOY\", y=\"LATITUDE\", color=\"POD_TYPE\")\n",
    "fig.add_hline(y=46.1)\n",
    "fig.add_hline(y=38.33)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa49a8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "data = coast_sightings[coast_sightings.POD_TYPE == \"SRKW\"]\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data[[\"LATITUDE\", \"WOY\"]])\n",
    "\n",
    "# Apply K-means clustering\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "data[\"Cluster\"] = kmeans.fit_predict(scaled_data)\n",
    "\n",
    "# Visualize the clusters\n",
    "plt.scatter(data[\"LATITUDE\"], data[\"WOY\"], c=data[\"Cluster\"], cmap=\"viridis\")\n",
    "plt.xlabel(\"Latitude\")\n",
    "plt.ylabel(\"Week of Year\")\n",
    "plt.title(\"K-means Clustering (k=3)\")\n",
    "plt.show()\n",
    "\n",
    "# Summarize cluster centers\n",
    "centers = scaler.inverse_transform(kmeans.cluster_centers_)\n",
    "print(\"Cluster Centers (LATITUDE, WOY):\")\n",
    "for i, center in enumerate(centers):\n",
    "    print(f\"Cluster {i}: {center}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59684f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Cluster\"] = data[\"Cluster\"].astype(str)\n",
    "fig = px.scatter(data, x=\"WOY\", y=\"LATITUDE\", color=\"Cluster\")\n",
    "fig.add_hline(y=46.1)\n",
    "fig.add_hline(y=38.33)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f62b3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(data, x=\"YEAR_WEEK\", y=\"LATITUDE\", color=\"WOY\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06d37d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "coast_Tags = tagging_gdf.drop(columns=\"index_right\").sjoin(gdf)\n",
    "coast_Tags[\"MONTH\"] = coast_Tags[\"DATETIME\"].dt.month.astype(float)\n",
    "coast_Tags[\"WOY\"] = coast_Tags[\"WOY\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6e5f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(coast_Tags, y=\"lat_p\", x=\"DATE\", color=\"WOY\")\n",
    "fig.add_hline(y=46.1)\n",
    "fig.add_hline(y=38.33)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1e39fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "coast_Tags.popid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cc73be",
   "metadata": {},
   "outputs": [],
   "source": [
    "coast_Tags.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344ac5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(coast_Tags, y=\"lat_p\", x=\"DOY\", color=\"popid\")\n",
    "\n",
    "fig.add_hline(\n",
    "    y=46.2,\n",
    "    line_dash=\"dot\",\n",
    "    line_color=\"black\",\n",
    "    opacity=0.25,\n",
    "    annotation_text=\"Columbia River\",  # The text for the annotation\n",
    "    annotation_position=\"top right\",  # The position of the annotation relative to the line\n",
    ")\n",
    "\n",
    "fig.add_hline(\n",
    "    y=40.65,\n",
    "    line_dash=\"dot\",\n",
    "    line_color=\"black\",\n",
    "    opacity=0.25,\n",
    "    annotation_text=\"Eel River\",  # The text for the annotation\n",
    "    annotation_position=\"top right\",  # The position of the annotation relative to the line\n",
    ")\n",
    "\n",
    "\n",
    "fig.add_hline(\n",
    "    y=46.95,\n",
    "    line_dash=\"dot\",\n",
    "    line_color=\"black\",\n",
    "    opacity=0.25,\n",
    "    annotation_text=\"Chehalis River\",  # The text for the annotation\n",
    "    annotation_position=\"top right\",  # The position of the annotation relative to the line\n",
    ")\n",
    "\n",
    "fig.add_hline(\n",
    "    y=47.55,  # The y-coordinate of the horizontal line\n",
    "    line_dash=\"dot\",\n",
    "    line_color=\"black\",\n",
    "    opacity=0.25,\n",
    "    annotation_text=\"Queets River\",  # The text for the annotation\n",
    "    annotation_position=\"top right\",  # The position of the annotation relative to the line\n",
    ")\n",
    "\n",
    "fig.add_hline(\n",
    "    y=38.33,  # The y-coordinate of the horizontal line\n",
    "    line_dash=\"dot\",\n",
    "    line_color=\"black\",\n",
    "    opacity=0.25,\n",
    "    annotation_text=\"Sacramento River\",  # The text for the annotation\n",
    "    annotation_position=\"top right\",  # The position of the annotation relative to the line\n",
    ")\n",
    "\n",
    "fig.add_hline(\n",
    "    y=36.78,  # The y-coordinate of the horizontal line\n",
    "    line_dash=\"dot\",\n",
    "    line_color=\"black\",\n",
    "    opacity=0.25,\n",
    "    annotation_text=\"Monterey Bay\",  # The text for the annotation\n",
    "    annotation_position=\"top right\",  # The position of the annotation relative to the line\n",
    ")\n",
    "\n",
    "fig.add_hline(\n",
    "    y=44.64,  # The y-coordinate of the horizontal line\n",
    "    line_dash=\"dot\",\n",
    "    line_color=\"black\",\n",
    "    opacity=0.25,\n",
    "    annotation_text=\"Newport\",  # The text for the annotation\n",
    "    annotation_position=\"top right\",  # The position of the annotation relative to the line\n",
    ")\n",
    "fig.add_hline(\n",
    "    y=43.67,  # The y-coordinate of the horizontal line\n",
    "    line_dash=\"dot\",\n",
    "    line_color=\"black\",\n",
    "    opacity=0.25,\n",
    "    annotation_text=\"Umpqua River\",  # The text for the annotation\n",
    "    annotation_position=\"top right\",  # The position of the annotation relative to the line\n",
    ")\n",
    "\n",
    "dd_ = coast_sightings[coast_sightings.POD_TYPE == \"SRKW\"]\n",
    "for pdtag in dd_.POD_TAG.unique():\n",
    "    tmpp = dd_[dd_.POD_TAG == pdtag]\n",
    "    if \"L\" in pdtag:\n",
    "        color_val = \"#fb8500\"\n",
    "    elif \"J\" in pdtag:\n",
    "        color_val = \"#fb6f92\"\n",
    "    elif \"K\" in pdtag:\n",
    "        color_val = \"#31572c\"\n",
    "    fig.add_scatter(\n",
    "        x=tmpp[\"DOY\"],\n",
    "        y=tmpp[\"LATITUDE\"],\n",
    "        name=pdtag,\n",
    "        mode=\"markers\",\n",
    "        marker_color=color_val,\n",
    "    )\n",
    "\n",
    "import calendar\n",
    "\n",
    "# Month start/end DOY\n",
    "month_bounds = []\n",
    "current_doy = 1\n",
    "for month in range(1, 13):\n",
    "    days_in_month = calendar.monthrange(2024, month)[1]  # leap year if needed\n",
    "    month_bounds.append(\n",
    "        (current_doy, current_doy + days_in_month - 1, calendar.month_abbr[month])\n",
    "    )\n",
    "    current_doy += days_in_month\n",
    "\n",
    "# Add shaded bands for months\n",
    "for start_doy, end_doy, month_name in month_bounds:\n",
    "    fig.add_vrect(\n",
    "        x0=start_doy,\n",
    "        x1=end_doy,\n",
    "        fillcolor=\"white\",\n",
    "        opacity=0.0,\n",
    "        line_width=1,\n",
    "        line_color=\"black\",\n",
    "        annotation_text=month_name,\n",
    "        annotation_position=\"top left\",\n",
    "    )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edefeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(coast_Tags, y=\"lat_p\", x=\"DOY\", color=\"popid\")\n",
    "\n",
    "fig.add_hline(\n",
    "    y=46.2,\n",
    "    line_dash=\"dot\",\n",
    "    line_color=\"black\",\n",
    "    opacity=0.25,\n",
    "    annotation_text=\"Columbia River\",  # The text for the annotation\n",
    "    annotation_position=\"top right\",  # The position of the annotation relative to the line\n",
    ")\n",
    "\n",
    "fig.add_hline(\n",
    "    y=40.65,\n",
    "    line_dash=\"dot\",\n",
    "    line_color=\"black\",\n",
    "    opacity=0.25,\n",
    "    annotation_text=\"Eel River\",  # The text for the annotation\n",
    "    annotation_position=\"top right\",  # The position of the annotation relative to the line\n",
    ")\n",
    "\n",
    "\n",
    "fig.add_hline(\n",
    "    y=46.95,\n",
    "    line_dash=\"dot\",\n",
    "    line_color=\"black\",\n",
    "    opacity=0.25,\n",
    "    annotation_text=\"Chehalis River\",  # The text for the annotation\n",
    "    annotation_position=\"top right\",  # The position of the annotation relative to the line\n",
    ")\n",
    "\n",
    "fig.add_hline(\n",
    "    y=47.55,  # The y-coordinate of the horizontal line\n",
    "    line_dash=\"dot\",\n",
    "    line_color=\"black\",\n",
    "    opacity=0.25,\n",
    "    annotation_text=\"Queets River\",  # The text for the annotation\n",
    "    annotation_position=\"top right\",  # The position of the annotation relative to the line\n",
    ")\n",
    "\n",
    "fig.add_hline(\n",
    "    y=38.33,  # The y-coordinate of the horizontal line\n",
    "    line_dash=\"dot\",\n",
    "    line_color=\"black\",\n",
    "    opacity=0.25,\n",
    "    annotation_text=\"Sacramento River\",  # The text for the annotation\n",
    "    annotation_position=\"top right\",  # The position of the annotation relative to the line\n",
    ")\n",
    "\n",
    "fig.add_hline(\n",
    "    y=36.78,  # The y-coordinate of the horizontal line\n",
    "    line_dash=\"dot\",\n",
    "    line_color=\"black\",\n",
    "    opacity=0.25,\n",
    "    annotation_text=\"Monterey Bay\",  # The text for the annotation\n",
    "    annotation_position=\"top right\",  # The position of the annotation relative to the line\n",
    ")\n",
    "\n",
    "fig.add_hline(\n",
    "    y=44.64,  # The y-coordinate of the horizontal line\n",
    "    line_dash=\"dot\",\n",
    "    line_color=\"black\",\n",
    "    opacity=0.25,\n",
    "    annotation_text=\"Newport\",  # The text for the annotation\n",
    "    annotation_position=\"top right\",  # The position of the annotation relative to the line\n",
    ")\n",
    "fig.add_hline(\n",
    "    y=43.67,  # The y-coordinate of the horizontal line\n",
    "    line_dash=\"dot\",\n",
    "    line_color=\"black\",\n",
    "    opacity=0.25,\n",
    "    annotation_text=\"Umpqua River\",  # The text for the annotation\n",
    "    annotation_position=\"top right\",  # The position of the annotation relative to the line\n",
    ")\n",
    "\n",
    "dd_ = coast_sightings.copy()#[coast_sightings.POD_TYPE != \"SRKW\"]\n",
    "for pdtag in dd_.POD_TAG.unique():\n",
    "    tmpp = dd_[dd_.POD_TAG == pdtag]\n",
    "    if \"L\" in pdtag:\n",
    "        color_val = \"#fb8500\"\n",
    "    elif \"J\" in pdtag:\n",
    "        color_val = \"#fb6f92\"\n",
    "    elif \"K\" in pdtag:\n",
    "        color_val = \"#31572c\"\n",
    "    elif \"T\" in pdtag:\n",
    "        color_val = \"#ffbe0b\"\n",
    "    elif \"O\" in pdtag:\n",
    "        color_val = \"#00f5d4\"\n",
    "    fig.add_scatter(\n",
    "        x=tmpp[\"DOY\"],\n",
    "        y=tmpp[\"LATITUDE\"],\n",
    "        name=pdtag,\n",
    "        mode=\"markers\",\n",
    "        marker_color=color_val,\n",
    "    )\n",
    "\n",
    "import calendar\n",
    "\n",
    "# Month start/end DOY\n",
    "month_bounds = []\n",
    "current_doy = 1\n",
    "for month in range(1, 13):\n",
    "    days_in_month = calendar.monthrange(2024, month)[1]  # leap year if needed\n",
    "    month_bounds.append(\n",
    "        (current_doy, current_doy + days_in_month - 1, calendar.month_abbr[month])\n",
    "    )\n",
    "    current_doy += days_in_month\n",
    "\n",
    "# Add shaded bands for months\n",
    "for start_doy, end_doy, month_name in month_bounds:\n",
    "    fig.add_vrect(\n",
    "        x0=start_doy,\n",
    "        x1=end_doy,\n",
    "        fillcolor=\"white\",\n",
    "        opacity=0.0,\n",
    "        line_width=1,\n",
    "        line_color=\"black\",\n",
    "        annotation_text=month_name,\n",
    "        annotation_position=\"top left\",\n",
    "    )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ba9127",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salmonsignal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
