{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b71a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------- #\n",
    "#                         MODULES                         #\n",
    "\n",
    "# Standard Modules\n",
    "import os\n",
    "\n",
    "# Third Party Modules\n",
    "import glob\n",
    "import h3\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "from typing import Literal\n",
    "from datetime import datetime, timedelta\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\n",
    "# ------------------------------------------------------- #\n",
    "#                         FUNCTIONS                       #\n",
    "\n",
    "###############################\n",
    "# FPC Data Pipeline\n",
    "\n",
    "\n",
    "# Dam Preprocessing Pipeline\n",
    "def prepare_data(path, location_name):\n",
    "    # Open Data\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Filter to Dam Code\n",
    "    df = df[df[\"Dam\"].str.len() == 3]\n",
    "\n",
    "    # Melt\n",
    "    df_long = df.melt(\n",
    "        id_vars=[\"Dam\", \"Date\"],\n",
    "        var_name=\"Species\",\n",
    "        value_name=\"Count\",\n",
    "    )\n",
    "\n",
    "    # Remove Null Rows\n",
    "    df_long = df_long.dropna(subset=\"Count\")\n",
    "\n",
    "    # Add Location Name\n",
    "    df_long[\"Location\"] = location_name\n",
    "\n",
    "    # Aggregate\n",
    "    df_long = df_long.groupby([\"Dam\", \"Date\", \"Species\", \"Location\"], as_index=False)[\n",
    "        \"Count\"\n",
    "    ].sum()\n",
    "\n",
    "    # Make Date Type\n",
    "    df_long[\"Datetime\"] = pd.to_datetime(df_long[\"Date\"])\n",
    "    df_long[\"Date\"] = df_long[\"Datetime\"].dt.date\n",
    "    df_long[\"DoY\"] = df_long[\"Datetime\"].dt.day_of_year\n",
    "    df_long[\"WoY\"] = df_long[\"Datetime\"].dt.isocalendar().week\n",
    "    df_long[\"Month\"] = df_long[\"Datetime\"].dt.month\n",
    "    df_long[\"Year\"] = df_long[\"Datetime\"].dt.year\n",
    "    df_long[\"YEAR_WEEK\"] = df_long[\"Datetime\"].dt.strftime(\"%Y-%U\")\n",
    "    df_long[\"YEAR_MONTH\"] = df_long[\"Datetime\"].dt.strftime(\"%Y-%m-01\")\n",
    "\n",
    "    # Calculate the weekday number (Monday=0, Sunday=6)\n",
    "    weekday_num = df_long[\"Datetime\"].dt.weekday\n",
    "\n",
    "    # Calculate the date of the previous Sunday by subtracting (weekday_num + 1) % 7 days\n",
    "    df_long[\"Stat_Week_Sunday\"] = df_long[\"Datetime\"] - pd.to_timedelta(\n",
    "        (weekday_num + 1) % 7, unit=\"D\"\n",
    "    )\n",
    "\n",
    "    # Standardize by D-o-Y for Each Species and Dam\n",
    "    df_long = pd.merge(\n",
    "        df_long,\n",
    "        df_long.groupby([\"Year\", \"Species\", \"Dam\"], as_index=False).agg(\n",
    "            Mean_DoY_Count=(\"Count\", \"mean\"), Std_DoY_Count=(\"Count\", \"std\")\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    df_long[\"DoY_ZScore\"] = (df_long[\"Count\"] - df_long[\"Mean_DoY_Count\"]) / df_long[\n",
    "        \"Std_DoY_Count\"\n",
    "    ]\n",
    "\n",
    "    df_long[\"DoY_ZScore\"] = df_long[\"DoY_ZScore\"].fillna(0)\n",
    "\n",
    "    return df_long\n",
    "\n",
    "\n",
    "# Save the Data to File\n",
    "def save_to_file(output_dir, df_long, location_name):\n",
    "    # Make Output Directory\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Output Path\n",
    "    output_path = f\"{output_dir}/{location_name}_FPC_DAM_COUNTS.parquet\"\n",
    "\n",
    "    # Save to File\n",
    "    df_long.to_parquet(output_path)\n",
    "\n",
    "\n",
    "###############################\n",
    "# Load Data\n",
    "\n",
    "\n",
    "# Load Columbia River Spatial Layers\n",
    "def load_columbia_river_data():\n",
    "    # Define Pathing\n",
    "    ## Marine Areas\n",
    "    if os.path.exists(\"../data/processed/GIS/ocean/TERRITORIAL_COLUMBIA_MOUNT.parquet\"):\n",
    "        columbia_path = \"../data/processed/GIS/ocean/TERRITORIAL_COLUMBIA_MOUNT.parquet\"\n",
    "    elif os.path.exists(\n",
    "        \"../../data/processed/GIS/ocean/TERRITORIAL_COLUMBIA_MOUNT.parquet\"\n",
    "    ):\n",
    "        columbia_path = \"../data/processed/GIS/ocean/TERRITORIAL_COLUMBIA_MOUNT.parquet\"\n",
    "\n",
    "    ## River Network\n",
    "    if os.path.exists(\n",
    "        \"../data/processed/GIS/inland_waters/US_INLAND_WATERS_COLUMBIA_R.parquet\"\n",
    "    ):\n",
    "        network_path = (\n",
    "            \"../data/processed/GIS/inland_waters/US_INLAND_WATERS_COLUMBIA_R.parquet\"\n",
    "        )\n",
    "    elif os.path.exists(\n",
    "        \"../../data/processed/GIS/inland_waters/US_INLAND_WATERS_COLUMBIA_R.parquet\"\n",
    "    ):\n",
    "        network_path = (\n",
    "            \"../../data/processed/GIS/inland_waters/US_INLAND_WATERS_COLUMBIA_R.parquet\"\n",
    "        )\n",
    "\n",
    "    ## Dam Locations\n",
    "    if os.path.exists(\n",
    "        \"../data/processed/GIS/important_locations/columbia_snake_dams.parquet\"\n",
    "    ):\n",
    "        dam_path = (\n",
    "            \"../data/processed/GIS/important_locations/columbia_snake_dams.parquet\"\n",
    "        )\n",
    "    elif os.path.exists(\n",
    "        \"../../data/processed/GIS/important_locations/columbia_snake_dams.parquet\"\n",
    "    ):\n",
    "        dam_path = (\n",
    "            \"../../data/processed/GIS/important_locations/columbia_snake_dams.parquet\"\n",
    "        )\n",
    "\n",
    "    # Data loading (unchanged)\n",
    "    columbia_river_mouth = gpd.read_parquet(columbia_path).to_crs(\"EPSG:4326\")\n",
    "    river_gdf = gpd.read_parquet(network_path).to_crs(\"EPSG:4326\")\n",
    "    dams = gpd.read_parquet(dam_path).to_crs(\"EPSG:4326\")\n",
    "\n",
    "    return columbia_river_mouth, river_gdf, dams\n",
    "\n",
    "\n",
    "#  Load Dam Counts\n",
    "def load_dam_counts(dam_count_directory):\n",
    "    if os.path.exists(dam_count_directory):\n",
    "        dam_counts_df = pd.read_parquet(dam_count_directory)\n",
    "\n",
    "    elif os.path.exists(f\"../{dam_count_directory}\"):\n",
    "        dam_counts_df = pd.read_parquet(f\"../{dam_count_directory}\")\n",
    "\n",
    "    else:\n",
    "        return print(\"DAM COUNTS UNAVAILABLE\")\n",
    "\n",
    "    # Standardize Columns\n",
    "    dam_counts_df.columns = dam_counts_df.columns.str.upper()\n",
    "\n",
    "    return dam_counts_df\n",
    "\n",
    "\n",
    "# Compute cross-correlation using numpy\n",
    "def cross_correlation(x, y, max_lag):\n",
    "    lags = np.arange(-max_lag, max_lag + 1)\n",
    "    corr = []\n",
    "    for lag in lags:\n",
    "        if lag < 0:\n",
    "            # Negative lag: shift x forward (x leads y)\n",
    "            x_shifted = x[-lag:]\n",
    "            y_truncated = y[: len(y) + lag]\n",
    "        else:\n",
    "            # Positive lag: shift y forward (y leads x)\n",
    "            x_shifted = x[: len(x) - lag]\n",
    "            y_truncated = y[lag:]\n",
    "        # Compute Pearson correlation\n",
    "        corr.append(np.corrcoef(x_shifted, y_truncated)[0, 1])\n",
    "    return lags, corr\n",
    "\n",
    "\n",
    "###############################\n",
    "# Visualization\n",
    "\n",
    "\n",
    "## Animated Plotly Figure\n",
    "def plot_plotly_mapbox_time_series(df, color_choice, species_choice):\n",
    "    if color_choice == \"Normalized Count\":\n",
    "        color_plot = \"DOY_ZSCORE\"\n",
    "    else:\n",
    "        color_plot = \"COUNT\"\n",
    "\n",
    "    df = df[df.SPECIES == species_choice]\n",
    "\n",
    "    fig = px.scatter_map(\n",
    "        df,\n",
    "        lat=\"LAT\",\n",
    "        lon=\"LON\",\n",
    "        color=color_plot,\n",
    "        hover_name=\"LOCATION\",\n",
    "        size=[10] * len(df),\n",
    "        hover_data={\n",
    "            \"DATE\": True,\n",
    "            \"DAM\": False,\n",
    "            \"COUNT\": True,\n",
    "            \"DOY_ZSCORE\": True,\n",
    "            \"LAT\": False,\n",
    "            \"LON\": False,\n",
    "        },\n",
    "        zoom=6,\n",
    "        height=600,\n",
    "        title=\"Map - Displaying Count of Salmon at Dams Along the Columbia\",\n",
    "        animation_frame=\"DATE\",\n",
    "        color_continuous_scale=\"RdBu\",  # Red-Blue diverging color scale # or your custom palette\n",
    "    )\n",
    "\n",
    "    # Center the diverging color scale on zero\n",
    "    fig.update_traces(marker=dict(colorscale=\"RdBu\", showscale=True))\n",
    "\n",
    "    fig.update_layout(\n",
    "        mapbox_style=\"open-street-map\",\n",
    "        margin={\"r\": 0, \"t\": 30, \"l\": 0, \"b\": 0},\n",
    "        coloraxis_colorbar=dict(\n",
    "            title=color_choice,  # Title for the color scale\n",
    "            tickvals=[\n",
    "                -max(df[color_plot].abs()),\n",
    "                0,\n",
    "                max(df[color_plot].abs()),\n",
    "            ],\n",
    "            ticktext=[\n",
    "                f\"-{max(df[color_plot].abs())}\",\n",
    "                \"0\",\n",
    "                f\"{max(df[color_plot].abs())}\",\n",
    "            ],\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_digraph_rivers(dams, edges):\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(dams)\n",
    "    G.add_edges_from(edges)\n",
    "\n",
    "    # Manual x positions, increasing left to right flow\n",
    "    x_positions = {\n",
    "        \"Pacific\": 0,\n",
    "        \"Columbia Mouth\": 1,\n",
    "        \"Willapa Bay\": 1,\n",
    "        \"Bonneville\": 2,\n",
    "        \"Willamette\": 2,\n",
    "        \"Dalles\": 3,\n",
    "        \"John Day\": 4,\n",
    "        \"McNary\": 5,\n",
    "        \"Priest Rapids\": 6,\n",
    "        \"Ice Harbor\": 6,\n",
    "        \"Wannapum\": 7,\n",
    "        \"Lower Monumental\": 7,\n",
    "        \"Rock Island\": 8,\n",
    "        \"Little Goose\": 8,\n",
    "        \"Rocky Reach\": 9,\n",
    "        \"Lower Granite\": 9,\n",
    "        \"Wells\": 10,\n",
    "    }\n",
    "\n",
    "    # Manual y positions to separate branches nicely\n",
    "    y_positions = {\n",
    "        \"Pacific\": 0,\n",
    "        \"Columbia Mouth\": 1,\n",
    "        \"Willapa Bay\": -1,\n",
    "        \"Bonneville\": 0.5,\n",
    "        \"Willamette\": -1.5,\n",
    "        \"Dalles\": 1,\n",
    "        \"John Day\": 1.5,\n",
    "        \"McNary\": 2,\n",
    "        \"Priest Rapids\": 3,\n",
    "        \"Ice Harbor\": 1.5,\n",
    "        \"Wannapum\": 3.5,\n",
    "        \"Lower Monumental\": 1,\n",
    "        \"Rock Island\": 4,\n",
    "        \"Little Goose\": 0.5,\n",
    "        \"Rocky Reach\": 4.5,\n",
    "        \"Lower Granite\": 0,\n",
    "        \"Wells\": 5,\n",
    "    }\n",
    "    node_colors = {\n",
    "        \"Pacific\": \"forestgreen\",\n",
    "        \"Columbia Mouth\": \"mediumseagreen\",\n",
    "        \"Willapa Bay\": \"limegreen\",\n",
    "        \"Bonneville\": \"darkgreen\",\n",
    "        \"Dalles\": \"seagreen\",\n",
    "        \"Willamette\": \"olivedrab\",\n",
    "        \"McNary\": \"yellowgreen\",\n",
    "        \"Ice Harbor\": \"lightgreen\",\n",
    "        \"John Day\": \"springgreen\",\n",
    "        \"Lower Granite\": \"darkolivegreen\",\n",
    "        \"Lower Monumental\": \"mediumaquamarine\",\n",
    "        \"Little Goose\": \"mediumspringgreen\",\n",
    "        \"Rock Island\": \"palegreen\",\n",
    "        \"Rocky Reach\": \"chartreuse\",\n",
    "        \"Wannapum\": \"lawngreen\",\n",
    "        \"Priest Rapids\": \"forestgreen\",\n",
    "        \"Wells\": \"lime\",\n",
    "    }\n",
    "\n",
    "    pos = {node: (x_positions[node], y_positions[node]) for node in dams}\n",
    "\n",
    "    # Edge lines\n",
    "    edge_x = []\n",
    "    edge_y = []\n",
    "    for src, dst in G.edges():\n",
    "        x0, y0 = pos[src]\n",
    "        x1, y1 = pos[dst]\n",
    "        edge_x.extend([x0, x1, None])\n",
    "        edge_y.extend([y0, y1, None])\n",
    "\n",
    "    edge_trace = go.Scatter(\n",
    "        x=edge_x,\n",
    "        y=edge_y,\n",
    "        line=dict(width=2, color=\"blue\"),\n",
    "        hoverinfo=\"none\",\n",
    "        mode=\"lines\",\n",
    "    )\n",
    "\n",
    "    # Nodes\n",
    "    node_x = [pos[dam][0] for dam in dams]\n",
    "    node_y = [pos[dam][1] for dam in dams]\n",
    "\n",
    "    node_trace = go.Scatter(\n",
    "        x=node_x,\n",
    "        y=node_y,\n",
    "        mode=\"markers+text\",\n",
    "        text=dams,\n",
    "        textposition=\"top center\",\n",
    "        hoverinfo=\"text\",\n",
    "        marker=dict(\n",
    "            size=20, color=\"lightblue\", line=dict(width=2, color=\"forestgreen\")\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Step 2 & 3: build annotations with arrow colors based on source node\n",
    "    annotations = []\n",
    "    for src, dst in G.edges():\n",
    "        x0, y0 = pos[src]\n",
    "        x1, y1 = pos[dst]\n",
    "        color = node_colors.get(src, \"blue\")  # fallback color if not found\n",
    "        annotations.append(\n",
    "            dict(\n",
    "                ax=x0,\n",
    "                ay=y0,\n",
    "                x=x1,\n",
    "                y=y1,\n",
    "                xref=\"x\",\n",
    "                yref=\"y\",\n",
    "                axref=\"x\",\n",
    "                ayref=\"y\",\n",
    "                showarrow=True,\n",
    "                arrowhead=2,\n",
    "                arrowsize=1,\n",
    "                arrowwidth=1,\n",
    "                arrowcolor=color,\n",
    "                standoff=4,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig = go.Figure(data=[edge_trace, node_trace])\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=dict(text=\"Dam Connectivity - Pacific Left to Right\", font=dict(size=18)),\n",
    "        annotations=annotations,\n",
    "        showlegend=False,\n",
    "        hovermode=\"closest\",\n",
    "        margin=dict(l=20, r=20, t=50, b=20),\n",
    "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "        plot_bgcolor=\"white\",\n",
    "        height=600,\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_dam_colors(dam_colors):\n",
    "    \"\"\"\n",
    "    Plot a list of dams and their corresponding colors.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dam_colors : dict\n",
    "        Dictionary mapping dam names (str) to color hex codes (str).\n",
    "    \"\"\"\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(6, len(dam_colors) * 0.4))\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    # Plot each dam name and its color swatch\n",
    "    for i, (dam, color) in enumerate(dam_colors.items()):\n",
    "        ax.add_patch(\n",
    "            mpatches.Rectangle((0.4, len(dam_colors) - i - 1), 1, 0.8, color=color)\n",
    "        )\n",
    "        ax.text(0, len(dam_colors) - i - 0.6, dam, va=\"center\", fontsize=12)\n",
    "\n",
    "    ax.set_xlim(0, 2.5)\n",
    "    ax.set_ylim(-0.5, len(dam_colors) + 0.5)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#                                                         #\n",
    "# ------------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf571a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = \"/Users/tylerstevenson/Documents/CODE/SalmonSignal/data\"\n",
    "\n",
    "path_lookup = [\n",
    "    (\n",
    "        \"Bonneville\",\n",
    "        f\"{base_directory}/raw/AD16894096d7ce32.csv\",\n",
    "    ),\n",
    "    (\n",
    "        \"Dalles\",\n",
    "        f\"{base_directory}/raw/AD1689415a04da39.csv\",\n",
    "    ),\n",
    "    (\n",
    "        \"Ice Harbor\",\n",
    "        f\"{base_directory}/raw/AD1689688165f481.csv\",\n",
    "    ),\n",
    "    (\n",
    "        \"John Day\",\n",
    "        f\"{base_directory}/raw/AD16894181728912.csv\",\n",
    "    ),\n",
    "    (\n",
    "        \"Little Goose\",\n",
    "        f\"{base_directory}/raw/AD1689688e70bc7a.csv\",\n",
    "    ),\n",
    "    (\n",
    "        \"Lower Granite\",\n",
    "        f\"{base_directory}/raw/AD16896890ee2687.csv\",\n",
    "    ),\n",
    "    (\n",
    "        \"Lower Monumental\",\n",
    "        f\"{base_directory}/raw/AD16896885f88a37.csv\",\n",
    "    ),\n",
    "    (\n",
    "        \"McNary\",\n",
    "        f\"{base_directory}/raw/AD168968ab3be339.csv\",\n",
    "    ),\n",
    "    (\n",
    "        \"Priest Rapids\",\n",
    "        f\"{base_directory}/raw/AD168968940d1cab.csv\",\n",
    "    ),\n",
    "    (\n",
    "        \"Rock Island\",\n",
    "        f\"{base_directory}/raw/AD168968a05c4ade.csv\",\n",
    "    ),\n",
    "    (\n",
    "        \"Rocky Reach\",\n",
    "        f\"{base_directory}/raw/AD168968a3217277.csv\",\n",
    "    ),\n",
    "    (\n",
    "        \"Wannapum\",\n",
    "        f\"{base_directory}/raw/AD1689689e1523e4.csv\",\n",
    "    ),\n",
    "    (\n",
    "        \"Wells\",\n",
    "        f\"{base_directory}/raw/AD168968a5de47f2.csv\",\n",
    "    ),\n",
    "    (\n",
    "        \"Willamette\",\n",
    "        f\"{base_directory}/raw/AD168948e560fe6a.csv\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b867df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../data/processed/FPC_DAM_COUNTS/\"\n",
    "\n",
    "for location in path_lookup:\n",
    "    df_long = prepare_data(path=location[1], location_name=location[0])\n",
    "    print(df_long.Dam.unique())\n",
    "\n",
    "    # Save to File\n",
    "    save_to_file(output_dir=output_dir, df_long=df_long, location_name=location[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11572fc",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed4378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### PARAMETERS\n",
    "## Dam Count Directory\n",
    "dam_count_directory = \"../data/processed/FPC_DAM_COUNTS/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9f31bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Spatial Layers\n",
    "columbia_river_mouth, river_gdf, dams = load_columbia_river_data()\n",
    "\n",
    "# Load Dam Counts\n",
    "dam_counts_df = load_dam_counts(dam_count_directory)\n",
    "dam_counts_df = pd.merge(dam_counts_df, dams, on=[\"DAM\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2b0f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Chinook\n",
    "selected_species = \"ChinookAdult\"\n",
    "color_choice = \"COUNT\"  # [\"Count\", \"Normalized Count\"]\n",
    "\n",
    "species_dam_counts = dam_counts_df[dam_counts_df.SPECIES == selected_species]\n",
    "species_dam_counts = species_dam_counts[species_dam_counts.DATETIME >= \"2018-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4dfb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "DAM_COLORS = {\n",
    "    \"Pacific\": \"#01295f\",\n",
    "    \"Willapa Bay\": \"#321129\",\n",
    "    \"Columbia Mouth\": \"#41ead4\",\n",
    "    \"Willamette\": \"#e60049\",\n",
    "    \"Bonneville\": \"#0bb4ff\",\n",
    "    \"Dalles\": \"#50e991\",\n",
    "    \"John Day\": \"#e6d800\",\n",
    "    \"McNary\": \"#9b19f5\",\n",
    "    \"Ice Harbor\": \"#ffa300\",\n",
    "    \"Lower Monumental\": \"#dc0ab4\",\n",
    "    \"Little Goose\": \"#b3d4ff\",\n",
    "    \"Lower Granite\": \"#00bfa0\",\n",
    "    \"Priest Rapids\": \"#1a53ff\",\n",
    "    \"Wannapum\": \"#fdcce5\",\n",
    "    \"Rock Island\": \"#32462f\",\n",
    "    \"Rocky Reach\": \"#9b8c6f\",\n",
    "    \"Wells\": \"#a5be00\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f19b8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_dam_counts_yr = species_dam_counts[species_dam_counts.YEAR == 2018].sort_values(\n",
    "    \"DOY\"\n",
    ")\n",
    "\n",
    "fig = px.line(\n",
    "    species_dam_counts_yr,\n",
    "    x=\"DOY\",\n",
    "    y=color_choice,\n",
    "    color=\"LOCATION\",\n",
    "    title=f\"Dam Counts Along the Columbia - {selected_species}\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daceaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_dam_counts_yr[\"LOCATION\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ca22a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edae4936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dams and edges\n",
    "dams = [\n",
    "    \"Pacific\",\n",
    "    \"Columbia Mouth\",\n",
    "    \"Willapa Bay\",\n",
    "    \"Bonneville\",\n",
    "    \"Dalles\",\n",
    "    \"Willamette\",\n",
    "    \"McNary\",\n",
    "    \"Ice Harbor\",\n",
    "    \"John Day\",\n",
    "    \"Lower Granite\",\n",
    "    \"Lower Monumental\",\n",
    "    \"Little Goose\",\n",
    "    \"Rock Island\",\n",
    "    \"Rocky Reach\",\n",
    "    \"Wannapum\",\n",
    "    \"Priest Rapids\",\n",
    "    \"Wells\",\n",
    "]\n",
    "\n",
    "edges = [\n",
    "    (\"Pacific\", \"Columbia Mouth\"),\n",
    "    (\"Pacific\", \"Willapa Bay\"),\n",
    "    (\"Columbia Mouth\", \"Bonneville\"),\n",
    "    (\"Columbia Mouth\", \"Bonneville\"),\n",
    "    (\"Willapa Bay\", \"Willamette\"),\n",
    "    (\"Willapa Bay\", \"Bonneville\"),\n",
    "    (\"Bonneville\", \"Dalles\"),\n",
    "    (\"Dalles\", \"John Day\"),\n",
    "    (\"John Day\", \"McNary\"),\n",
    "    (\"McNary\", \"Ice Harbor\"),\n",
    "    (\"Ice Harbor\", \"Lower Monumental\"),\n",
    "    (\"Lower Monumental\", \"Little Goose\"),\n",
    "    (\"Little Goose\", \"Lower Granite\"),\n",
    "    (\"McNary\", \"Priest Rapids\"),\n",
    "    (\"Priest Rapids\", \"Wannapum\"),\n",
    "    (\"Wannapum\", \"Rock Island\"),\n",
    "    (\"Rock Island\", \"Rocky Reach\"),\n",
    "    (\"Rocky Reach\", \"Wells\"),\n",
    "]\n",
    "\n",
    "\n",
    "digraph_fig = plot_digraph_rivers(dams, edges)\n",
    "digraph_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1324ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column map from species_dam_counts_yr\n",
    "column_map = dict(zip(species_dam_counts_yr[\"LOCATION\"], species_dam_counts_yr[\"DAM\"]))\n",
    "\n",
    "\n",
    "# Create directed graph (downstream-to-upstream)\n",
    "G = nx.DiGraph()\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "transitive_pairs = set()\n",
    "for node1 in G.nodes():\n",
    "    for node2 in G.nodes():\n",
    "        if node1 != node2 and nx.has_path(G, node1, node2):\n",
    "            if node1 in column_map.keys() and node2 in column_map.keys():\n",
    "                transitive_pairs.add((column_map[node1], column_map[node2]))\n",
    "\n",
    "print(f\"Analyzing {len(transitive_pairs)} hierarchical pairs:\")\n",
    "for pair in sorted(transitive_pairs)[0:10]:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9204f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# species_dam_counts_select = species_dam_counts[\n",
    "#     species_dam_counts.LOCATION.isin([\"Bonneville\", \"Dalles\"])\n",
    "# ].copy()\n",
    "# species_dam_counts_select.COUNT = np.where(\n",
    "#     species_dam_counts_select.COUNT < 0, 0, species_dam_counts_select.COUNT\n",
    "# )\n",
    "# print(species_dam_counts_select.DAM.unique())\n",
    "\n",
    "# avg_doy = species_dam_counts_select[species_dam_counts_select[\"YEAR\"] == 2023][\n",
    "#     [\"DAM\", \"DOY\", \"COUNT\"]\n",
    "# ].copy()\n",
    "# avg_doy = avg_doy.sort_values(\"DOY\").reset_index(drop=True)\n",
    "\n",
    "# color_map = {\"BON\": \"blue\", \"MCN\": \"red\"}\n",
    "\n",
    "# fig = px.bar(\n",
    "#     avg_doy,\n",
    "#     x=\"DOY\",\n",
    "#     y=\"COUNT\",\n",
    "#     color=\"DAM\",\n",
    "#     barmode=\"overlay\",\n",
    "#     color_discrete_map=color_map,\n",
    "# )\n",
    "# fig.show()\n",
    "\n",
    "\n",
    "# df = pd.pivot_table(avg_doy, index=\"DOY\", columns=\"DAM\", values=\"COUNT\").reset_index()\n",
    "\n",
    "# # Extract the time series\n",
    "# doy = df[\"DOY\"]\n",
    "# bon = df[\"BON\"]\n",
    "# bon = bon.fillna(0)\n",
    "\n",
    "# mcn = df[\"TDA\"]\n",
    "# mcn = mcn.fillna(0)\n",
    "\n",
    "# # Set maximum lag for analysis\n",
    "# max_lag = 50\n",
    "# lags, corr = cross_correlation(bon, mcn, max_lag)\n",
    "\n",
    "# # Find the lag with maximum correlation\n",
    "# max_corr_idx = np.argmax(corr)\n",
    "# max_corr_lag = lags[max_corr_idx]\n",
    "# max_corr_value = corr[max_corr_idx]\n",
    "\n",
    "# print(f\"Maximum correlation: {max_corr_value:.2f} at lag {max_corr_lag} days\")\n",
    "# print(\"Positive lag indicates BON lags MCN; negative lag indicates BON leads MCN.\")\n",
    "\n",
    "# # Plot the time series\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(doy, bon, label=\"BON\", color=\"#1f77b4\")\n",
    "# plt.plot(doy, mcn, label=\"MCN\", color=\"#ff7f0e\")\n",
    "# plt.xlabel(\"Day of Year (DOY)\")\n",
    "# plt.ylabel(\"Value\")\n",
    "# plt.title(\"BON and MCN Time Series\")\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# # Plot the cross-correlation\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(lags, corr, color=\"#2ca02c\")\n",
    "# plt.axvline(\n",
    "#     x=max_corr_lag, color=\"r\", linestyle=\"--\", label=f\"Max Corr at lag {max_corr_lag}\"\n",
    "# )\n",
    "# plt.xlabel(\"Lag (Days)\")\n",
    "# plt.ylabel(\"Correlation Coefficient\")\n",
    "# plt.title(\"Cross-Correlation Function (BON vs. MCN)\")\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# # Clip the dataset to DOY 76–365 (where both BON and MCN have significant activity)\n",
    "# df_clipped = df[df[\"DOY\"] >= 76].copy()\n",
    "\n",
    "# # Check for NaNs\n",
    "# if df_clipped[[\"BON\", \"TDA\"]].isna().any().any():\n",
    "#     print(\"NaNs detected. Imputing with zeros.\")\n",
    "#     df_clipped[\"BON\"] = df_clipped[\"BON\"].fillna(0.0)\n",
    "#     df_clipped[\"TDA\"] = df_clipped[\"TDA\"].fillna(0.0)\n",
    "# else:\n",
    "#     print(\"No NaNs detected in BON or MCN.\")\n",
    "\n",
    "# # Extract the time series\n",
    "# doy = df_clipped[\"DOY\"]\n",
    "# bon = df_clipped[\"BON\"]\n",
    "# mcn = df_clipped[\"TDA\"]\n",
    "\n",
    "# # Set maximum lag\n",
    "# max_lag = 50\n",
    "# lags, corr = cross_correlation(bon, mcn, max_lag)\n",
    "\n",
    "# # Remove NaNs from correlation results for plotting\n",
    "# valid_idx = ~np.isnan(corr)\n",
    "# lags = lags[valid_idx]\n",
    "# corr = np.array(corr)[valid_idx]\n",
    "\n",
    "# # Find the lag with maximum correlation\n",
    "# max_corr_idx = np.argmax(corr)\n",
    "# max_corr_lag = lags[max_corr_idx]\n",
    "# max_corr_value = corr[max_corr_idx]\n",
    "\n",
    "# print(f\"Maximum correlation: {max_corr_value:.2f} at lag {max_corr_lag} days\")\n",
    "# print(\"Positive lag indicates BON lags MCN; negative lag indicates BON leads MCN.\")\n",
    "\n",
    "# # Plot the time series\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(doy, bon, label=\"BON\", color=\"#1f77b4\")\n",
    "# plt.plot(doy, mcn, label=\"TDA\", color=\"#ff7f0e\")\n",
    "# plt.xlabel(\"Day of Year (DOY)\")\n",
    "# plt.ylabel(\"Value\")\n",
    "# plt.title(\"BON and TDA Time Series (DOY 76–365)\")\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# # Plot the cross-correlation\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(lags, corr, color=\"#2ca02c\")\n",
    "# plt.axvline(\n",
    "#     x=max_corr_lag, color=\"r\", linestyle=\"--\", label=f\"Max Corr at lag {max_corr_lag}\"\n",
    "# )\n",
    "# plt.xlabel(\"Lag (Days)\")\n",
    "# plt.ylabel(\"Correlation Coefficient\")\n",
    "# plt.title(\"Cross-Correlation Function (BON vs. MCN, DOY 76–365)\")\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1fa553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same lag with tighter window == probably somewhat robust... let's do it across all sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e096df47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the time series\n",
    "def get_max_corr_lag(df, pair1, pair2):\n",
    "    doy = df[\"DOY\"]\n",
    "    pair1_df = df[pair1]\n",
    "    pair1_df = pair1_df.fillna(0)\n",
    "\n",
    "    pair2_df = df[pair2]\n",
    "    pair2_df = pair2_df.fillna(0)\n",
    "\n",
    "    # Set maximum lag for analysis\n",
    "    max_lag = 50\n",
    "    lags, corr = cross_correlation(pair1_df, pair2_df, max_lag)\n",
    "    max_corr_idx = np.argmax(corr)\n",
    "\n",
    "    lookup = pd.DataFrame()\n",
    "    lookup[\"PAIR\"] = [f\"{pair1}-{pair2}\"]\n",
    "    lookup[\"MAX_CORR_LAG\"] = [lags[max_corr_idx]]\n",
    "    lookup[\"MAX_CORR\"] = [corr[max_corr_idx]]\n",
    "\n",
    "    return lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f46666",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_dam_counts_select = species_dam_counts.copy()\n",
    "species_dam_counts_select.COUNT = np.where(\n",
    "    species_dam_counts_select.COUNT < 0, 0, species_dam_counts_select.COUNT\n",
    ")\n",
    "\n",
    "df = pd.pivot_table(\n",
    "    species_dam_counts, index=\"DOY\", columns=\"DAM\", values=\"COUNT\"\n",
    ").reset_index()\n",
    "df = df.fillna(0)\n",
    "\n",
    "returned_vals = []\n",
    "for pair in transitive_pairs:\n",
    "    pair_corr = get_max_corr_lag(df, pair1=pair[0], pair2=pair[1])\n",
    "    returned_vals.append(pair_corr)\n",
    "\n",
    "returned_vals = pd.concat(returned_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8ef26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "returned_vals[returned_vals.PAIR.str.startswith(\"BON\")].sort_values(\"MAX_CORR_LAG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a10b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line()\n",
    "fig.add_scatter(x=df[\"DOY\"], y=df[\"BON\"], marker_color=\"green\", name=\"BON\")\n",
    "fig.add_scatter(x=df[\"DOY\"], y=df[\"TDA\"], marker_color=\"blue\", name=\"TDA\")\n",
    "fig.add_scatter(x=df[\"DOY\"], y=df[\"JDA\"], marker_color=\"teal\", name=\"JDA\")\n",
    "fig.add_scatter(x=df[\"DOY\"], y=df[\"IHR\"], marker_color=\"orange\", name=\"IHR\")\n",
    "fig.add_scatter(x=df[\"DOY\"], y=df[\"LMN\"], marker_color=\"red\", name=\"LMN\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0f58fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fb4f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column map from species_dam_counts_yr\n",
    "column_map = dict(zip(species_dam_counts_yr[\"LOCATION\"], species_dam_counts_yr[\"DAM\"]))\n",
    "\n",
    "digraph_fig = plot_digraph_rivers(dams, edges)\n",
    "digraph_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salmonsignal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
